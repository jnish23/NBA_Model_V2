{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "infinite-photography",
   "metadata": {},
   "source": [
    "# Team Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-communist",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "wooden-lucas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sqlite3\n",
    "import joblib\n",
    "import optuna\n",
    "\n",
    "import pandas as pd\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE, RFECV, SequentialFeatureSelector, SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression, SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pointbiserialr\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# import tensorflow as tf \n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, RFE, RFECV\n",
    "from tqdm import tqdm\n",
    "from nba_api.stats.static import players, teams\n",
    "\n",
    "import sys\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bizarre-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=230\n",
    "pd.options.display.max_rows=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c35dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sqlite3.connect('../data/nba.db')\n",
    "\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM team_stats_ewa_matchup', con=connection)\n",
    "df = df.drop(columns=['index'])\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aeaba3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON</th>\n",
       "      <th>HOME_TEAM_ABBREVIATION</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>HOME_HOME_GAME</th>\n",
       "      <th>HOME_TEAM_SCORE</th>\n",
       "      <th>HOME_ML</th>\n",
       "      <th>HOME_SPREAD</th>\n",
       "      <th>HOME_ATS_DIFF</th>\n",
       "      <th>HOME_TEAM_COVERED</th>\n",
       "      <th>HOME_POINT_DIFF</th>\n",
       "      <th>HOME_WL</th>\n",
       "      <th>HOME_FG2M_L5</th>\n",
       "      <th>HOME_FG2A_L5</th>\n",
       "      <th>HOME_FG3M_L5</th>\n",
       "      <th>HOME_FG3A_L5</th>\n",
       "      <th>HOME_FTM_L5</th>\n",
       "      <th>HOME_FTA_L5</th>\n",
       "      <th>HOME_OREB_L5</th>\n",
       "      <th>HOME_DREB_L5</th>\n",
       "      <th>HOME_REB_L5</th>\n",
       "      <th>HOME_AST_L5</th>\n",
       "      <th>HOME_STL_L5</th>\n",
       "      <th>HOME_BLK_L5</th>\n",
       "      <th>HOME_TOV_L5</th>\n",
       "      <th>HOME_PF_L5</th>\n",
       "      <th>HOME_PTS_L5</th>\n",
       "      <th>HOME_PLUS_MINUS_L5</th>\n",
       "      <th>HOME_OFF_RATING_L5</th>\n",
       "      <th>HOME_DEF_RATING_L5</th>\n",
       "      <th>HOME_NET_RATING_L5</th>\n",
       "      <th>HOME_PACE_L5</th>\n",
       "      <th>HOME_POSS_L5</th>\n",
       "      <th>HOME_DIST_L5</th>\n",
       "      <th>HOME_ORBC_L5</th>\n",
       "      <th>HOME_DRBC_L5</th>\n",
       "      <th>HOME_RBC_L5</th>\n",
       "      <th>HOME_TCHS_L5</th>\n",
       "      <th>HOME_SAST_L5</th>\n",
       "      <th>HOME_FTAST_L5</th>\n",
       "      <th>HOME_PASS_L5</th>\n",
       "      <th>HOME_CFGM_L5</th>\n",
       "      <th>HOME_CFGA_L5</th>\n",
       "      <th>HOME_UFGM_L5</th>\n",
       "      <th>HOME_UFGA_L5</th>\n",
       "      <th>HOME_DFGM_L5</th>\n",
       "      <th>HOME_DFGA_L5</th>\n",
       "      <th>HOME_PTS_2PT_MR_L5</th>\n",
       "      <th>HOME_PTS_FB_L5</th>\n",
       "      <th>HOME_PTS_OFF_TOV_L5</th>\n",
       "      <th>HOME_PTS_PAINT_L5</th>\n",
       "      <th>HOME_AST_2PM_L5</th>\n",
       "      <th>HOME_AST_3PM_L5</th>\n",
       "      <th>HOME_UAST_2PM_L5</th>\n",
       "      <th>HOME_UAST_3PM_L5</th>\n",
       "      <th>HOME_FG2M_opp_L5</th>\n",
       "      <th>HOME_FG2A_opp_L5</th>\n",
       "      <th>HOME_FG3M_opp_L5</th>\n",
       "      <th>HOME_FG3A_opp_L5</th>\n",
       "      <th>HOME_FTM_opp_L5</th>\n",
       "      <th>HOME_FTA_opp_L5</th>\n",
       "      <th>HOME_OREB_opp_L5</th>\n",
       "      <th>HOME_DREB_opp_L5</th>\n",
       "      <th>HOME_REB_opp_L5</th>\n",
       "      <th>HOME_AST_opp_L5</th>\n",
       "      <th>HOME_STL_opp_L5</th>\n",
       "      <th>HOME_BLK_opp_L5</th>\n",
       "      <th>HOME_TOV_opp_L5</th>\n",
       "      <th>HOME_PF_opp_L5</th>\n",
       "      <th>HOME_PTS_opp_L5</th>\n",
       "      <th>HOME_PLUS_MINUS_opp_L5</th>\n",
       "      <th>HOME_OFF_RATING_opp_L5</th>\n",
       "      <th>HOME_DEF_RATING_opp_L5</th>\n",
       "      <th>HOME_NET_RATING_opp_L5</th>\n",
       "      <th>HOME_PACE_opp_L5</th>\n",
       "      <th>HOME_POSS_opp_L5</th>\n",
       "      <th>HOME_DIST_opp_L5</th>\n",
       "      <th>HOME_ORBC_opp_L5</th>\n",
       "      <th>HOME_DRBC_opp_L5</th>\n",
       "      <th>HOME_RBC_opp_L5</th>\n",
       "      <th>HOME_TCHS_opp_L5</th>\n",
       "      <th>HOME_SAST_opp_L5</th>\n",
       "      <th>HOME_FTAST_opp_L5</th>\n",
       "      <th>HOME_PASS_opp_L5</th>\n",
       "      <th>HOME_CFGM_opp_L5</th>\n",
       "      <th>HOME_CFGA_opp_L5</th>\n",
       "      <th>HOME_UFGM_opp_L5</th>\n",
       "      <th>HOME_UFGA_opp_L5</th>\n",
       "      <th>HOME_DFGM_opp_L5</th>\n",
       "      <th>HOME_DFGA_opp_L5</th>\n",
       "      <th>HOME_PTS_2PT_MR_opp_L5</th>\n",
       "      <th>HOME_PTS_FB_opp_L5</th>\n",
       "      <th>HOME_PTS_OFF_TOV_opp_L5</th>\n",
       "      <th>HOME_PTS_PAINT_opp_L5</th>\n",
       "      <th>HOME_AST_2PM_opp_L5</th>\n",
       "      <th>HOME_AST_3PM_opp_L5</th>\n",
       "      <th>HOME_UAST_2PM_opp_L5</th>\n",
       "      <th>HOME_UAST_3PM_opp_L5</th>\n",
       "      <th>HOME_AVG_ATS_DIFF_L5</th>\n",
       "      <th>HOME_WIN_PCT_L5</th>\n",
       "      <th>HOME_COVER_PCT_L5</th>\n",
       "      <th>HOME_OREB_PCT_L5</th>\n",
       "      <th>HOME_OREB_PCT_opp_L5</th>\n",
       "      <th>HOME_DREB_PCT_L5</th>\n",
       "      <th>HOME_DREB_PCT_opp_L5</th>\n",
       "      <th>HOME_REB_PCT_L5</th>\n",
       "      <th>HOME_REB_PCT_opp_L5</th>\n",
       "      <th>HOME_TS_PCT_L5</th>\n",
       "      <th>HOME_TS_PCT_opp_L5</th>\n",
       "      <th>HOME_EFG_PCT_L5</th>\n",
       "      <th>HOME_EFG_PCT_opp_L5</th>\n",
       "      <th>HOME_AST_RATIO_L5</th>\n",
       "      <th>HOME_AST_RATIO_opp_L5</th>\n",
       "      <th>HOME_TOV_PCT_L5</th>\n",
       "      <th>...</th>\n",
       "      <th>AWAY_REB_PCT_opp_L10</th>\n",
       "      <th>AWAY_TS_PCT_L10</th>\n",
       "      <th>AWAY_TS_PCT_opp_L10</th>\n",
       "      <th>AWAY_EFG_PCT_L10</th>\n",
       "      <th>AWAY_EFG_PCT_opp_L10</th>\n",
       "      <th>AWAY_AST_RATIO_L10</th>\n",
       "      <th>AWAY_AST_RATIO_opp_L10</th>\n",
       "      <th>AWAY_TOV_PCT_L10</th>\n",
       "      <th>AWAY_TOV_PCT_opp_L10</th>\n",
       "      <th>AWAY_PIE_L10</th>\n",
       "      <th>AWAY_FG2M_L20</th>\n",
       "      <th>AWAY_FG2A_L20</th>\n",
       "      <th>AWAY_FG3M_L20</th>\n",
       "      <th>AWAY_FG3A_L20</th>\n",
       "      <th>AWAY_FTM_L20</th>\n",
       "      <th>AWAY_FTA_L20</th>\n",
       "      <th>AWAY_OREB_L20</th>\n",
       "      <th>AWAY_DREB_L20</th>\n",
       "      <th>AWAY_REB_L20</th>\n",
       "      <th>AWAY_AST_L20</th>\n",
       "      <th>AWAY_STL_L20</th>\n",
       "      <th>AWAY_BLK_L20</th>\n",
       "      <th>AWAY_TOV_L20</th>\n",
       "      <th>AWAY_PF_L20</th>\n",
       "      <th>AWAY_PTS_L20</th>\n",
       "      <th>AWAY_PLUS_MINUS_L20</th>\n",
       "      <th>AWAY_OFF_RATING_L20</th>\n",
       "      <th>AWAY_DEF_RATING_L20</th>\n",
       "      <th>AWAY_NET_RATING_L20</th>\n",
       "      <th>AWAY_PACE_L20</th>\n",
       "      <th>AWAY_POSS_L20</th>\n",
       "      <th>AWAY_DIST_L20</th>\n",
       "      <th>AWAY_ORBC_L20</th>\n",
       "      <th>AWAY_DRBC_L20</th>\n",
       "      <th>AWAY_RBC_L20</th>\n",
       "      <th>AWAY_TCHS_L20</th>\n",
       "      <th>AWAY_SAST_L20</th>\n",
       "      <th>AWAY_FTAST_L20</th>\n",
       "      <th>AWAY_PASS_L20</th>\n",
       "      <th>AWAY_CFGM_L20</th>\n",
       "      <th>AWAY_CFGA_L20</th>\n",
       "      <th>AWAY_UFGM_L20</th>\n",
       "      <th>AWAY_UFGA_L20</th>\n",
       "      <th>AWAY_DFGM_L20</th>\n",
       "      <th>AWAY_DFGA_L20</th>\n",
       "      <th>AWAY_PTS_2PT_MR_L20</th>\n",
       "      <th>AWAY_PTS_FB_L20</th>\n",
       "      <th>AWAY_PTS_OFF_TOV_L20</th>\n",
       "      <th>AWAY_PTS_PAINT_L20</th>\n",
       "      <th>AWAY_AST_2PM_L20</th>\n",
       "      <th>AWAY_AST_3PM_L20</th>\n",
       "      <th>AWAY_UAST_2PM_L20</th>\n",
       "      <th>AWAY_UAST_3PM_L20</th>\n",
       "      <th>AWAY_FG2M_opp_L20</th>\n",
       "      <th>AWAY_FG2A_opp_L20</th>\n",
       "      <th>AWAY_FG3M_opp_L20</th>\n",
       "      <th>AWAY_FG3A_opp_L20</th>\n",
       "      <th>AWAY_FTM_opp_L20</th>\n",
       "      <th>AWAY_FTA_opp_L20</th>\n",
       "      <th>AWAY_OREB_opp_L20</th>\n",
       "      <th>AWAY_DREB_opp_L20</th>\n",
       "      <th>AWAY_REB_opp_L20</th>\n",
       "      <th>AWAY_AST_opp_L20</th>\n",
       "      <th>AWAY_STL_opp_L20</th>\n",
       "      <th>AWAY_BLK_opp_L20</th>\n",
       "      <th>AWAY_TOV_opp_L20</th>\n",
       "      <th>AWAY_PF_opp_L20</th>\n",
       "      <th>AWAY_PTS_opp_L20</th>\n",
       "      <th>AWAY_PLUS_MINUS_opp_L20</th>\n",
       "      <th>AWAY_OFF_RATING_opp_L20</th>\n",
       "      <th>AWAY_DEF_RATING_opp_L20</th>\n",
       "      <th>AWAY_NET_RATING_opp_L20</th>\n",
       "      <th>AWAY_PACE_opp_L20</th>\n",
       "      <th>AWAY_POSS_opp_L20</th>\n",
       "      <th>AWAY_DIST_opp_L20</th>\n",
       "      <th>AWAY_ORBC_opp_L20</th>\n",
       "      <th>AWAY_DRBC_opp_L20</th>\n",
       "      <th>AWAY_RBC_opp_L20</th>\n",
       "      <th>AWAY_TCHS_opp_L20</th>\n",
       "      <th>AWAY_SAST_opp_L20</th>\n",
       "      <th>AWAY_FTAST_opp_L20</th>\n",
       "      <th>AWAY_PASS_opp_L20</th>\n",
       "      <th>AWAY_CFGM_opp_L20</th>\n",
       "      <th>AWAY_CFGA_opp_L20</th>\n",
       "      <th>AWAY_UFGM_opp_L20</th>\n",
       "      <th>AWAY_UFGA_opp_L20</th>\n",
       "      <th>AWAY_DFGM_opp_L20</th>\n",
       "      <th>AWAY_DFGA_opp_L20</th>\n",
       "      <th>AWAY_PTS_2PT_MR_opp_L20</th>\n",
       "      <th>AWAY_PTS_FB_opp_L20</th>\n",
       "      <th>AWAY_PTS_OFF_TOV_opp_L20</th>\n",
       "      <th>AWAY_PTS_PAINT_opp_L20</th>\n",
       "      <th>AWAY_AST_2PM_opp_L20</th>\n",
       "      <th>AWAY_AST_3PM_opp_L20</th>\n",
       "      <th>AWAY_UAST_2PM_opp_L20</th>\n",
       "      <th>AWAY_UAST_3PM_opp_L20</th>\n",
       "      <th>AWAY_AVG_ATS_DIFF_L20</th>\n",
       "      <th>AWAY_WIN_PCT_L20</th>\n",
       "      <th>AWAY_COVER_PCT_L20</th>\n",
       "      <th>AWAY_OREB_PCT_L20</th>\n",
       "      <th>AWAY_OREB_PCT_opp_L20</th>\n",
       "      <th>AWAY_DREB_PCT_L20</th>\n",
       "      <th>AWAY_DREB_PCT_opp_L20</th>\n",
       "      <th>AWAY_REB_PCT_L20</th>\n",
       "      <th>AWAY_REB_PCT_opp_L20</th>\n",
       "      <th>AWAY_TS_PCT_L20</th>\n",
       "      <th>AWAY_TS_PCT_opp_L20</th>\n",
       "      <th>AWAY_EFG_PCT_L20</th>\n",
       "      <th>AWAY_EFG_PCT_opp_L20</th>\n",
       "      <th>AWAY_AST_RATIO_L20</th>\n",
       "      <th>AWAY_AST_RATIO_opp_L20</th>\n",
       "      <th>AWAY_TOV_PCT_L20</th>\n",
       "      <th>AWAY_TOV_PCT_opp_L20</th>\n",
       "      <th>AWAY_PIE_L20</th>\n",
       "      <th>AWAY_REST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>IND</td>\n",
       "      <td>2013-10-29 00:00:00</td>\n",
       "      <td>0021300001</td>\n",
       "      <td>IND vs. ORL</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>28.723404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.723404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2013-10-29 00:00:00</td>\n",
       "      <td>0021300002</td>\n",
       "      <td>MIA vs. CHI</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>26.395939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.426396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>LAL</td>\n",
       "      <td>2013-10-29 00:00:00</td>\n",
       "      <td>0021300003</td>\n",
       "      <td>LAL vs. LAC</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>1.156250</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>28.426396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.502538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>CLE</td>\n",
       "      <td>2013-10-30 00:00:00</td>\n",
       "      <td>0021300004</td>\n",
       "      <td>CLE vs. BKN</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>32.258065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.806452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2013-10-30 00:00:00</td>\n",
       "      <td>0021300005</td>\n",
       "      <td>PHI vs. MIA</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>1.125786</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>34.482759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.682572</td>\n",
       "      <td>0.539405</td>\n",
       "      <td>0.584407</td>\n",
       "      <td>0.463855</td>\n",
       "      <td>26.797908</td>\n",
       "      <td>23.705841</td>\n",
       "      <td>19.091256</td>\n",
       "      <td>16.946129</td>\n",
       "      <td>0.598399</td>\n",
       "      <td>25.986347</td>\n",
       "      <td>52.791878</td>\n",
       "      <td>11.167513</td>\n",
       "      <td>20.304569</td>\n",
       "      <td>22.335025</td>\n",
       "      <td>29.441624</td>\n",
       "      <td>5.076142</td>\n",
       "      <td>35.532995</td>\n",
       "      <td>40.609137</td>\n",
       "      <td>26.395939</td>\n",
       "      <td>10.152284</td>\n",
       "      <td>7.106599</td>\n",
       "      <td>20.304569</td>\n",
       "      <td>21.319797</td>\n",
       "      <td>108.629442</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>108.100000</td>\n",
       "      <td>96.900000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>17.010000</td>\n",
       "      <td>22.335025</td>\n",
       "      <td>74.111675</td>\n",
       "      <td>94.416244</td>\n",
       "      <td>469.035533</td>\n",
       "      <td>3.045685</td>\n",
       "      <td>3.045685</td>\n",
       "      <td>345.177665</td>\n",
       "      <td>11.167513</td>\n",
       "      <td>28.426396</td>\n",
       "      <td>26.395939</td>\n",
       "      <td>44.670051</td>\n",
       "      <td>17.258883</td>\n",
       "      <td>26.395939</td>\n",
       "      <td>17.258883</td>\n",
       "      <td>9.137056</td>\n",
       "      <td>14.213198</td>\n",
       "      <td>34.517766</td>\n",
       "      <td>15.228426</td>\n",
       "      <td>11.167513</td>\n",
       "      <td>10.152284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.426396</td>\n",
       "      <td>57.868020</td>\n",
       "      <td>7.106599</td>\n",
       "      <td>26.395939</td>\n",
       "      <td>18.274112</td>\n",
       "      <td>23.350254</td>\n",
       "      <td>11.167513</td>\n",
       "      <td>30.456853</td>\n",
       "      <td>41.624365</td>\n",
       "      <td>23.350254</td>\n",
       "      <td>11.167513</td>\n",
       "      <td>4.060914</td>\n",
       "      <td>19.289340</td>\n",
       "      <td>27.411168</td>\n",
       "      <td>96.446701</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>96.900000</td>\n",
       "      <td>108.100000</td>\n",
       "      <td>-11.100000</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>17.640000</td>\n",
       "      <td>37.563452</td>\n",
       "      <td>57.868020</td>\n",
       "      <td>88.324873</td>\n",
       "      <td>452.791878</td>\n",
       "      <td>3.045685</td>\n",
       "      <td>3.045685</td>\n",
       "      <td>321.827411</td>\n",
       "      <td>17.258883</td>\n",
       "      <td>35.532995</td>\n",
       "      <td>18.274112</td>\n",
       "      <td>48.730964</td>\n",
       "      <td>11.167513</td>\n",
       "      <td>20.304569</td>\n",
       "      <td>5.076142</td>\n",
       "      <td>17.258883</td>\n",
       "      <td>30.456853</td>\n",
       "      <td>49.746193</td>\n",
       "      <td>15.228426</td>\n",
       "      <td>7.106599</td>\n",
       "      <td>12.182741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.682572</td>\n",
       "      <td>0.539405</td>\n",
       "      <td>0.584674</td>\n",
       "      <td>0.463855</td>\n",
       "      <td>26.797908</td>\n",
       "      <td>23.705841</td>\n",
       "      <td>19.091256</td>\n",
       "      <td>16.946129</td>\n",
       "      <td>0.598445</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11498</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2022-06-05 00:00:00</td>\n",
       "      <td>0042100402</td>\n",
       "      <td>GSW vs. BOS</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>26.971768</td>\n",
       "      <td>51.898323</td>\n",
       "      <td>15.541157</td>\n",
       "      <td>39.226574</td>\n",
       "      <td>15.586635</td>\n",
       "      <td>19.620277</td>\n",
       "      <td>12.070249</td>\n",
       "      <td>35.235072</td>\n",
       "      <td>47.305322</td>\n",
       "      <td>29.670827</td>\n",
       "      <td>6.633065</td>\n",
       "      <td>4.612038</td>\n",
       "      <td>13.578367</td>\n",
       "      <td>20.166314</td>\n",
       "      <td>118.510024</td>\n",
       "      <td>-0.714885</td>\n",
       "      <td>117.943514</td>\n",
       "      <td>119.789634</td>\n",
       "      <td>-1.828789</td>\n",
       "      <td>94.888299</td>\n",
       "      <td>95.333903</td>\n",
       "      <td>16.940859</td>\n",
       "      <td>24.052189</td>\n",
       "      <td>55.136665</td>\n",
       "      <td>76.612428</td>\n",
       "      <td>415.811215</td>\n",
       "      <td>4.469245</td>\n",
       "      <td>2.747346</td>\n",
       "      <td>294.077956</td>\n",
       "      <td>18.685272</td>\n",
       "      <td>37.838453</td>\n",
       "      <td>24.647650</td>\n",
       "      <td>52.563284</td>\n",
       "      <td>12.369350</td>\n",
       "      <td>19.765537</td>\n",
       "      <td>13.259690</td>\n",
       "      <td>11.199072</td>\n",
       "      <td>11.013802</td>\n",
       "      <td>42.526630</td>\n",
       "      <td>17.400146</td>\n",
       "      <td>11.645877</td>\n",
       "      <td>10.079246</td>\n",
       "      <td>3.068551</td>\n",
       "      <td>21.779687</td>\n",
       "      <td>43.277004</td>\n",
       "      <td>19.158878</td>\n",
       "      <td>44.544451</td>\n",
       "      <td>18.181184</td>\n",
       "      <td>23.542364</td>\n",
       "      <td>7.013393</td>\n",
       "      <td>33.011401</td>\n",
       "      <td>40.024794</td>\n",
       "      <td>27.845951</td>\n",
       "      <td>6.575658</td>\n",
       "      <td>5.099944</td>\n",
       "      <td>11.051786</td>\n",
       "      <td>17.359797</td>\n",
       "      <td>119.217191</td>\n",
       "      <td>0.714885</td>\n",
       "      <td>119.789634</td>\n",
       "      <td>117.943514</td>\n",
       "      <td>1.828789</td>\n",
       "      <td>94.888299</td>\n",
       "      <td>94.442696</td>\n",
       "      <td>16.989342</td>\n",
       "      <td>21.022891</td>\n",
       "      <td>51.938057</td>\n",
       "      <td>70.788320</td>\n",
       "      <td>405.703013</td>\n",
       "      <td>4.657281</td>\n",
       "      <td>1.329612</td>\n",
       "      <td>286.507239</td>\n",
       "      <td>11.276352</td>\n",
       "      <td>25.261753</td>\n",
       "      <td>29.662212</td>\n",
       "      <td>62.559701</td>\n",
       "      <td>17.081504</td>\n",
       "      <td>26.904980</td>\n",
       "      <td>6.769602</td>\n",
       "      <td>10.503473</td>\n",
       "      <td>14.761488</td>\n",
       "      <td>35.727067</td>\n",
       "      <td>11.445706</td>\n",
       "      <td>15.651332</td>\n",
       "      <td>9.645340</td>\n",
       "      <td>2.621200</td>\n",
       "      <td>4.197887</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.267742</td>\n",
       "      <td>0.166003</td>\n",
       "      <td>0.833997</td>\n",
       "      <td>0.732258</td>\n",
       "      <td>0.541684</td>\n",
       "      <td>0.458316</td>\n",
       "      <td>0.620853</td>\n",
       "      <td>0.640947</td>\n",
       "      <td>0.551809</td>\n",
       "      <td>0.575235</td>\n",
       "      <td>31.269216</td>\n",
       "      <td>29.346032</td>\n",
       "      <td>11.980610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489492</td>\n",
       "      <td>0.627927</td>\n",
       "      <td>0.545112</td>\n",
       "      <td>0.527472</td>\n",
       "      <td>0.484129</td>\n",
       "      <td>27.838196</td>\n",
       "      <td>22.552520</td>\n",
       "      <td>13.525213</td>\n",
       "      <td>11.777779</td>\n",
       "      <td>0.555738</td>\n",
       "      <td>23.962387</td>\n",
       "      <td>46.402887</td>\n",
       "      <td>14.775180</td>\n",
       "      <td>38.923535</td>\n",
       "      <td>20.189286</td>\n",
       "      <td>24.877337</td>\n",
       "      <td>8.970200</td>\n",
       "      <td>36.641990</td>\n",
       "      <td>45.612190</td>\n",
       "      <td>26.497970</td>\n",
       "      <td>6.566610</td>\n",
       "      <td>6.577763</td>\n",
       "      <td>14.586371</td>\n",
       "      <td>21.496854</td>\n",
       "      <td>114.245445</td>\n",
       "      <td>8.054409</td>\n",
       "      <td>114.333904</td>\n",
       "      <td>105.463006</td>\n",
       "      <td>8.856144</td>\n",
       "      <td>95.765802</td>\n",
       "      <td>95.704049</td>\n",
       "      <td>16.800785</td>\n",
       "      <td>22.896829</td>\n",
       "      <td>61.429673</td>\n",
       "      <td>82.058568</td>\n",
       "      <td>421.383837</td>\n",
       "      <td>3.295900</td>\n",
       "      <td>2.578561</td>\n",
       "      <td>300.197940</td>\n",
       "      <td>15.558230</td>\n",
       "      <td>31.417331</td>\n",
       "      <td>24.074133</td>\n",
       "      <td>53.883772</td>\n",
       "      <td>14.659232</td>\n",
       "      <td>23.774835</td>\n",
       "      <td>7.682811</td>\n",
       "      <td>13.299941</td>\n",
       "      <td>16.335745</td>\n",
       "      <td>41.206341</td>\n",
       "      <td>13.756908</td>\n",
       "      <td>12.064796</td>\n",
       "      <td>10.376416</td>\n",
       "      <td>1.976988</td>\n",
       "      <td>27.316866</td>\n",
       "      <td>55.528020</td>\n",
       "      <td>11.472733</td>\n",
       "      <td>35.644861</td>\n",
       "      <td>16.658099</td>\n",
       "      <td>21.356940</td>\n",
       "      <td>11.347182</td>\n",
       "      <td>32.775430</td>\n",
       "      <td>44.122612</td>\n",
       "      <td>21.405061</td>\n",
       "      <td>7.845549</td>\n",
       "      <td>4.673995</td>\n",
       "      <td>13.497611</td>\n",
       "      <td>21.848666</td>\n",
       "      <td>105.710028</td>\n",
       "      <td>-8.054409</td>\n",
       "      <td>105.463006</td>\n",
       "      <td>114.333904</td>\n",
       "      <td>-8.856144</td>\n",
       "      <td>95.765802</td>\n",
       "      <td>95.991703</td>\n",
       "      <td>17.434882</td>\n",
       "      <td>28.509495</td>\n",
       "      <td>52.058551</td>\n",
       "      <td>78.193547</td>\n",
       "      <td>395.792135</td>\n",
       "      <td>2.515657</td>\n",
       "      <td>1.963284</td>\n",
       "      <td>271.047245</td>\n",
       "      <td>17.457893</td>\n",
       "      <td>37.841285</td>\n",
       "      <td>21.221282</td>\n",
       "      <td>53.105100</td>\n",
       "      <td>14.835099</td>\n",
       "      <td>22.517894</td>\n",
       "      <td>10.959252</td>\n",
       "      <td>12.421262</td>\n",
       "      <td>15.861143</td>\n",
       "      <td>42.825490</td>\n",
       "      <td>11.994308</td>\n",
       "      <td>8.486989</td>\n",
       "      <td>14.526056</td>\n",
       "      <td>2.382018</td>\n",
       "      <td>-5.365054</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.214878</td>\n",
       "      <td>0.236453</td>\n",
       "      <td>0.763547</td>\n",
       "      <td>0.785122</td>\n",
       "      <td>0.508300</td>\n",
       "      <td>0.491700</td>\n",
       "      <td>0.629109</td>\n",
       "      <td>0.551312</td>\n",
       "      <td>0.540573</td>\n",
       "      <td>0.488369</td>\n",
       "      <td>27.669554</td>\n",
       "      <td>22.351466</td>\n",
       "      <td>13.157609</td>\n",
       "      <td>11.832998</td>\n",
       "      <td>0.556072</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2022-06-08 00:00:00</td>\n",
       "      <td>0042100403</td>\n",
       "      <td>BOS vs. GSW</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>24.579412</td>\n",
       "      <td>45.901263</td>\n",
       "      <td>15.408181</td>\n",
       "      <td>38.103140</td>\n",
       "      <td>17.932363</td>\n",
       "      <td>22.292901</td>\n",
       "      <td>7.708010</td>\n",
       "      <td>37.575117</td>\n",
       "      <td>45.283127</td>\n",
       "      <td>26.602889</td>\n",
       "      <td>6.039470</td>\n",
       "      <td>6.781988</td>\n",
       "      <td>16.497772</td>\n",
       "      <td>20.094501</td>\n",
       "      <td>106.149109</td>\n",
       "      <td>-1.609723</td>\n",
       "      <td>106.162270</td>\n",
       "      <td>107.603392</td>\n",
       "      <td>-1.447176</td>\n",
       "      <td>95.628335</td>\n",
       "      <td>95.673230</td>\n",
       "      <td>16.897151</td>\n",
       "      <td>21.451170</td>\n",
       "      <td>61.786106</td>\n",
       "      <td>81.358496</td>\n",
       "      <td>422.347185</td>\n",
       "      <td>3.485767</td>\n",
       "      <td>2.018684</td>\n",
       "      <td>300.427052</td>\n",
       "      <td>13.244140</td>\n",
       "      <td>31.887082</td>\n",
       "      <td>23.160142</td>\n",
       "      <td>52.117312</td>\n",
       "      <td>15.458857</td>\n",
       "      <td>26.176245</td>\n",
       "      <td>6.460567</td>\n",
       "      <td>14.088210</td>\n",
       "      <td>16.923747</td>\n",
       "      <td>34.498502</td>\n",
       "      <td>13.101474</td>\n",
       "      <td>12.928046</td>\n",
       "      <td>7.373006</td>\n",
       "      <td>1.921934</td>\n",
       "      <td>24.989380</td>\n",
       "      <td>51.494783</td>\n",
       "      <td>14.154004</td>\n",
       "      <td>39.404819</td>\n",
       "      <td>15.127795</td>\n",
       "      <td>20.170562</td>\n",
       "      <td>9.855122</td>\n",
       "      <td>33.462082</td>\n",
       "      <td>43.317204</td>\n",
       "      <td>23.183340</td>\n",
       "      <td>10.310402</td>\n",
       "      <td>3.779154</td>\n",
       "      <td>13.292889</td>\n",
       "      <td>19.706759</td>\n",
       "      <td>107.568566</td>\n",
       "      <td>1.609723</td>\n",
       "      <td>107.603392</td>\n",
       "      <td>106.162270</td>\n",
       "      <td>1.447176</td>\n",
       "      <td>95.628335</td>\n",
       "      <td>95.583614</td>\n",
       "      <td>17.258736</td>\n",
       "      <td>25.282173</td>\n",
       "      <td>55.630568</td>\n",
       "      <td>79.505036</td>\n",
       "      <td>400.434731</td>\n",
       "      <td>3.479770</td>\n",
       "      <td>2.338052</td>\n",
       "      <td>276.372694</td>\n",
       "      <td>18.082262</td>\n",
       "      <td>39.166246</td>\n",
       "      <td>20.823451</td>\n",
       "      <td>51.258014</td>\n",
       "      <td>12.674921</td>\n",
       "      <td>21.261160</td>\n",
       "      <td>9.575772</td>\n",
       "      <td>11.474845</td>\n",
       "      <td>20.627931</td>\n",
       "      <td>39.914795</td>\n",
       "      <td>13.038995</td>\n",
       "      <td>9.398855</td>\n",
       "      <td>11.190547</td>\n",
       "      <td>4.351843</td>\n",
       "      <td>0.848461</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.187224</td>\n",
       "      <td>0.207781</td>\n",
       "      <td>0.792219</td>\n",
       "      <td>0.812776</td>\n",
       "      <td>0.511094</td>\n",
       "      <td>0.488906</td>\n",
       "      <td>0.596955</td>\n",
       "      <td>0.564148</td>\n",
       "      <td>0.567728</td>\n",
       "      <td>0.508477</td>\n",
       "      <td>27.819045</td>\n",
       "      <td>24.243170</td>\n",
       "      <td>14.955684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468377</td>\n",
       "      <td>0.617200</td>\n",
       "      <td>0.601372</td>\n",
       "      <td>0.548943</td>\n",
       "      <td>0.535101</td>\n",
       "      <td>29.457899</td>\n",
       "      <td>26.471224</td>\n",
       "      <td>12.444038</td>\n",
       "      <td>11.694736</td>\n",
       "      <td>0.528823</td>\n",
       "      <td>27.642420</td>\n",
       "      <td>51.064582</td>\n",
       "      <td>14.326287</td>\n",
       "      <td>37.221382</td>\n",
       "      <td>15.868365</td>\n",
       "      <td>20.629914</td>\n",
       "      <td>10.228317</td>\n",
       "      <td>36.080545</td>\n",
       "      <td>46.308862</td>\n",
       "      <td>28.282059</td>\n",
       "      <td>7.469030</td>\n",
       "      <td>4.480784</td>\n",
       "      <td>14.486348</td>\n",
       "      <td>21.231081</td>\n",
       "      <td>115.273159</td>\n",
       "      <td>4.634028</td>\n",
       "      <td>115.060475</td>\n",
       "      <td>110.620860</td>\n",
       "      <td>4.441837</td>\n",
       "      <td>97.578041</td>\n",
       "      <td>97.742968</td>\n",
       "      <td>17.395800</td>\n",
       "      <td>22.857268</td>\n",
       "      <td>60.140252</td>\n",
       "      <td>80.739558</td>\n",
       "      <td>412.005477</td>\n",
       "      <td>4.643631</td>\n",
       "      <td>2.773737</td>\n",
       "      <td>290.145669</td>\n",
       "      <td>17.249004</td>\n",
       "      <td>34.245711</td>\n",
       "      <td>25.165336</td>\n",
       "      <td>53.770578</td>\n",
       "      <td>13.145476</td>\n",
       "      <td>21.078780</td>\n",
       "      <td>10.440727</td>\n",
       "      <td>11.574401</td>\n",
       "      <td>15.059731</td>\n",
       "      <td>45.224198</td>\n",
       "      <td>16.760872</td>\n",
       "      <td>10.953325</td>\n",
       "      <td>10.642778</td>\n",
       "      <td>2.729238</td>\n",
       "      <td>22.919904</td>\n",
       "      <td>47.055792</td>\n",
       "      <td>15.466666</td>\n",
       "      <td>40.454812</td>\n",
       "      <td>18.179250</td>\n",
       "      <td>23.783126</td>\n",
       "      <td>8.810788</td>\n",
       "      <td>32.856493</td>\n",
       "      <td>41.667281</td>\n",
       "      <td>24.780244</td>\n",
       "      <td>7.240836</td>\n",
       "      <td>4.689044</td>\n",
       "      <td>12.874578</td>\n",
       "      <td>18.907089</td>\n",
       "      <td>110.419056</td>\n",
       "      <td>-4.634028</td>\n",
       "      <td>110.620860</td>\n",
       "      <td>115.060475</td>\n",
       "      <td>-4.441837</td>\n",
       "      <td>97.578041</td>\n",
       "      <td>97.421335</td>\n",
       "      <td>17.518055</td>\n",
       "      <td>23.887444</td>\n",
       "      <td>51.818061</td>\n",
       "      <td>73.571649</td>\n",
       "      <td>411.485127</td>\n",
       "      <td>4.022259</td>\n",
       "      <td>1.858708</td>\n",
       "      <td>289.891479</td>\n",
       "      <td>14.100236</td>\n",
       "      <td>31.352840</td>\n",
       "      <td>24.279637</td>\n",
       "      <td>56.141779</td>\n",
       "      <td>18.613238</td>\n",
       "      <td>28.097510</td>\n",
       "      <td>6.022375</td>\n",
       "      <td>11.900466</td>\n",
       "      <td>15.754285</td>\n",
       "      <td>38.938603</td>\n",
       "      <td>11.863053</td>\n",
       "      <td>12.385359</td>\n",
       "      <td>10.448648</td>\n",
       "      <td>2.426007</td>\n",
       "      <td>-0.402021</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.237400</td>\n",
       "      <td>0.196269</td>\n",
       "      <td>0.803731</td>\n",
       "      <td>0.762600</td>\n",
       "      <td>0.526380</td>\n",
       "      <td>0.473620</td>\n",
       "      <td>0.620920</td>\n",
       "      <td>0.595297</td>\n",
       "      <td>0.556508</td>\n",
       "      <td>0.527021</td>\n",
       "      <td>28.984041</td>\n",
       "      <td>25.395308</td>\n",
       "      <td>12.951646</td>\n",
       "      <td>11.614440</td>\n",
       "      <td>0.529838</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11500</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2022-06-10 00:00:00</td>\n",
       "      <td>0042100404</td>\n",
       "      <td>BOS vs. GSW</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-10</td>\n",
       "      <td>0</td>\n",
       "      <td>22.983497</td>\n",
       "      <td>49.648461</td>\n",
       "      <td>14.857658</td>\n",
       "      <td>37.747772</td>\n",
       "      <td>17.951381</td>\n",
       "      <td>23.327542</td>\n",
       "      <td>10.429679</td>\n",
       "      <td>36.337556</td>\n",
       "      <td>46.767234</td>\n",
       "      <td>27.611803</td>\n",
       "      <td>6.495449</td>\n",
       "      <td>6.990461</td>\n",
       "      <td>15.231319</td>\n",
       "      <td>19.392807</td>\n",
       "      <td>111.683180</td>\n",
       "      <td>4.260185</td>\n",
       "      <td>111.474847</td>\n",
       "      <td>107.202261</td>\n",
       "      <td>4.268549</td>\n",
       "      <td>95.252223</td>\n",
       "      <td>95.448820</td>\n",
       "      <td>16.781434</td>\n",
       "      <td>22.413655</td>\n",
       "      <td>57.416487</td>\n",
       "      <td>78.577622</td>\n",
       "      <td>431.123873</td>\n",
       "      <td>3.734780</td>\n",
       "      <td>2.403990</td>\n",
       "      <td>306.104807</td>\n",
       "      <td>15.884101</td>\n",
       "      <td>36.072869</td>\n",
       "      <td>23.552970</td>\n",
       "      <td>51.323358</td>\n",
       "      <td>14.891442</td>\n",
       "      <td>25.210971</td>\n",
       "      <td>7.128914</td>\n",
       "      <td>10.450341</td>\n",
       "      <td>17.278971</td>\n",
       "      <td>40.988419</td>\n",
       "      <td>14.730789</td>\n",
       "      <td>12.146034</td>\n",
       "      <td>9.148142</td>\n",
       "      <td>1.986757</td>\n",
       "      <td>24.066994</td>\n",
       "      <td>47.733735</td>\n",
       "      <td>14.727008</td>\n",
       "      <td>40.379227</td>\n",
       "      <td>14.670735</td>\n",
       "      <td>18.738046</td>\n",
       "      <td>8.686484</td>\n",
       "      <td>31.126397</td>\n",
       "      <td>39.812880</td>\n",
       "      <td>23.215701</td>\n",
       "      <td>9.342737</td>\n",
       "      <td>4.283104</td>\n",
       "      <td>14.858399</td>\n",
       "      <td>21.250714</td>\n",
       "      <td>106.985746</td>\n",
       "      <td>-4.260185</td>\n",
       "      <td>107.202261</td>\n",
       "      <td>111.474847</td>\n",
       "      <td>-4.268549</td>\n",
       "      <td>95.252223</td>\n",
       "      <td>95.055743</td>\n",
       "      <td>17.105824</td>\n",
       "      <td>23.556722</td>\n",
       "      <td>50.490925</td>\n",
       "      <td>72.050977</td>\n",
       "      <td>396.762484</td>\n",
       "      <td>3.378048</td>\n",
       "      <td>3.322370</td>\n",
       "      <td>274.548286</td>\n",
       "      <td>16.640379</td>\n",
       "      <td>35.634640</td>\n",
       "      <td>21.995175</td>\n",
       "      <td>52.161427</td>\n",
       "      <td>14.799153</td>\n",
       "      <td>24.050650</td>\n",
       "      <td>12.027587</td>\n",
       "      <td>13.999103</td>\n",
       "      <td>20.453894</td>\n",
       "      <td>35.780939</td>\n",
       "      <td>12.572734</td>\n",
       "      <td>9.793240</td>\n",
       "      <td>10.634968</td>\n",
       "      <td>4.312163</td>\n",
       "      <td>-3.601026</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.250978</td>\n",
       "      <td>0.192930</td>\n",
       "      <td>0.807070</td>\n",
       "      <td>0.749022</td>\n",
       "      <td>0.540161</td>\n",
       "      <td>0.459839</td>\n",
       "      <td>0.603508</td>\n",
       "      <td>0.579961</td>\n",
       "      <td>0.517986</td>\n",
       "      <td>0.523845</td>\n",
       "      <td>28.988093</td>\n",
       "      <td>24.372871</td>\n",
       "      <td>13.491978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491560</td>\n",
       "      <td>0.616828</td>\n",
       "      <td>0.604059</td>\n",
       "      <td>0.558324</td>\n",
       "      <td>0.539198</td>\n",
       "      <td>28.597243</td>\n",
       "      <td>27.342651</td>\n",
       "      <td>13.197450</td>\n",
       "      <td>11.513722</td>\n",
       "      <td>0.508287</td>\n",
       "      <td>27.489967</td>\n",
       "      <td>50.030968</td>\n",
       "      <td>14.473594</td>\n",
       "      <td>37.707731</td>\n",
       "      <td>15.667246</td>\n",
       "      <td>20.176876</td>\n",
       "      <td>9.858878</td>\n",
       "      <td>35.163829</td>\n",
       "      <td>45.022707</td>\n",
       "      <td>27.805713</td>\n",
       "      <td>7.463161</td>\n",
       "      <td>4.557948</td>\n",
       "      <td>14.819974</td>\n",
       "      <td>21.527038</td>\n",
       "      <td>114.372868</td>\n",
       "      <td>2.668883</td>\n",
       "      <td>114.235668</td>\n",
       "      <td>111.714111</td>\n",
       "      <td>2.523567</td>\n",
       "      <td>97.284894</td>\n",
       "      <td>97.386495</td>\n",
       "      <td>17.339057</td>\n",
       "      <td>22.595225</td>\n",
       "      <td>58.242289</td>\n",
       "      <td>78.492253</td>\n",
       "      <td>409.854288</td>\n",
       "      <td>4.503723</td>\n",
       "      <td>3.013477</td>\n",
       "      <td>288.312698</td>\n",
       "      <td>16.916395</td>\n",
       "      <td>33.705303</td>\n",
       "      <td>25.086601</td>\n",
       "      <td>53.789404</td>\n",
       "      <td>13.707585</td>\n",
       "      <td>21.893147</td>\n",
       "      <td>11.058869</td>\n",
       "      <td>12.286136</td>\n",
       "      <td>15.540311</td>\n",
       "      <td>43.537439</td>\n",
       "      <td>16.273190</td>\n",
       "      <td>10.917962</td>\n",
       "      <td>10.536210</td>\n",
       "      <td>2.872435</td>\n",
       "      <td>23.760488</td>\n",
       "      <td>48.016465</td>\n",
       "      <td>15.303804</td>\n",
       "      <td>40.129310</td>\n",
       "      <td>18.161171</td>\n",
       "      <td>23.936812</td>\n",
       "      <td>9.483381</td>\n",
       "      <td>32.952297</td>\n",
       "      <td>42.435678</td>\n",
       "      <td>25.242090</td>\n",
       "      <td>7.256700</td>\n",
       "      <td>4.947936</td>\n",
       "      <td>12.857801</td>\n",
       "      <td>18.819692</td>\n",
       "      <td>111.593558</td>\n",
       "      <td>-2.668883</td>\n",
       "      <td>111.714111</td>\n",
       "      <td>114.235668</td>\n",
       "      <td>-2.523567</td>\n",
       "      <td>97.284894</td>\n",
       "      <td>97.190732</td>\n",
       "      <td>17.425859</td>\n",
       "      <td>23.930414</td>\n",
       "      <td>51.518936</td>\n",
       "      <td>73.518718</td>\n",
       "      <td>415.027234</td>\n",
       "      <td>4.042311</td>\n",
       "      <td>1.984032</td>\n",
       "      <td>292.517082</td>\n",
       "      <td>14.772977</td>\n",
       "      <td>32.599659</td>\n",
       "      <td>24.285255</td>\n",
       "      <td>55.531652</td>\n",
       "      <td>18.150702</td>\n",
       "      <td>27.638740</td>\n",
       "      <td>6.255064</td>\n",
       "      <td>11.069431</td>\n",
       "      <td>15.967155</td>\n",
       "      <td>40.369998</td>\n",
       "      <td>12.446516</td>\n",
       "      <td>12.213612</td>\n",
       "      <td>10.662911</td>\n",
       "      <td>2.396521</td>\n",
       "      <td>0.829903</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.230287</td>\n",
       "      <td>0.212407</td>\n",
       "      <td>0.787593</td>\n",
       "      <td>0.769713</td>\n",
       "      <td>0.514790</td>\n",
       "      <td>0.485210</td>\n",
       "      <td>0.620394</td>\n",
       "      <td>0.597320</td>\n",
       "      <td>0.560760</td>\n",
       "      <td>0.529988</td>\n",
       "      <td>28.581737</td>\n",
       "      <td>25.946567</td>\n",
       "      <td>13.299030</td>\n",
       "      <td>11.527961</td>\n",
       "      <td>0.518848</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11501</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2022-06-13 00:00:00</td>\n",
       "      <td>0042100405</td>\n",
       "      <td>GSW vs. BOS</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>28.011024</td>\n",
       "      <td>48.425262</td>\n",
       "      <td>15.619660</td>\n",
       "      <td>41.581508</td>\n",
       "      <td>13.969209</td>\n",
       "      <td>17.588022</td>\n",
       "      <td>11.454541</td>\n",
       "      <td>35.330668</td>\n",
       "      <td>46.785210</td>\n",
       "      <td>24.707898</td>\n",
       "      <td>9.362868</td>\n",
       "      <td>4.582314</td>\n",
       "      <td>15.399786</td>\n",
       "      <td>21.258550</td>\n",
       "      <td>112.040748</td>\n",
       "      <td>2.380775</td>\n",
       "      <td>112.098078</td>\n",
       "      <td>109.596929</td>\n",
       "      <td>2.472951</td>\n",
       "      <td>95.559496</td>\n",
       "      <td>95.506342</td>\n",
       "      <td>17.073958</td>\n",
       "      <td>24.507640</td>\n",
       "      <td>55.678693</td>\n",
       "      <td>77.675813</td>\n",
       "      <td>398.361855</td>\n",
       "      <td>3.831089</td>\n",
       "      <td>3.292039</td>\n",
       "      <td>273.515834</td>\n",
       "      <td>18.272889</td>\n",
       "      <td>36.377077</td>\n",
       "      <td>22.846918</td>\n",
       "      <td>53.415424</td>\n",
       "      <td>13.583932</td>\n",
       "      <td>21.881701</td>\n",
       "      <td>12.726309</td>\n",
       "      <td>12.000241</td>\n",
       "      <td>19.190829</td>\n",
       "      <td>37.639628</td>\n",
       "      <td>13.645684</td>\n",
       "      <td>10.641932</td>\n",
       "      <td>11.374807</td>\n",
       "      <td>4.150393</td>\n",
       "      <td>22.384339</td>\n",
       "      <td>48.374386</td>\n",
       "      <td>16.221265</td>\n",
       "      <td>40.245285</td>\n",
       "      <td>16.221086</td>\n",
       "      <td>21.799572</td>\n",
       "      <td>10.336505</td>\n",
       "      <td>33.692062</td>\n",
       "      <td>44.028567</td>\n",
       "      <td>26.120627</td>\n",
       "      <td>7.131946</td>\n",
       "      <td>6.304146</td>\n",
       "      <td>14.539018</td>\n",
       "      <td>17.779113</td>\n",
       "      <td>109.653560</td>\n",
       "      <td>-2.380775</td>\n",
       "      <td>109.596929</td>\n",
       "      <td>112.098078</td>\n",
       "      <td>-2.472951</td>\n",
       "      <td>95.559496</td>\n",
       "      <td>95.612651</td>\n",
       "      <td>16.917953</td>\n",
       "      <td>22.510689</td>\n",
       "      <td>53.269967</td>\n",
       "      <td>74.984967</td>\n",
       "      <td>427.242822</td>\n",
       "      <td>3.275568</td>\n",
       "      <td>2.293040</td>\n",
       "      <td>303.408450</td>\n",
       "      <td>13.383170</td>\n",
       "      <td>32.249921</td>\n",
       "      <td>25.222434</td>\n",
       "      <td>56.369750</td>\n",
       "      <td>15.714366</td>\n",
       "      <td>25.841736</td>\n",
       "      <td>6.730122</td>\n",
       "      <td>10.306805</td>\n",
       "      <td>16.054234</td>\n",
       "      <td>37.336578</td>\n",
       "      <td>11.642886</td>\n",
       "      <td>13.326240</td>\n",
       "      <td>9.955033</td>\n",
       "      <td>2.050026</td>\n",
       "      <td>-2.645070</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.253719</td>\n",
       "      <td>0.226344</td>\n",
       "      <td>0.773656</td>\n",
       "      <td>0.746281</td>\n",
       "      <td>0.515177</td>\n",
       "      <td>0.484823</td>\n",
       "      <td>0.596748</td>\n",
       "      <td>0.586913</td>\n",
       "      <td>0.571518</td>\n",
       "      <td>0.527154</td>\n",
       "      <td>25.856037</td>\n",
       "      <td>27.334412</td>\n",
       "      <td>13.610630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493275</td>\n",
       "      <td>0.598628</td>\n",
       "      <td>0.564292</td>\n",
       "      <td>0.522007</td>\n",
       "      <td>0.507993</td>\n",
       "      <td>27.308562</td>\n",
       "      <td>23.169220</td>\n",
       "      <td>13.807612</td>\n",
       "      <td>12.848721</td>\n",
       "      <td>0.525644</td>\n",
       "      <td>23.881298</td>\n",
       "      <td>47.392366</td>\n",
       "      <td>14.815860</td>\n",
       "      <td>38.747819</td>\n",
       "      <td>18.931329</td>\n",
       "      <td>23.857606</td>\n",
       "      <td>9.582399</td>\n",
       "      <td>36.090040</td>\n",
       "      <td>45.672438</td>\n",
       "      <td>26.279973</td>\n",
       "      <td>6.695179</td>\n",
       "      <td>6.664947</td>\n",
       "      <td>15.003887</td>\n",
       "      <td>20.597177</td>\n",
       "      <td>111.850658</td>\n",
       "      <td>4.910397</td>\n",
       "      <td>111.820499</td>\n",
       "      <td>106.495795</td>\n",
       "      <td>5.323301</td>\n",
       "      <td>95.814236</td>\n",
       "      <td>95.850564</td>\n",
       "      <td>16.833608</td>\n",
       "      <td>22.856340</td>\n",
       "      <td>59.506916</td>\n",
       "      <td>80.603590</td>\n",
       "      <td>424.863530</td>\n",
       "      <td>3.224831</td>\n",
       "      <td>2.560894</td>\n",
       "      <td>302.421058</td>\n",
       "      <td>15.237465</td>\n",
       "      <td>32.594815</td>\n",
       "      <td>23.808250</td>\n",
       "      <td>53.526619</td>\n",
       "      <td>14.870660</td>\n",
       "      <td>24.374961</td>\n",
       "      <td>7.414644</td>\n",
       "      <td>12.453088</td>\n",
       "      <td>16.355643</td>\n",
       "      <td>40.262743</td>\n",
       "      <td>13.392894</td>\n",
       "      <td>12.096619</td>\n",
       "      <td>10.110459</td>\n",
       "      <td>1.985675</td>\n",
       "      <td>26.545813</td>\n",
       "      <td>53.270782</td>\n",
       "      <td>12.552325</td>\n",
       "      <td>37.271472</td>\n",
       "      <td>15.832832</td>\n",
       "      <td>20.272695</td>\n",
       "      <td>11.018256</td>\n",
       "      <td>33.301749</td>\n",
       "      <td>44.320005</td>\n",
       "      <td>21.842448</td>\n",
       "      <td>8.640419</td>\n",
       "      <td>4.573581</td>\n",
       "      <td>14.093707</td>\n",
       "      <td>21.721703</td>\n",
       "      <td>106.581433</td>\n",
       "      <td>-4.910397</td>\n",
       "      <td>106.495795</td>\n",
       "      <td>111.820499</td>\n",
       "      <td>-5.323301</td>\n",
       "      <td>95.814236</td>\n",
       "      <td>95.899481</td>\n",
       "      <td>17.361150</td>\n",
       "      <td>27.304485</td>\n",
       "      <td>53.011100</td>\n",
       "      <td>77.985786</td>\n",
       "      <td>394.800458</td>\n",
       "      <td>2.834148</td>\n",
       "      <td>2.428241</td>\n",
       "      <td>269.862703</td>\n",
       "      <td>17.538678</td>\n",
       "      <td>37.216807</td>\n",
       "      <td>21.477676</td>\n",
       "      <td>53.157696</td>\n",
       "      <td>14.618732</td>\n",
       "      <td>22.695492</td>\n",
       "      <td>11.306659</td>\n",
       "      <td>12.514099</td>\n",
       "      <td>17.923408</td>\n",
       "      <td>40.957765</td>\n",
       "      <td>12.157818</td>\n",
       "      <td>8.909277</td>\n",
       "      <td>13.626936</td>\n",
       "      <td>3.005520</td>\n",
       "      <td>-2.661114</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.223449</td>\n",
       "      <td>0.233892</td>\n",
       "      <td>0.766108</td>\n",
       "      <td>0.776551</td>\n",
       "      <td>0.507514</td>\n",
       "      <td>0.492486</td>\n",
       "      <td>0.611949</td>\n",
       "      <td>0.560942</td>\n",
       "      <td>0.535233</td>\n",
       "      <td>0.501140</td>\n",
       "      <td>27.428046</td>\n",
       "      <td>22.796663</td>\n",
       "      <td>13.439355</td>\n",
       "      <td>12.411245</td>\n",
       "      <td>0.538944</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11502</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2022-06-16 00:00:00</td>\n",
       "      <td>0042100406</td>\n",
       "      <td>BOS vs. GSW</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-13</td>\n",
       "      <td>0</td>\n",
       "      <td>22.972936</td>\n",
       "      <td>47.646467</td>\n",
       "      <td>13.836310</td>\n",
       "      <td>36.513255</td>\n",
       "      <td>18.398620</td>\n",
       "      <td>25.364235</td>\n",
       "      <td>9.916752</td>\n",
       "      <td>36.659284</td>\n",
       "      <td>46.576036</td>\n",
       "      <td>23.518351</td>\n",
       "      <td>5.422479</td>\n",
       "      <td>5.179521</td>\n",
       "      <td>16.627025</td>\n",
       "      <td>18.024296</td>\n",
       "      <td>104.227425</td>\n",
       "      <td>-3.662140</td>\n",
       "      <td>103.955487</td>\n",
       "      <td>108.156561</td>\n",
       "      <td>-4.180645</td>\n",
       "      <td>96.167655</td>\n",
       "      <td>96.421698</td>\n",
       "      <td>16.898415</td>\n",
       "      <td>21.097664</td>\n",
       "      <td>57.616017</td>\n",
       "      <td>78.157006</td>\n",
       "      <td>424.327847</td>\n",
       "      <td>2.233264</td>\n",
       "      <td>2.446645</td>\n",
       "      <td>300.765242</td>\n",
       "      <td>13.708461</td>\n",
       "      <td>31.744637</td>\n",
       "      <td>22.287787</td>\n",
       "      <td>52.415082</td>\n",
       "      <td>14.645484</td>\n",
       "      <td>24.050318</td>\n",
       "      <td>5.924817</td>\n",
       "      <td>10.047018</td>\n",
       "      <td>14.460169</td>\n",
       "      <td>37.932175</td>\n",
       "      <td>11.586191</td>\n",
       "      <td>10.800659</td>\n",
       "      <td>10.030940</td>\n",
       "      <td>2.140126</td>\n",
       "      <td>27.423650</td>\n",
       "      <td>48.736361</td>\n",
       "      <td>13.094482</td>\n",
       "      <td>41.575240</td>\n",
       "      <td>13.742549</td>\n",
       "      <td>16.928448</td>\n",
       "      <td>8.931884</td>\n",
       "      <td>34.827544</td>\n",
       "      <td>43.759428</td>\n",
       "      <td>22.810967</td>\n",
       "      <td>9.544066</td>\n",
       "      <td>3.744770</td>\n",
       "      <td>12.700599</td>\n",
       "      <td>23.878522</td>\n",
       "      <td>107.873295</td>\n",
       "      <td>3.662140</td>\n",
       "      <td>108.156561</td>\n",
       "      <td>103.955487</td>\n",
       "      <td>4.180645</td>\n",
       "      <td>96.167655</td>\n",
       "      <td>95.913664</td>\n",
       "      <td>17.285922</td>\n",
       "      <td>23.788743</td>\n",
       "      <td>54.107078</td>\n",
       "      <td>74.946445</td>\n",
       "      <td>392.254124</td>\n",
       "      <td>2.537679</td>\n",
       "      <td>2.623333</td>\n",
       "      <td>269.795677</td>\n",
       "      <td>18.521080</td>\n",
       "      <td>34.890324</td>\n",
       "      <td>21.926631</td>\n",
       "      <td>55.280435</td>\n",
       "      <td>14.141504</td>\n",
       "      <td>23.060973</td>\n",
       "      <td>12.678215</td>\n",
       "      <td>11.834359</td>\n",
       "      <td>21.010135</td>\n",
       "      <td>41.561471</td>\n",
       "      <td>13.372782</td>\n",
       "      <td>9.060528</td>\n",
       "      <td>13.668960</td>\n",
       "      <td>3.184323</td>\n",
       "      <td>3.510655</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.221632</td>\n",
       "      <td>0.195913</td>\n",
       "      <td>0.804087</td>\n",
       "      <td>0.778368</td>\n",
       "      <td>0.515590</td>\n",
       "      <td>0.484410</td>\n",
       "      <td>0.580720</td>\n",
       "      <td>0.573575</td>\n",
       "      <td>0.519576</td>\n",
       "      <td>0.521144</td>\n",
       "      <td>24.455573</td>\n",
       "      <td>23.719999</td>\n",
       "      <td>14.852585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491570</td>\n",
       "      <td>0.600472</td>\n",
       "      <td>0.590027</td>\n",
       "      <td>0.530883</td>\n",
       "      <td>0.522876</td>\n",
       "      <td>26.767138</td>\n",
       "      <td>25.283521</td>\n",
       "      <td>12.261739</td>\n",
       "      <td>12.946894</td>\n",
       "      <td>0.519518</td>\n",
       "      <td>27.266516</td>\n",
       "      <td>49.952090</td>\n",
       "      <td>14.073492</td>\n",
       "      <td>38.634129</td>\n",
       "      <td>15.172054</td>\n",
       "      <td>19.328245</td>\n",
       "      <td>9.897270</td>\n",
       "      <td>35.704273</td>\n",
       "      <td>45.601543</td>\n",
       "      <td>26.803398</td>\n",
       "      <td>7.886002</td>\n",
       "      <td>4.375260</td>\n",
       "      <td>14.251434</td>\n",
       "      <td>22.241869</td>\n",
       "      <td>113.387805</td>\n",
       "      <td>3.998791</td>\n",
       "      <td>113.329878</td>\n",
       "      <td>109.284794</td>\n",
       "      <td>4.038112</td>\n",
       "      <td>97.194664</td>\n",
       "      <td>97.230214</td>\n",
       "      <td>17.350113</td>\n",
       "      <td>22.963147</td>\n",
       "      <td>58.141647</td>\n",
       "      <td>78.524983</td>\n",
       "      <td>406.004842</td>\n",
       "      <td>4.053676</td>\n",
       "      <td>2.841691</td>\n",
       "      <td>284.066557</td>\n",
       "      <td>17.498746</td>\n",
       "      <td>33.932174</td>\n",
       "      <td>24.479869</td>\n",
       "      <td>54.454316</td>\n",
       "      <td>13.665567</td>\n",
       "      <td>21.881570</td>\n",
       "      <td>11.407585</td>\n",
       "      <td>11.849905</td>\n",
       "      <td>16.575574</td>\n",
       "      <td>43.844546</td>\n",
       "      <td>15.781600</td>\n",
       "      <td>10.518721</td>\n",
       "      <td>11.534133</td>\n",
       "      <td>2.808071</td>\n",
       "      <td>23.109201</td>\n",
       "      <td>47.724871</td>\n",
       "      <td>14.948457</td>\n",
       "      <td>39.386188</td>\n",
       "      <td>18.174523</td>\n",
       "      <td>24.328020</td>\n",
       "      <td>9.531820</td>\n",
       "      <td>33.566581</td>\n",
       "      <td>43.098402</td>\n",
       "      <td>24.395947</td>\n",
       "      <td>6.853717</td>\n",
       "      <td>4.784260</td>\n",
       "      <td>13.719691</td>\n",
       "      <td>18.494458</td>\n",
       "      <td>109.238296</td>\n",
       "      <td>-3.998791</td>\n",
       "      <td>109.284794</td>\n",
       "      <td>113.329878</td>\n",
       "      <td>-4.038112</td>\n",
       "      <td>97.194664</td>\n",
       "      <td>97.165202</td>\n",
       "      <td>17.344841</td>\n",
       "      <td>23.314294</td>\n",
       "      <td>52.595724</td>\n",
       "      <td>74.329614</td>\n",
       "      <td>416.126500</td>\n",
       "      <td>3.496450</td>\n",
       "      <td>2.088751</td>\n",
       "      <td>293.625022</td>\n",
       "      <td>14.252573</td>\n",
       "      <td>31.836479</td>\n",
       "      <td>23.800125</td>\n",
       "      <td>55.262741</td>\n",
       "      <td>17.482193</td>\n",
       "      <td>26.838309</td>\n",
       "      <td>6.049628</td>\n",
       "      <td>10.911988</td>\n",
       "      <td>15.385870</td>\n",
       "      <td>39.435386</td>\n",
       "      <td>11.793753</td>\n",
       "      <td>11.848607</td>\n",
       "      <td>10.692737</td>\n",
       "      <td>2.344576</td>\n",
       "      <td>-1.102482</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.227713</td>\n",
       "      <td>0.210713</td>\n",
       "      <td>0.789287</td>\n",
       "      <td>0.772287</td>\n",
       "      <td>0.514110</td>\n",
       "      <td>0.485890</td>\n",
       "      <td>0.610673</td>\n",
       "      <td>0.590712</td>\n",
       "      <td>0.546098</td>\n",
       "      <td>0.522688</td>\n",
       "      <td>27.577026</td>\n",
       "      <td>25.100089</td>\n",
       "      <td>12.799683</td>\n",
       "      <td>12.300786</td>\n",
       "      <td>0.523450</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11503 rows × 640 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SEASON HOME_TEAM_ABBREVIATION            GAME_DATE     GAME_ID  \\\n",
       "0      2013-14                    IND  2013-10-29 00:00:00  0021300001   \n",
       "1      2013-14                    MIA  2013-10-29 00:00:00  0021300002   \n",
       "2      2013-14                    LAL  2013-10-29 00:00:00  0021300003   \n",
       "3      2013-14                    CLE  2013-10-30 00:00:00  0021300004   \n",
       "4      2013-14                    PHI  2013-10-30 00:00:00  0021300005   \n",
       "...        ...                    ...                  ...         ...   \n",
       "11498  2021-22                    GSW  2022-06-05 00:00:00  0042100402   \n",
       "11499  2021-22                    BOS  2022-06-08 00:00:00  0042100403   \n",
       "11500  2021-22                    BOS  2022-06-10 00:00:00  0042100404   \n",
       "11501  2021-22                    GSW  2022-06-13 00:00:00  0042100405   \n",
       "11502  2021-22                    BOS  2022-06-16 00:00:00  0042100406   \n",
       "\n",
       "           MATCHUP  HOME_HOME_GAME  HOME_TEAM_SCORE   HOME_ML  HOME_SPREAD  \\\n",
       "0      IND vs. ORL               1               97  8.600000         12.5   \n",
       "1      MIA vs. CHI               1              107  2.850000          5.0   \n",
       "2      LAL vs. LAC               1              116  1.156250        -10.0   \n",
       "3      CLE vs. BKN               1               98  1.625000         -3.5   \n",
       "4      PHI vs. MIA               1              114  1.125786        -10.0   \n",
       "...            ...             ...              ...       ...          ...   \n",
       "11498  GSW vs. BOS               1              107  2.700000          5.5   \n",
       "11499  BOS vs. GSW               1              116  2.350000          3.5   \n",
       "11500  BOS vs. GSW               1               97  2.400000          4.0   \n",
       "11501  GSW vs. BOS               1              104  2.500000          4.0   \n",
       "11502  BOS vs. GSW               1               90  2.500000          4.0   \n",
       "\n",
       "       HOME_ATS_DIFF  HOME_TEAM_COVERED  HOME_POINT_DIFF  HOME_WL  \\\n",
       "0                2.5                  1               10        1   \n",
       "1               -7.0                  0               12        1   \n",
       "2              -23.0                  0               13        1   \n",
       "3               -7.5                  0                4        1   \n",
       "4              -14.0                  0                4        1   \n",
       "...              ...                ...              ...      ...   \n",
       "11498          -13.5                  0               19        1   \n",
       "11499          -12.5                  0               16        1   \n",
       "11500           14.0                  1              -10        0   \n",
       "11501           -6.0                  0               10        1   \n",
       "11502           17.0                  1              -13        0   \n",
       "\n",
       "       HOME_FG2M_L5  HOME_FG2A_L5  HOME_FG3M_L5  HOME_FG3A_L5  HOME_FTM_L5  \\\n",
       "0         28.723404           NaN           NaN           NaN          NaN   \n",
       "1         26.395939           NaN           NaN           NaN          NaN   \n",
       "2         28.426396           NaN           NaN           NaN          NaN   \n",
       "3         32.258065           NaN           NaN           NaN          NaN   \n",
       "4         34.482759           NaN           NaN           NaN          NaN   \n",
       "...             ...           ...           ...           ...          ...   \n",
       "11498     26.971768     51.898323     15.541157     39.226574    15.586635   \n",
       "11499     24.579412     45.901263     15.408181     38.103140    17.932363   \n",
       "11500     22.983497     49.648461     14.857658     37.747772    17.951381   \n",
       "11501     28.011024     48.425262     15.619660     41.581508    13.969209   \n",
       "11502     22.972936     47.646467     13.836310     36.513255    18.398620   \n",
       "\n",
       "       HOME_FTA_L5  HOME_OREB_L5  HOME_DREB_L5  HOME_REB_L5  HOME_AST_L5  \\\n",
       "0              NaN           NaN           NaN          NaN          NaN   \n",
       "1              NaN           NaN           NaN          NaN          NaN   \n",
       "2              NaN           NaN           NaN          NaN          NaN   \n",
       "3              NaN           NaN           NaN          NaN          NaN   \n",
       "4              NaN           NaN           NaN          NaN          NaN   \n",
       "...            ...           ...           ...          ...          ...   \n",
       "11498    19.620277     12.070249     35.235072    47.305322    29.670827   \n",
       "11499    22.292901      7.708010     37.575117    45.283127    26.602889   \n",
       "11500    23.327542     10.429679     36.337556    46.767234    27.611803   \n",
       "11501    17.588022     11.454541     35.330668    46.785210    24.707898   \n",
       "11502    25.364235      9.916752     36.659284    46.576036    23.518351   \n",
       "\n",
       "       HOME_STL_L5  HOME_BLK_L5  HOME_TOV_L5  HOME_PF_L5  HOME_PTS_L5  \\\n",
       "0              NaN          NaN          NaN         NaN          NaN   \n",
       "1              NaN          NaN          NaN         NaN          NaN   \n",
       "2              NaN          NaN          NaN         NaN          NaN   \n",
       "3              NaN          NaN          NaN         NaN          NaN   \n",
       "4              NaN          NaN          NaN         NaN          NaN   \n",
       "...            ...          ...          ...         ...          ...   \n",
       "11498     6.633065     4.612038    13.578367   20.166314   118.510024   \n",
       "11499     6.039470     6.781988    16.497772   20.094501   106.149109   \n",
       "11500     6.495449     6.990461    15.231319   19.392807   111.683180   \n",
       "11501     9.362868     4.582314    15.399786   21.258550   112.040748   \n",
       "11502     5.422479     5.179521    16.627025   18.024296   104.227425   \n",
       "\n",
       "       HOME_PLUS_MINUS_L5  HOME_OFF_RATING_L5  HOME_DEF_RATING_L5  \\\n",
       "0                     NaN                 NaN                 NaN   \n",
       "1                     NaN                 NaN                 NaN   \n",
       "2                     NaN                 NaN                 NaN   \n",
       "3                     NaN                 NaN                 NaN   \n",
       "4                     NaN                 NaN                 NaN   \n",
       "...                   ...                 ...                 ...   \n",
       "11498           -0.714885          117.943514          119.789634   \n",
       "11499           -1.609723          106.162270          107.603392   \n",
       "11500            4.260185          111.474847          107.202261   \n",
       "11501            2.380775          112.098078          109.596929   \n",
       "11502           -3.662140          103.955487          108.156561   \n",
       "\n",
       "       HOME_NET_RATING_L5  HOME_PACE_L5  HOME_POSS_L5  HOME_DIST_L5  \\\n",
       "0                     NaN           NaN           NaN           NaN   \n",
       "1                     NaN           NaN           NaN           NaN   \n",
       "2                     NaN           NaN           NaN           NaN   \n",
       "3                     NaN           NaN           NaN           NaN   \n",
       "4                     NaN           NaN           NaN           NaN   \n",
       "...                   ...           ...           ...           ...   \n",
       "11498           -1.828789     94.888299     95.333903     16.940859   \n",
       "11499           -1.447176     95.628335     95.673230     16.897151   \n",
       "11500            4.268549     95.252223     95.448820     16.781434   \n",
       "11501            2.472951     95.559496     95.506342     17.073958   \n",
       "11502           -4.180645     96.167655     96.421698     16.898415   \n",
       "\n",
       "       HOME_ORBC_L5  HOME_DRBC_L5  HOME_RBC_L5  HOME_TCHS_L5  HOME_SAST_L5  \\\n",
       "0               NaN           NaN          NaN           NaN           NaN   \n",
       "1               NaN           NaN          NaN           NaN           NaN   \n",
       "2               NaN           NaN          NaN           NaN           NaN   \n",
       "3               NaN           NaN          NaN           NaN           NaN   \n",
       "4               NaN           NaN          NaN           NaN           NaN   \n",
       "...             ...           ...          ...           ...           ...   \n",
       "11498     24.052189     55.136665    76.612428    415.811215      4.469245   \n",
       "11499     21.451170     61.786106    81.358496    422.347185      3.485767   \n",
       "11500     22.413655     57.416487    78.577622    431.123873      3.734780   \n",
       "11501     24.507640     55.678693    77.675813    398.361855      3.831089   \n",
       "11502     21.097664     57.616017    78.157006    424.327847      2.233264   \n",
       "\n",
       "       HOME_FTAST_L5  HOME_PASS_L5  HOME_CFGM_L5  HOME_CFGA_L5  HOME_UFGM_L5  \\\n",
       "0                NaN           NaN           NaN           NaN           NaN   \n",
       "1                NaN           NaN           NaN           NaN           NaN   \n",
       "2                NaN           NaN           NaN           NaN           NaN   \n",
       "3                NaN           NaN           NaN           NaN           NaN   \n",
       "4                NaN           NaN           NaN           NaN           NaN   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "11498       2.747346    294.077956     18.685272     37.838453     24.647650   \n",
       "11499       2.018684    300.427052     13.244140     31.887082     23.160142   \n",
       "11500       2.403990    306.104807     15.884101     36.072869     23.552970   \n",
       "11501       3.292039    273.515834     18.272889     36.377077     22.846918   \n",
       "11502       2.446645    300.765242     13.708461     31.744637     22.287787   \n",
       "\n",
       "       HOME_UFGA_L5  HOME_DFGM_L5  HOME_DFGA_L5  HOME_PTS_2PT_MR_L5  \\\n",
       "0               NaN           NaN           NaN                 NaN   \n",
       "1               NaN           NaN           NaN                 NaN   \n",
       "2               NaN           NaN           NaN                 NaN   \n",
       "3               NaN           NaN           NaN                 NaN   \n",
       "4               NaN           NaN           NaN                 NaN   \n",
       "...             ...           ...           ...                 ...   \n",
       "11498     52.563284     12.369350     19.765537           13.259690   \n",
       "11499     52.117312     15.458857     26.176245            6.460567   \n",
       "11500     51.323358     14.891442     25.210971            7.128914   \n",
       "11501     53.415424     13.583932     21.881701           12.726309   \n",
       "11502     52.415082     14.645484     24.050318            5.924817   \n",
       "\n",
       "       HOME_PTS_FB_L5  HOME_PTS_OFF_TOV_L5  HOME_PTS_PAINT_L5  \\\n",
       "0                 NaN                  NaN                NaN   \n",
       "1                 NaN                  NaN                NaN   \n",
       "2                 NaN                  NaN                NaN   \n",
       "3                 NaN                  NaN                NaN   \n",
       "4                 NaN                  NaN                NaN   \n",
       "...               ...                  ...                ...   \n",
       "11498       11.199072            11.013802          42.526630   \n",
       "11499       14.088210            16.923747          34.498502   \n",
       "11500       10.450341            17.278971          40.988419   \n",
       "11501       12.000241            19.190829          37.639628   \n",
       "11502       10.047018            14.460169          37.932175   \n",
       "\n",
       "       HOME_AST_2PM_L5  HOME_AST_3PM_L5  HOME_UAST_2PM_L5  HOME_UAST_3PM_L5  \\\n",
       "0                  NaN              NaN               NaN               NaN   \n",
       "1                  NaN              NaN               NaN               NaN   \n",
       "2                  NaN              NaN               NaN               NaN   \n",
       "3                  NaN              NaN               NaN               NaN   \n",
       "4                  NaN              NaN               NaN               NaN   \n",
       "...                ...              ...               ...               ...   \n",
       "11498        17.400146        11.645877         10.079246          3.068551   \n",
       "11499        13.101474        12.928046          7.373006          1.921934   \n",
       "11500        14.730789        12.146034          9.148142          1.986757   \n",
       "11501        13.645684        10.641932         11.374807          4.150393   \n",
       "11502        11.586191        10.800659         10.030940          2.140126   \n",
       "\n",
       "       HOME_FG2M_opp_L5  HOME_FG2A_opp_L5  HOME_FG3M_opp_L5  HOME_FG3A_opp_L5  \\\n",
       "0                   NaN               NaN               NaN               NaN   \n",
       "1                   NaN               NaN               NaN               NaN   \n",
       "2                   NaN               NaN               NaN               NaN   \n",
       "3                   NaN               NaN               NaN               NaN   \n",
       "4                   NaN               NaN               NaN               NaN   \n",
       "...                 ...               ...               ...               ...   \n",
       "11498         21.779687         43.277004         19.158878         44.544451   \n",
       "11499         24.989380         51.494783         14.154004         39.404819   \n",
       "11500         24.066994         47.733735         14.727008         40.379227   \n",
       "11501         22.384339         48.374386         16.221265         40.245285   \n",
       "11502         27.423650         48.736361         13.094482         41.575240   \n",
       "\n",
       "       HOME_FTM_opp_L5  HOME_FTA_opp_L5  HOME_OREB_opp_L5  HOME_DREB_opp_L5  \\\n",
       "0                  NaN              NaN               NaN               NaN   \n",
       "1                  NaN              NaN               NaN               NaN   \n",
       "2                  NaN              NaN               NaN               NaN   \n",
       "3                  NaN              NaN               NaN               NaN   \n",
       "4                  NaN              NaN               NaN               NaN   \n",
       "...                ...              ...               ...               ...   \n",
       "11498        18.181184        23.542364          7.013393         33.011401   \n",
       "11499        15.127795        20.170562          9.855122         33.462082   \n",
       "11500        14.670735        18.738046          8.686484         31.126397   \n",
       "11501        16.221086        21.799572         10.336505         33.692062   \n",
       "11502        13.742549        16.928448          8.931884         34.827544   \n",
       "\n",
       "       HOME_REB_opp_L5  HOME_AST_opp_L5  HOME_STL_opp_L5  HOME_BLK_opp_L5  \\\n",
       "0                  NaN              NaN              NaN              NaN   \n",
       "1                  NaN              NaN              NaN              NaN   \n",
       "2                  NaN              NaN              NaN              NaN   \n",
       "3                  NaN              NaN              NaN              NaN   \n",
       "4                  NaN              NaN              NaN              NaN   \n",
       "...                ...              ...              ...              ...   \n",
       "11498        40.024794        27.845951         6.575658         5.099944   \n",
       "11499        43.317204        23.183340        10.310402         3.779154   \n",
       "11500        39.812880        23.215701         9.342737         4.283104   \n",
       "11501        44.028567        26.120627         7.131946         6.304146   \n",
       "11502        43.759428        22.810967         9.544066         3.744770   \n",
       "\n",
       "       HOME_TOV_opp_L5  HOME_PF_opp_L5  HOME_PTS_opp_L5  \\\n",
       "0                  NaN             NaN              NaN   \n",
       "1                  NaN             NaN              NaN   \n",
       "2                  NaN             NaN              NaN   \n",
       "3                  NaN             NaN              NaN   \n",
       "4                  NaN             NaN              NaN   \n",
       "...                ...             ...              ...   \n",
       "11498        11.051786       17.359797       119.217191   \n",
       "11499        13.292889       19.706759       107.568566   \n",
       "11500        14.858399       21.250714       106.985746   \n",
       "11501        14.539018       17.779113       109.653560   \n",
       "11502        12.700599       23.878522       107.873295   \n",
       "\n",
       "       HOME_PLUS_MINUS_opp_L5  HOME_OFF_RATING_opp_L5  HOME_DEF_RATING_opp_L5  \\\n",
       "0                         NaN                     NaN                     NaN   \n",
       "1                         NaN                     NaN                     NaN   \n",
       "2                         NaN                     NaN                     NaN   \n",
       "3                         NaN                     NaN                     NaN   \n",
       "4                         NaN                     NaN                     NaN   \n",
       "...                       ...                     ...                     ...   \n",
       "11498                0.714885              119.789634              117.943514   \n",
       "11499                1.609723              107.603392              106.162270   \n",
       "11500               -4.260185              107.202261              111.474847   \n",
       "11501               -2.380775              109.596929              112.098078   \n",
       "11502                3.662140              108.156561              103.955487   \n",
       "\n",
       "       HOME_NET_RATING_opp_L5  HOME_PACE_opp_L5  HOME_POSS_opp_L5  \\\n",
       "0                         NaN               NaN               NaN   \n",
       "1                         NaN               NaN               NaN   \n",
       "2                         NaN               NaN               NaN   \n",
       "3                         NaN               NaN               NaN   \n",
       "4                         NaN               NaN               NaN   \n",
       "...                       ...               ...               ...   \n",
       "11498                1.828789         94.888299         94.442696   \n",
       "11499                1.447176         95.628335         95.583614   \n",
       "11500               -4.268549         95.252223         95.055743   \n",
       "11501               -2.472951         95.559496         95.612651   \n",
       "11502                4.180645         96.167655         95.913664   \n",
       "\n",
       "       HOME_DIST_opp_L5  HOME_ORBC_opp_L5  HOME_DRBC_opp_L5  HOME_RBC_opp_L5  \\\n",
       "0                   NaN               NaN               NaN              NaN   \n",
       "1                   NaN               NaN               NaN              NaN   \n",
       "2                   NaN               NaN               NaN              NaN   \n",
       "3                   NaN               NaN               NaN              NaN   \n",
       "4                   NaN               NaN               NaN              NaN   \n",
       "...                 ...               ...               ...              ...   \n",
       "11498         16.989342         21.022891         51.938057        70.788320   \n",
       "11499         17.258736         25.282173         55.630568        79.505036   \n",
       "11500         17.105824         23.556722         50.490925        72.050977   \n",
       "11501         16.917953         22.510689         53.269967        74.984967   \n",
       "11502         17.285922         23.788743         54.107078        74.946445   \n",
       "\n",
       "       HOME_TCHS_opp_L5  HOME_SAST_opp_L5  HOME_FTAST_opp_L5  \\\n",
       "0                   NaN               NaN                NaN   \n",
       "1                   NaN               NaN                NaN   \n",
       "2                   NaN               NaN                NaN   \n",
       "3                   NaN               NaN                NaN   \n",
       "4                   NaN               NaN                NaN   \n",
       "...                 ...               ...                ...   \n",
       "11498        405.703013          4.657281           1.329612   \n",
       "11499        400.434731          3.479770           2.338052   \n",
       "11500        396.762484          3.378048           3.322370   \n",
       "11501        427.242822          3.275568           2.293040   \n",
       "11502        392.254124          2.537679           2.623333   \n",
       "\n",
       "       HOME_PASS_opp_L5  HOME_CFGM_opp_L5  HOME_CFGA_opp_L5  HOME_UFGM_opp_L5  \\\n",
       "0                   NaN               NaN               NaN               NaN   \n",
       "1                   NaN               NaN               NaN               NaN   \n",
       "2                   NaN               NaN               NaN               NaN   \n",
       "3                   NaN               NaN               NaN               NaN   \n",
       "4                   NaN               NaN               NaN               NaN   \n",
       "...                 ...               ...               ...               ...   \n",
       "11498        286.507239         11.276352         25.261753         29.662212   \n",
       "11499        276.372694         18.082262         39.166246         20.823451   \n",
       "11500        274.548286         16.640379         35.634640         21.995175   \n",
       "11501        303.408450         13.383170         32.249921         25.222434   \n",
       "11502        269.795677         18.521080         34.890324         21.926631   \n",
       "\n",
       "       HOME_UFGA_opp_L5  HOME_DFGM_opp_L5  HOME_DFGA_opp_L5  \\\n",
       "0                   NaN               NaN               NaN   \n",
       "1                   NaN               NaN               NaN   \n",
       "2                   NaN               NaN               NaN   \n",
       "3                   NaN               NaN               NaN   \n",
       "4                   NaN               NaN               NaN   \n",
       "...                 ...               ...               ...   \n",
       "11498         62.559701         17.081504         26.904980   \n",
       "11499         51.258014         12.674921         21.261160   \n",
       "11500         52.161427         14.799153         24.050650   \n",
       "11501         56.369750         15.714366         25.841736   \n",
       "11502         55.280435         14.141504         23.060973   \n",
       "\n",
       "       HOME_PTS_2PT_MR_opp_L5  HOME_PTS_FB_opp_L5  HOME_PTS_OFF_TOV_opp_L5  \\\n",
       "0                         NaN                 NaN                      NaN   \n",
       "1                         NaN                 NaN                      NaN   \n",
       "2                         NaN                 NaN                      NaN   \n",
       "3                         NaN                 NaN                      NaN   \n",
       "4                         NaN                 NaN                      NaN   \n",
       "...                       ...                 ...                      ...   \n",
       "11498                6.769602           10.503473                14.761488   \n",
       "11499                9.575772           11.474845                20.627931   \n",
       "11500               12.027587           13.999103                20.453894   \n",
       "11501                6.730122           10.306805                16.054234   \n",
       "11502               12.678215           11.834359                21.010135   \n",
       "\n",
       "       HOME_PTS_PAINT_opp_L5  HOME_AST_2PM_opp_L5  HOME_AST_3PM_opp_L5  \\\n",
       "0                        NaN                  NaN                  NaN   \n",
       "1                        NaN                  NaN                  NaN   \n",
       "2                        NaN                  NaN                  NaN   \n",
       "3                        NaN                  NaN                  NaN   \n",
       "4                        NaN                  NaN                  NaN   \n",
       "...                      ...                  ...                  ...   \n",
       "11498              35.727067            11.445706            15.651332   \n",
       "11499              39.914795            13.038995             9.398855   \n",
       "11500              35.780939            12.572734             9.793240   \n",
       "11501              37.336578            11.642886            13.326240   \n",
       "11502              41.561471            13.372782             9.060528   \n",
       "\n",
       "       HOME_UAST_2PM_opp_L5  HOME_UAST_3PM_opp_L5  HOME_AVG_ATS_DIFF_L5  \\\n",
       "0                       NaN                   NaN                   NaN   \n",
       "1                       NaN                   NaN                   NaN   \n",
       "2                       NaN                   NaN                   NaN   \n",
       "3                       NaN                   NaN                   NaN   \n",
       "4                       NaN                   NaN                   NaN   \n",
       "...                     ...                   ...                   ...   \n",
       "11498              9.645340              2.621200              4.197887   \n",
       "11499             11.190547              4.351843              0.848461   \n",
       "11500             10.634968              4.312163             -3.601026   \n",
       "11501              9.955033              2.050026             -2.645070   \n",
       "11502             13.668960              3.184323              3.510655   \n",
       "\n",
       "       HOME_WIN_PCT_L5  HOME_COVER_PCT_L5  HOME_OREB_PCT_L5  \\\n",
       "0                  NaN                NaN               NaN   \n",
       "1                  NaN                NaN               NaN   \n",
       "2                  NaN                NaN               NaN   \n",
       "3                  NaN                NaN               NaN   \n",
       "4                  NaN                NaN               NaN   \n",
       "...                ...                ...               ...   \n",
       "11498              0.6                0.4          0.267742   \n",
       "11499              0.6                0.4          0.187224   \n",
       "11500              0.6                0.4          0.250978   \n",
       "11501              0.6                0.4          0.253719   \n",
       "11502              0.4                0.6          0.221632   \n",
       "\n",
       "       HOME_OREB_PCT_opp_L5  HOME_DREB_PCT_L5  HOME_DREB_PCT_opp_L5  \\\n",
       "0                       NaN               NaN                   NaN   \n",
       "1                       NaN               NaN                   NaN   \n",
       "2                       NaN               NaN                   NaN   \n",
       "3                       NaN               NaN                   NaN   \n",
       "4                       NaN               NaN                   NaN   \n",
       "...                     ...               ...                   ...   \n",
       "11498              0.166003          0.833997              0.732258   \n",
       "11499              0.207781          0.792219              0.812776   \n",
       "11500              0.192930          0.807070              0.749022   \n",
       "11501              0.226344          0.773656              0.746281   \n",
       "11502              0.195913          0.804087              0.778368   \n",
       "\n",
       "       HOME_REB_PCT_L5  HOME_REB_PCT_opp_L5  HOME_TS_PCT_L5  \\\n",
       "0                  NaN                  NaN             NaN   \n",
       "1                  NaN                  NaN             NaN   \n",
       "2                  NaN                  NaN             NaN   \n",
       "3                  NaN                  NaN             NaN   \n",
       "4                  NaN                  NaN             NaN   \n",
       "...                ...                  ...             ...   \n",
       "11498         0.541684             0.458316        0.620853   \n",
       "11499         0.511094             0.488906        0.596955   \n",
       "11500         0.540161             0.459839        0.603508   \n",
       "11501         0.515177             0.484823        0.596748   \n",
       "11502         0.515590             0.484410        0.580720   \n",
       "\n",
       "       HOME_TS_PCT_opp_L5  HOME_EFG_PCT_L5  HOME_EFG_PCT_opp_L5  \\\n",
       "0                     NaN              NaN                  NaN   \n",
       "1                     NaN              NaN                  NaN   \n",
       "2                     NaN              NaN                  NaN   \n",
       "3                     NaN              NaN                  NaN   \n",
       "4                     NaN              NaN                  NaN   \n",
       "...                   ...              ...                  ...   \n",
       "11498            0.640947         0.551809             0.575235   \n",
       "11499            0.564148         0.567728             0.508477   \n",
       "11500            0.579961         0.517986             0.523845   \n",
       "11501            0.586913         0.571518             0.527154   \n",
       "11502            0.573575         0.519576             0.521144   \n",
       "\n",
       "       HOME_AST_RATIO_L5  HOME_AST_RATIO_opp_L5  HOME_TOV_PCT_L5  ...  \\\n",
       "0                    NaN                    NaN              NaN  ...   \n",
       "1                    NaN                    NaN              NaN  ...   \n",
       "2                    NaN                    NaN              NaN  ...   \n",
       "3                    NaN                    NaN              NaN  ...   \n",
       "4                    NaN                    NaN              NaN  ...   \n",
       "...                  ...                    ...              ...  ...   \n",
       "11498          31.269216              29.346032        11.980610  ...   \n",
       "11499          27.819045              24.243170        14.955684  ...   \n",
       "11500          28.988093              24.372871        13.491978  ...   \n",
       "11501          25.856037              27.334412        13.610630  ...   \n",
       "11502          24.455573              23.719999        14.852585  ...   \n",
       "\n",
       "       AWAY_REB_PCT_opp_L10  AWAY_TS_PCT_L10  AWAY_TS_PCT_opp_L10  \\\n",
       "0                       NaN              NaN                  NaN   \n",
       "1                       NaN              NaN                  NaN   \n",
       "2                       NaN              NaN                  NaN   \n",
       "3                       NaN              NaN                  NaN   \n",
       "4                  0.506173         0.682572             0.539405   \n",
       "...                     ...              ...                  ...   \n",
       "11498              0.489492         0.627927             0.545112   \n",
       "11499              0.468377         0.617200             0.601372   \n",
       "11500              0.491560         0.616828             0.604059   \n",
       "11501              0.493275         0.598628             0.564292   \n",
       "11502              0.491570         0.600472             0.590027   \n",
       "\n",
       "       AWAY_EFG_PCT_L10  AWAY_EFG_PCT_opp_L10  AWAY_AST_RATIO_L10  \\\n",
       "0                   NaN                   NaN                 NaN   \n",
       "1                   NaN                   NaN                 NaN   \n",
       "2                   NaN                   NaN                 NaN   \n",
       "3                   NaN                   NaN                 NaN   \n",
       "4              0.584407              0.463855           26.797908   \n",
       "...                 ...                   ...                 ...   \n",
       "11498          0.527472              0.484129           27.838196   \n",
       "11499          0.548943              0.535101           29.457899   \n",
       "11500          0.558324              0.539198           28.597243   \n",
       "11501          0.522007              0.507993           27.308562   \n",
       "11502          0.530883              0.522876           26.767138   \n",
       "\n",
       "       AWAY_AST_RATIO_opp_L10  AWAY_TOV_PCT_L10  AWAY_TOV_PCT_opp_L10  \\\n",
       "0                         NaN               NaN                   NaN   \n",
       "1                         NaN               NaN                   NaN   \n",
       "2                         NaN               NaN                   NaN   \n",
       "3                         NaN               NaN                   NaN   \n",
       "4                   23.705841         19.091256             16.946129   \n",
       "...                       ...               ...                   ...   \n",
       "11498               22.552520         13.525213             11.777779   \n",
       "11499               26.471224         12.444038             11.694736   \n",
       "11500               27.342651         13.197450             11.513722   \n",
       "11501               23.169220         13.807612             12.848721   \n",
       "11502               25.283521         12.261739             12.946894   \n",
       "\n",
       "       AWAY_PIE_L10  AWAY_FG2M_L20  AWAY_FG2A_L20  AWAY_FG3M_L20  \\\n",
       "0               NaN      28.723404            NaN            NaN   \n",
       "1               NaN      28.426396            NaN            NaN   \n",
       "2               NaN      33.502538            NaN            NaN   \n",
       "3               NaN      25.806452            NaN            NaN   \n",
       "4          0.598399      25.986347      52.791878      11.167513   \n",
       "...             ...            ...            ...            ...   \n",
       "11498      0.555738      23.962387      46.402887      14.775180   \n",
       "11499      0.528823      27.642420      51.064582      14.326287   \n",
       "11500      0.508287      27.489967      50.030968      14.473594   \n",
       "11501      0.525644      23.881298      47.392366      14.815860   \n",
       "11502      0.519518      27.266516      49.952090      14.073492   \n",
       "\n",
       "       AWAY_FG3A_L20  AWAY_FTM_L20  AWAY_FTA_L20  AWAY_OREB_L20  \\\n",
       "0                NaN           NaN           NaN            NaN   \n",
       "1                NaN           NaN           NaN            NaN   \n",
       "2                NaN           NaN           NaN            NaN   \n",
       "3                NaN           NaN           NaN            NaN   \n",
       "4          20.304569     22.335025     29.441624       5.076142   \n",
       "...              ...           ...           ...            ...   \n",
       "11498      38.923535     20.189286     24.877337       8.970200   \n",
       "11499      37.221382     15.868365     20.629914      10.228317   \n",
       "11500      37.707731     15.667246     20.176876       9.858878   \n",
       "11501      38.747819     18.931329     23.857606       9.582399   \n",
       "11502      38.634129     15.172054     19.328245       9.897270   \n",
       "\n",
       "       AWAY_DREB_L20  AWAY_REB_L20  AWAY_AST_L20  AWAY_STL_L20  AWAY_BLK_L20  \\\n",
       "0                NaN           NaN           NaN           NaN           NaN   \n",
       "1                NaN           NaN           NaN           NaN           NaN   \n",
       "2                NaN           NaN           NaN           NaN           NaN   \n",
       "3                NaN           NaN           NaN           NaN           NaN   \n",
       "4          35.532995     40.609137     26.395939     10.152284      7.106599   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "11498      36.641990     45.612190     26.497970      6.566610      6.577763   \n",
       "11499      36.080545     46.308862     28.282059      7.469030      4.480784   \n",
       "11500      35.163829     45.022707     27.805713      7.463161      4.557948   \n",
       "11501      36.090040     45.672438     26.279973      6.695179      6.664947   \n",
       "11502      35.704273     45.601543     26.803398      7.886002      4.375260   \n",
       "\n",
       "       AWAY_TOV_L20  AWAY_PF_L20  AWAY_PTS_L20  AWAY_PLUS_MINUS_L20  \\\n",
       "0               NaN          NaN           NaN                  NaN   \n",
       "1               NaN          NaN           NaN                  NaN   \n",
       "2               NaN          NaN           NaN                  NaN   \n",
       "3               NaN          NaN           NaN                  NaN   \n",
       "4         20.304569    21.319797    108.629442            12.000000   \n",
       "...             ...          ...           ...                  ...   \n",
       "11498     14.586371    21.496854    114.245445             8.054409   \n",
       "11499     14.486348    21.231081    115.273159             4.634028   \n",
       "11500     14.819974    21.527038    114.372868             2.668883   \n",
       "11501     15.003887    20.597177    111.850658             4.910397   \n",
       "11502     14.251434    22.241869    113.387805             3.998791   \n",
       "\n",
       "       AWAY_OFF_RATING_L20  AWAY_DEF_RATING_L20  AWAY_NET_RATING_L20  \\\n",
       "0                      NaN                  NaN                  NaN   \n",
       "1                      NaN                  NaN                  NaN   \n",
       "2                      NaN                  NaN                  NaN   \n",
       "3                      NaN                  NaN                  NaN   \n",
       "4               108.100000            96.900000            11.100000   \n",
       "...                    ...                  ...                  ...   \n",
       "11498           114.333904           105.463006             8.856144   \n",
       "11499           115.060475           110.620860             4.441837   \n",
       "11500           114.235668           111.714111             2.523567   \n",
       "11501           111.820499           106.495795             5.323301   \n",
       "11502           113.329878           109.284794             4.038112   \n",
       "\n",
       "       AWAY_PACE_L20  AWAY_POSS_L20  AWAY_DIST_L20  AWAY_ORBC_L20  \\\n",
       "0                NaN            NaN            NaN            NaN   \n",
       "1                NaN            NaN            NaN            NaN   \n",
       "2                NaN            NaN            NaN            NaN   \n",
       "3                NaN            NaN            NaN            NaN   \n",
       "4          98.500000      99.000000      17.010000      22.335025   \n",
       "...              ...            ...            ...            ...   \n",
       "11498      95.765802      95.704049      16.800785      22.896829   \n",
       "11499      97.578041      97.742968      17.395800      22.857268   \n",
       "11500      97.284894      97.386495      17.339057      22.595225   \n",
       "11501      95.814236      95.850564      16.833608      22.856340   \n",
       "11502      97.194664      97.230214      17.350113      22.963147   \n",
       "\n",
       "       AWAY_DRBC_L20  AWAY_RBC_L20  AWAY_TCHS_L20  AWAY_SAST_L20  \\\n",
       "0                NaN           NaN            NaN            NaN   \n",
       "1                NaN           NaN            NaN            NaN   \n",
       "2                NaN           NaN            NaN            NaN   \n",
       "3                NaN           NaN            NaN            NaN   \n",
       "4          74.111675     94.416244     469.035533       3.045685   \n",
       "...              ...           ...            ...            ...   \n",
       "11498      61.429673     82.058568     421.383837       3.295900   \n",
       "11499      60.140252     80.739558     412.005477       4.643631   \n",
       "11500      58.242289     78.492253     409.854288       4.503723   \n",
       "11501      59.506916     80.603590     424.863530       3.224831   \n",
       "11502      58.141647     78.524983     406.004842       4.053676   \n",
       "\n",
       "       AWAY_FTAST_L20  AWAY_PASS_L20  AWAY_CFGM_L20  AWAY_CFGA_L20  \\\n",
       "0                 NaN            NaN            NaN            NaN   \n",
       "1                 NaN            NaN            NaN            NaN   \n",
       "2                 NaN            NaN            NaN            NaN   \n",
       "3                 NaN            NaN            NaN            NaN   \n",
       "4            3.045685     345.177665      11.167513      28.426396   \n",
       "...               ...            ...            ...            ...   \n",
       "11498        2.578561     300.197940      15.558230      31.417331   \n",
       "11499        2.773737     290.145669      17.249004      34.245711   \n",
       "11500        3.013477     288.312698      16.916395      33.705303   \n",
       "11501        2.560894     302.421058      15.237465      32.594815   \n",
       "11502        2.841691     284.066557      17.498746      33.932174   \n",
       "\n",
       "       AWAY_UFGM_L20  AWAY_UFGA_L20  AWAY_DFGM_L20  AWAY_DFGA_L20  \\\n",
       "0                NaN            NaN            NaN            NaN   \n",
       "1                NaN            NaN            NaN            NaN   \n",
       "2                NaN            NaN            NaN            NaN   \n",
       "3                NaN            NaN            NaN            NaN   \n",
       "4          26.395939      44.670051      17.258883      26.395939   \n",
       "...              ...            ...            ...            ...   \n",
       "11498      24.074133      53.883772      14.659232      23.774835   \n",
       "11499      25.165336      53.770578      13.145476      21.078780   \n",
       "11500      25.086601      53.789404      13.707585      21.893147   \n",
       "11501      23.808250      53.526619      14.870660      24.374961   \n",
       "11502      24.479869      54.454316      13.665567      21.881570   \n",
       "\n",
       "       AWAY_PTS_2PT_MR_L20  AWAY_PTS_FB_L20  AWAY_PTS_OFF_TOV_L20  \\\n",
       "0                      NaN              NaN                   NaN   \n",
       "1                      NaN              NaN                   NaN   \n",
       "2                      NaN              NaN                   NaN   \n",
       "3                      NaN              NaN                   NaN   \n",
       "4                17.258883         9.137056             14.213198   \n",
       "...                    ...              ...                   ...   \n",
       "11498             7.682811        13.299941             16.335745   \n",
       "11499            10.440727        11.574401             15.059731   \n",
       "11500            11.058869        12.286136             15.540311   \n",
       "11501             7.414644        12.453088             16.355643   \n",
       "11502            11.407585        11.849905             16.575574   \n",
       "\n",
       "       AWAY_PTS_PAINT_L20  AWAY_AST_2PM_L20  AWAY_AST_3PM_L20  \\\n",
       "0                     NaN               NaN               NaN   \n",
       "1                     NaN               NaN               NaN   \n",
       "2                     NaN               NaN               NaN   \n",
       "3                     NaN               NaN               NaN   \n",
       "4               34.517766         15.228426         11.167513   \n",
       "...                   ...               ...               ...   \n",
       "11498           41.206341         13.756908         12.064796   \n",
       "11499           45.224198         16.760872         10.953325   \n",
       "11500           43.537439         16.273190         10.917962   \n",
       "11501           40.262743         13.392894         12.096619   \n",
       "11502           43.844546         15.781600         10.518721   \n",
       "\n",
       "       AWAY_UAST_2PM_L20  AWAY_UAST_3PM_L20  AWAY_FG2M_opp_L20  \\\n",
       "0                    NaN                NaN                NaN   \n",
       "1                    NaN                NaN                NaN   \n",
       "2                    NaN                NaN                NaN   \n",
       "3                    NaN                NaN                NaN   \n",
       "4              10.152284           0.000000          28.426396   \n",
       "...                  ...                ...                ...   \n",
       "11498          10.376416           1.976988          27.316866   \n",
       "11499          10.642778           2.729238          22.919904   \n",
       "11500          10.536210           2.872435          23.760488   \n",
       "11501          10.110459           1.985675          26.545813   \n",
       "11502          11.534133           2.808071          23.109201   \n",
       "\n",
       "       AWAY_FG2A_opp_L20  AWAY_FG3M_opp_L20  AWAY_FG3A_opp_L20  \\\n",
       "0                    NaN                NaN                NaN   \n",
       "1                    NaN                NaN                NaN   \n",
       "2                    NaN                NaN                NaN   \n",
       "3                    NaN                NaN                NaN   \n",
       "4              57.868020           7.106599          26.395939   \n",
       "...                  ...                ...                ...   \n",
       "11498          55.528020          11.472733          35.644861   \n",
       "11499          47.055792          15.466666          40.454812   \n",
       "11500          48.016465          15.303804          40.129310   \n",
       "11501          53.270782          12.552325          37.271472   \n",
       "11502          47.724871          14.948457          39.386188   \n",
       "\n",
       "       AWAY_FTM_opp_L20  AWAY_FTA_opp_L20  AWAY_OREB_opp_L20  \\\n",
       "0                   NaN               NaN                NaN   \n",
       "1                   NaN               NaN                NaN   \n",
       "2                   NaN               NaN                NaN   \n",
       "3                   NaN               NaN                NaN   \n",
       "4             18.274112         23.350254          11.167513   \n",
       "...                 ...               ...                ...   \n",
       "11498         16.658099         21.356940          11.347182   \n",
       "11499         18.179250         23.783126           8.810788   \n",
       "11500         18.161171         23.936812           9.483381   \n",
       "11501         15.832832         20.272695          11.018256   \n",
       "11502         18.174523         24.328020           9.531820   \n",
       "\n",
       "       AWAY_DREB_opp_L20  AWAY_REB_opp_L20  AWAY_AST_opp_L20  \\\n",
       "0                    NaN               NaN               NaN   \n",
       "1                    NaN               NaN               NaN   \n",
       "2                    NaN               NaN               NaN   \n",
       "3                    NaN               NaN               NaN   \n",
       "4              30.456853         41.624365         23.350254   \n",
       "...                  ...               ...               ...   \n",
       "11498          32.775430         44.122612         21.405061   \n",
       "11499          32.856493         41.667281         24.780244   \n",
       "11500          32.952297         42.435678         25.242090   \n",
       "11501          33.301749         44.320005         21.842448   \n",
       "11502          33.566581         43.098402         24.395947   \n",
       "\n",
       "       AWAY_STL_opp_L20  AWAY_BLK_opp_L20  AWAY_TOV_opp_L20  AWAY_PF_opp_L20  \\\n",
       "0                   NaN               NaN               NaN              NaN   \n",
       "1                   NaN               NaN               NaN              NaN   \n",
       "2                   NaN               NaN               NaN              NaN   \n",
       "3                   NaN               NaN               NaN              NaN   \n",
       "4             11.167513          4.060914         19.289340        27.411168   \n",
       "...                 ...               ...               ...              ...   \n",
       "11498          7.845549          4.673995         13.497611        21.848666   \n",
       "11499          7.240836          4.689044         12.874578        18.907089   \n",
       "11500          7.256700          4.947936         12.857801        18.819692   \n",
       "11501          8.640419          4.573581         14.093707        21.721703   \n",
       "11502          6.853717          4.784260         13.719691        18.494458   \n",
       "\n",
       "       AWAY_PTS_opp_L20  AWAY_PLUS_MINUS_opp_L20  AWAY_OFF_RATING_opp_L20  \\\n",
       "0                   NaN                      NaN                      NaN   \n",
       "1                   NaN                      NaN                      NaN   \n",
       "2                   NaN                      NaN                      NaN   \n",
       "3                   NaN                      NaN                      NaN   \n",
       "4             96.446701               -12.000000                96.900000   \n",
       "...                 ...                      ...                      ...   \n",
       "11498        105.710028                -8.054409               105.463006   \n",
       "11499        110.419056                -4.634028               110.620860   \n",
       "11500        111.593558                -2.668883               111.714111   \n",
       "11501        106.581433                -4.910397               106.495795   \n",
       "11502        109.238296                -3.998791               109.284794   \n",
       "\n",
       "       AWAY_DEF_RATING_opp_L20  AWAY_NET_RATING_opp_L20  AWAY_PACE_opp_L20  \\\n",
       "0                          NaN                      NaN                NaN   \n",
       "1                          NaN                      NaN                NaN   \n",
       "2                          NaN                      NaN                NaN   \n",
       "3                          NaN                      NaN                NaN   \n",
       "4                   108.100000               -11.100000          98.500000   \n",
       "...                        ...                      ...                ...   \n",
       "11498               114.333904                -8.856144          95.765802   \n",
       "11499               115.060475                -4.441837          97.578041   \n",
       "11500               114.235668                -2.523567          97.284894   \n",
       "11501               111.820499                -5.323301          95.814236   \n",
       "11502               113.329878                -4.038112          97.194664   \n",
       "\n",
       "       AWAY_POSS_opp_L20  AWAY_DIST_opp_L20  AWAY_ORBC_opp_L20  \\\n",
       "0                    NaN                NaN                NaN   \n",
       "1                    NaN                NaN                NaN   \n",
       "2                    NaN                NaN                NaN   \n",
       "3                    NaN                NaN                NaN   \n",
       "4              98.000000          17.640000          37.563452   \n",
       "...                  ...                ...                ...   \n",
       "11498          95.991703          17.434882          28.509495   \n",
       "11499          97.421335          17.518055          23.887444   \n",
       "11500          97.190732          17.425859          23.930414   \n",
       "11501          95.899481          17.361150          27.304485   \n",
       "11502          97.165202          17.344841          23.314294   \n",
       "\n",
       "       AWAY_DRBC_opp_L20  AWAY_RBC_opp_L20  AWAY_TCHS_opp_L20  \\\n",
       "0                    NaN               NaN                NaN   \n",
       "1                    NaN               NaN                NaN   \n",
       "2                    NaN               NaN                NaN   \n",
       "3                    NaN               NaN                NaN   \n",
       "4              57.868020         88.324873         452.791878   \n",
       "...                  ...               ...                ...   \n",
       "11498          52.058551         78.193547         395.792135   \n",
       "11499          51.818061         73.571649         411.485127   \n",
       "11500          51.518936         73.518718         415.027234   \n",
       "11501          53.011100         77.985786         394.800458   \n",
       "11502          52.595724         74.329614         416.126500   \n",
       "\n",
       "       AWAY_SAST_opp_L20  AWAY_FTAST_opp_L20  AWAY_PASS_opp_L20  \\\n",
       "0                    NaN                 NaN                NaN   \n",
       "1                    NaN                 NaN                NaN   \n",
       "2                    NaN                 NaN                NaN   \n",
       "3                    NaN                 NaN                NaN   \n",
       "4               3.045685            3.045685         321.827411   \n",
       "...                  ...                 ...                ...   \n",
       "11498           2.515657            1.963284         271.047245   \n",
       "11499           4.022259            1.858708         289.891479   \n",
       "11500           4.042311            1.984032         292.517082   \n",
       "11501           2.834148            2.428241         269.862703   \n",
       "11502           3.496450            2.088751         293.625022   \n",
       "\n",
       "       AWAY_CFGM_opp_L20  AWAY_CFGA_opp_L20  AWAY_UFGM_opp_L20  \\\n",
       "0                    NaN                NaN                NaN   \n",
       "1                    NaN                NaN                NaN   \n",
       "2                    NaN                NaN                NaN   \n",
       "3                    NaN                NaN                NaN   \n",
       "4              17.258883          35.532995          18.274112   \n",
       "...                  ...                ...                ...   \n",
       "11498          17.457893          37.841285          21.221282   \n",
       "11499          14.100236          31.352840          24.279637   \n",
       "11500          14.772977          32.599659          24.285255   \n",
       "11501          17.538678          37.216807          21.477676   \n",
       "11502          14.252573          31.836479          23.800125   \n",
       "\n",
       "       AWAY_UFGA_opp_L20  AWAY_DFGM_opp_L20  AWAY_DFGA_opp_L20  \\\n",
       "0                    NaN                NaN                NaN   \n",
       "1                    NaN                NaN                NaN   \n",
       "2                    NaN                NaN                NaN   \n",
       "3                    NaN                NaN                NaN   \n",
       "4              48.730964          11.167513          20.304569   \n",
       "...                  ...                ...                ...   \n",
       "11498          53.105100          14.835099          22.517894   \n",
       "11499          56.141779          18.613238          28.097510   \n",
       "11500          55.531652          18.150702          27.638740   \n",
       "11501          53.157696          14.618732          22.695492   \n",
       "11502          55.262741          17.482193          26.838309   \n",
       "\n",
       "       AWAY_PTS_2PT_MR_opp_L20  AWAY_PTS_FB_opp_L20  AWAY_PTS_OFF_TOV_opp_L20  \\\n",
       "0                          NaN                  NaN                       NaN   \n",
       "1                          NaN                  NaN                       NaN   \n",
       "2                          NaN                  NaN                       NaN   \n",
       "3                          NaN                  NaN                       NaN   \n",
       "4                     5.076142            17.258883                 30.456853   \n",
       "...                        ...                  ...                       ...   \n",
       "11498                10.959252            12.421262                 15.861143   \n",
       "11499                 6.022375            11.900466                 15.754285   \n",
       "11500                 6.255064            11.069431                 15.967155   \n",
       "11501                11.306659            12.514099                 17.923408   \n",
       "11502                 6.049628            10.911988                 15.385870   \n",
       "\n",
       "       AWAY_PTS_PAINT_opp_L20  AWAY_AST_2PM_opp_L20  AWAY_AST_3PM_opp_L20  \\\n",
       "0                         NaN                   NaN                   NaN   \n",
       "1                         NaN                   NaN                   NaN   \n",
       "2                         NaN                   NaN                   NaN   \n",
       "3                         NaN                   NaN                   NaN   \n",
       "4                   49.746193             15.228426              7.106599   \n",
       "...                       ...                   ...                   ...   \n",
       "11498               42.825490             11.994308              8.486989   \n",
       "11499               38.938603             11.863053             12.385359   \n",
       "11500               40.369998             12.446516             12.213612   \n",
       "11501               40.957765             12.157818              8.909277   \n",
       "11502               39.435386             11.793753             11.848607   \n",
       "\n",
       "       AWAY_UAST_2PM_opp_L20  AWAY_UAST_3PM_opp_L20  AWAY_AVG_ATS_DIFF_L20  \\\n",
       "0                        NaN                    NaN                    NaN   \n",
       "1                        NaN                    NaN                    NaN   \n",
       "2                        NaN                    NaN                    NaN   \n",
       "3                        NaN                    NaN                    NaN   \n",
       "4                  12.182741               0.000000              -7.000000   \n",
       "...                      ...                    ...                    ...   \n",
       "11498              14.526056               2.382018              -5.365054   \n",
       "11499              10.448648               2.426007              -0.402021   \n",
       "11500              10.662911               2.396521               0.829903   \n",
       "11501              13.626936               3.005520              -2.661114   \n",
       "11502              10.692737               2.344576              -1.102482   \n",
       "\n",
       "       AWAY_WIN_PCT_L20  AWAY_COVER_PCT_L20  AWAY_OREB_PCT_L20  \\\n",
       "0                   NaN                 NaN                NaN   \n",
       "1                   NaN                 NaN                NaN   \n",
       "2                   NaN                 NaN                NaN   \n",
       "3                   NaN                 NaN                NaN   \n",
       "4                   NaN                 NaN           0.142857   \n",
       "...                 ...                 ...                ...   \n",
       "11498              0.70                0.30           0.214878   \n",
       "11499              0.75                0.45           0.237400   \n",
       "11500              0.70                0.45           0.230287   \n",
       "11501              0.60                0.35           0.223449   \n",
       "11502              0.70                0.45           0.227713   \n",
       "\n",
       "       AWAY_OREB_PCT_opp_L20  AWAY_DREB_PCT_L20  AWAY_DREB_PCT_opp_L20  \\\n",
       "0                        NaN                NaN                    NaN   \n",
       "1                        NaN                NaN                    NaN   \n",
       "2                        NaN                NaN                    NaN   \n",
       "3                        NaN                NaN                    NaN   \n",
       "4                   0.239130           0.760870               0.857143   \n",
       "...                      ...                ...                    ...   \n",
       "11498               0.236453           0.763547               0.785122   \n",
       "11499               0.196269           0.803731               0.762600   \n",
       "11500               0.212407           0.787593               0.769713   \n",
       "11501               0.233892           0.766108               0.776551   \n",
       "11502               0.210713           0.789287               0.772287   \n",
       "\n",
       "       AWAY_REB_PCT_L20  AWAY_REB_PCT_opp_L20  AWAY_TS_PCT_L20  \\\n",
       "0                   NaN                   NaN              NaN   \n",
       "1                   NaN                   NaN              NaN   \n",
       "2                   NaN                   NaN              NaN   \n",
       "3                   NaN                   NaN              NaN   \n",
       "4              0.493827              0.506173         0.682572   \n",
       "...                 ...                   ...              ...   \n",
       "11498          0.508300              0.491700         0.629109   \n",
       "11499          0.526380              0.473620         0.620920   \n",
       "11500          0.514790              0.485210         0.620394   \n",
       "11501          0.507514              0.492486         0.611949   \n",
       "11502          0.514110              0.485890         0.610673   \n",
       "\n",
       "       AWAY_TS_PCT_opp_L20  AWAY_EFG_PCT_L20  AWAY_EFG_PCT_opp_L20  \\\n",
       "0                      NaN               NaN                   NaN   \n",
       "1                      NaN               NaN                   NaN   \n",
       "2                      NaN               NaN                   NaN   \n",
       "3                      NaN               NaN                   NaN   \n",
       "4                 0.539405          0.584674              0.463855   \n",
       "...                    ...               ...                   ...   \n",
       "11498             0.551312          0.540573              0.488369   \n",
       "11499             0.595297          0.556508              0.527021   \n",
       "11500             0.597320          0.560760              0.529988   \n",
       "11501             0.560942          0.535233              0.501140   \n",
       "11502             0.590712          0.546098              0.522688   \n",
       "\n",
       "       AWAY_AST_RATIO_L20  AWAY_AST_RATIO_opp_L20  AWAY_TOV_PCT_L20  \\\n",
       "0                     NaN                     NaN               NaN   \n",
       "1                     NaN                     NaN               NaN   \n",
       "2                     NaN                     NaN               NaN   \n",
       "3                     NaN                     NaN               NaN   \n",
       "4               26.797908               23.705841         19.091256   \n",
       "...                   ...                     ...               ...   \n",
       "11498           27.669554               22.351466         13.157609   \n",
       "11499           28.984041               25.395308         12.951646   \n",
       "11500           28.581737               25.946567         13.299030   \n",
       "11501           27.428046               22.796663         13.439355   \n",
       "11502           27.577026               25.100089         12.799683   \n",
       "\n",
       "       AWAY_TOV_PCT_opp_L20  AWAY_PIE_L20  AWAY_REST  \n",
       "0                       NaN           NaN        NaN  \n",
       "1                       NaN           NaN        NaN  \n",
       "2                       NaN           NaN        NaN  \n",
       "3                       NaN           NaN        NaN  \n",
       "4                 16.946129      0.598445        1.0  \n",
       "...                     ...           ...        ...  \n",
       "11498             11.832998      0.556072        3.0  \n",
       "11499             11.614440      0.529838        3.0  \n",
       "11500             11.527961      0.518848        2.0  \n",
       "11501             12.411245      0.538944        3.0  \n",
       "11502             12.300786      0.523450        3.0  \n",
       "\n",
       "[11503 rows x 640 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2fc2cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7458, 639), (2263, 639), (1234, 639))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('GAME_DATE')\n",
    "\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=['AWAY_ML'])\n",
    "\n",
    "train_df = df.loc[df['SEASON'] < '2019-20']\n",
    "val_df = df.loc[df['SEASON'].between('2019-20', '2020-21')]\n",
    "test_df = df.loc[df['SEASON'] >= '2021-22']\n",
    "\n",
    "\n",
    "X_train = train_df.iloc[:, 13:]\n",
    "y_train = train_df['HOME_WL']\n",
    "\n",
    "X_val = val_df.iloc[:, 13:]\n",
    "y_val = val_df['HOME_WL']\n",
    "\n",
    "X_test = test_df.iloc[:, 13:]\n",
    "y_test = test_df['HOME_WL']\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "77e5564d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON</th>\n",
       "      <th>HOME_TEAM_ABBREVIATION</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>HOME_HOME_GAME</th>\n",
       "      <th>HOME_TEAM_SCORE</th>\n",
       "      <th>HOME_ML</th>\n",
       "      <th>HOME_SPREAD</th>\n",
       "      <th>HOME_ATS_DIFF</th>\n",
       "      <th>HOME_TEAM_COVERED</th>\n",
       "      <th>HOME_POINT_DIFF</th>\n",
       "      <th>HOME_WL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>POR</td>\n",
       "      <td>2013-12-07 00:00:00</td>\n",
       "      <td>0021300298</td>\n",
       "      <td>POR vs. DAL</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>DET</td>\n",
       "      <td>2013-12-08 00:00:00</td>\n",
       "      <td>0021300300</td>\n",
       "      <td>DET vs. MIA</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>1.588235</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>CHA</td>\n",
       "      <td>2013-12-09 00:00:00</td>\n",
       "      <td>0021300304</td>\n",
       "      <td>CHA vs. GSW</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2013-12-09 00:00:00</td>\n",
       "      <td>0021300305</td>\n",
       "      <td>PHI vs. LAC</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>UTA</td>\n",
       "      <td>2013-12-09 00:00:00</td>\n",
       "      <td>0021300308</td>\n",
       "      <td>UTA vs. POR</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>2018-19</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2019-06-02 00:00:00</td>\n",
       "      <td>0041800402</td>\n",
       "      <td>TOR vs. GSW</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7875</th>\n",
       "      <td>2018-19</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2019-06-05 00:00:00</td>\n",
       "      <td>0041800403</td>\n",
       "      <td>GSW vs. TOR</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7876</th>\n",
       "      <td>2018-19</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2019-06-07 00:00:00</td>\n",
       "      <td>0041800404</td>\n",
       "      <td>GSW vs. TOR</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7877</th>\n",
       "      <td>2018-19</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2019-06-10 00:00:00</td>\n",
       "      <td>0041800405</td>\n",
       "      <td>TOR vs. GSW</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7878</th>\n",
       "      <td>2018-19</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2019-06-13 00:00:00</td>\n",
       "      <td>0041800406</td>\n",
       "      <td>GSW vs. TOR</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7458 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEASON HOME_TEAM_ABBREVIATION            GAME_DATE     GAME_ID  \\\n",
       "296   2013-14                    POR  2013-12-07 00:00:00  0021300298   \n",
       "298   2013-14                    DET  2013-12-08 00:00:00  0021300300   \n",
       "302   2013-14                    CHA  2013-12-09 00:00:00  0021300304   \n",
       "303   2013-14                    PHI  2013-12-09 00:00:00  0021300305   \n",
       "306   2013-14                    UTA  2013-12-09 00:00:00  0021300308   \n",
       "...       ...                    ...                  ...         ...   \n",
       "7874  2018-19                    TOR  2019-06-02 00:00:00  0041800402   \n",
       "7875  2018-19                    GSW  2019-06-05 00:00:00  0041800403   \n",
       "7876  2018-19                    GSW  2019-06-07 00:00:00  0041800404   \n",
       "7877  2018-19                    TOR  2019-06-10 00:00:00  0041800405   \n",
       "7878  2018-19                    GSW  2019-06-13 00:00:00  0041800406   \n",
       "\n",
       "          MATCHUP  HOME_HOME_GAME  HOME_TEAM_SCORE   HOME_ML  HOME_SPREAD  \\\n",
       "296   POR vs. DAL               1              106  2.900000          5.5   \n",
       "298   DET vs. MIA               1               95  1.588235         -4.0   \n",
       "302   CHA vs. GSW               1              115  1.400000         -6.0   \n",
       "303   PHI vs. LAC               1               83  1.166667        -10.0   \n",
       "306   UTA vs. POR               1               94  1.312500         -8.0   \n",
       "...           ...             ...              ...       ...          ...   \n",
       "7874  TOR vs. GSW               1              104  2.100000          2.5   \n",
       "7875  GSW vs. TOR               1              109  2.200000          3.0   \n",
       "7876  GSW vs. TOR               1               92  2.950000          5.0   \n",
       "7877  TOR vs. GSW               1              105  3.150000         -1.0   \n",
       "7878  GSW vs. TOR               1              110  2.250000          2.5   \n",
       "\n",
       "      HOME_ATS_DIFF  HOME_TEAM_COVERED  HOME_POINT_DIFF  HOME_WL  \n",
       "296             7.5                  1               -2        0  \n",
       "298            11.0                  1              -15        0  \n",
       "302           -10.0                  0                4        1  \n",
       "303             1.0                  1              -11        0  \n",
       "306             3.0                  1              -11        0  \n",
       "...             ...                ...              ...      ...  \n",
       "7874            7.5                  1               -5        0  \n",
       "7875           17.0                  1              -14        0  \n",
       "7876           18.0                  1              -13        0  \n",
       "7877            0.0                  0               -1        0  \n",
       "7878            6.5                  1               -4        0  \n",
       "\n",
       "[7458 rows x 13 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[:, :13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45d5f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def print_metrics(model, X_train, X_test, y_train, y_test, cv, scoring):\n",
    "    cv_results = cross_validate(model, X_train, y_train, cv=cv, scoring=scoring)\n",
    "    \n",
    "\n",
    "    print(\"Model:\", model)\n",
    "    print(f\"CV Split {str(scoring)}:\", cv_results['test_score'])\n",
    "    print(f\"Mean {str(scoring)}:\", cv_results['test_score'].mean())    \n",
    "    \n",
    "    \n",
    "    return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce84f7a7-8b86-421e-b4a2-100d833accc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('lr', LogisticRegression(max_iter=10000))])\n",
      "CV Split accuracy: [0.64360418 0.69670153 0.67015286 0.66452132 0.68543846]\n",
      "Mean accuracy: 0.6720836685438455\n"
     ]
    }
   ],
   "source": [
    "lr_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('lr', LogisticRegression(max_iter=10000))])\n",
    "          \n",
    "print_metrics(lr_pipe, X_train, X_val, y_train, y_val, cv=TimeSeriesSplit(5), scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "433a439a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>AWAY_AST_opp_L5</td>\n",
       "      <td>0.803791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>HOME_PTS_FB_L10</td>\n",
       "      <td>0.789732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>HOME_DIST_opp_L10</td>\n",
       "      <td>0.788174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>HOME_PIE_L5</td>\n",
       "      <td>0.774788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>HOME_ORBC_L20</td>\n",
       "      <td>0.770055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>HOME_FTA_L20</td>\n",
       "      <td>-0.704908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>HOME_BLK_L10</td>\n",
       "      <td>-0.705033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>AWAY_PTS_PAINT_L20</td>\n",
       "      <td>-0.862086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>HOME_ORBC_L10</td>\n",
       "      <td>-0.915781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>HOME_PTS_OFF_TOV_L10</td>\n",
       "      <td>-0.966748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 features  coefficients\n",
       "365       AWAY_AST_opp_L5      0.803791\n",
       "140       HOME_PTS_FB_L10      0.789732\n",
       "168     HOME_DIST_opp_L10      0.788174\n",
       "103           HOME_PIE_L5      0.774788\n",
       "230         HOME_ORBC_L20      0.770055\n",
       "..                    ...           ...\n",
       "213          HOME_FTA_L20     -0.704908\n",
       "115          HOME_BLK_L10     -0.705033\n",
       "559    AWAY_PTS_PAINT_L20     -0.862086\n",
       "126         HOME_ORBC_L10     -0.915781\n",
       "141  HOME_PTS_OFF_TOV_L10     -0.966748\n",
       "\n",
       "[626 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe.fit(X_train, y_train)\n",
    "coefficients= pd.DataFrame({'features':X_train.columns,\n",
    "                      'coefficients': list(lr_pipe.named_steps['lr'].coef_)[0]})\n",
    "\n",
    "coefficients.sort_values(['coefficients'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-focus",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-ranch",
   "metadata": {},
   "source": [
    "## Helper Functions for Bet Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "subtle-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_bets_1(selected_bets, unit_size):\n",
    "    \"\"\"This function simulates betting unit_size of your bankroll on each bet in the\n",
    "    selected_bets df\"\"\"\n",
    "    selected_bets = selected_bets.copy()\n",
    "    selected_bets = selected_bets.reset_index()\n",
    "    selected_bets.loc[0, 'bankroll_i'] = 100\n",
    "    for idx in range(selected_bets.shape[0]):\n",
    "        if np.isnan(selected_bets.loc[idx, 'bankroll_i']):\n",
    "            selected_bets.loc[idx, 'bankroll_i'] = selected_bets.loc[idx-1, 'bankroll_n']\n",
    "\n",
    "        selected_bets.loc[idx, 'bet_size'] = unit_size\n",
    "        if selected_bets.loc[idx, 'bet_won'] == 1:\n",
    "            selected_bets.loc[idx, 'bankroll_n'] = selected_bets.loc[idx, 'bankroll_i'] + (1/1.1)*selected_bets.loc[idx, 'bet_size']\n",
    "        elif selected_bets.loc[idx, 'bet_won'] == 0:\n",
    "            selected_bets.loc[idx, 'bankroll_n'] = selected_bets.loc[idx, 'bankroll_i'] - selected_bets.loc[idx, 'bet_size']\n",
    "        else:\n",
    "            selected_bets.loc[idx, 'bankroll_n'] = selected_bets.loc[idx, 'bankroll_i']\n",
    "            \n",
    "    plt.style.use('fivethirtyeight')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.plot(range(selected_bets.shape[0]), selected_bets['bankroll_i'], linewidth=1.5)\n",
    "    ax.set_ylabel(\"Bankroll\")\n",
    "    ax.set_xlabel(\"Games Bet\")\n",
    "    plt.show()\n",
    "    min_balance = selected_bets['bankroll_n'].min()\n",
    "    max_balance = selected_bets['bankroll_n'].max()\n",
    "    final_balance = selected_bets['bankroll_n'].iloc[-1]\n",
    "    win_pct = selected_bets.loc[selected_bets['bet_won'] != 0.5, 'bet_won'].mean()\n",
    "    \n",
    "    amt_won = selected_bets.loc[selected_bets['bet_won'] ==1, 'bet_size'].sum() * 1/1.1\n",
    "    amt_lost = selected_bets.loc[selected_bets['bet_won']==0, 'bet_size'].sum()\n",
    "    amt_risked = selected_bets['bet_size'].sum()\n",
    "\n",
    "    profit = amt_won - amt_lost\n",
    "    roi = profit/amt_risked\n",
    "    \n",
    "    print(\"min balance:\", min_balance,\n",
    "         \"\\nmax balance:\", max_balance,\n",
    "         \"\\nfinal balance:\", final_balance,\n",
    "         \"\\nwin percentage\", round(win_pct, 4) * 100,\n",
    "         \"\\nprofit:\", profit, \"risk:\", amt_risked,\n",
    "         \"\\nROI:\", round(roi, 4) * 100)\n",
    "    return selected_bets, roi, profit, win_pct\n",
    "\n",
    "def simulate_bets_2(selected_bets, unit_pct=0.03):\n",
    "    \"\"\"This function simulates betting unit_size (default 3%) of your bankroll on each bet in the\n",
    "    selected_bets df\"\"\"\n",
    "    selected_bets = selected_bets.copy()\n",
    "    selected_bets = selected_bets.reset_index()\n",
    "    selected_bets.loc[0, 'bankroll_i'] = 100\n",
    "    for idx in range(selected_bets.shape[0]):\n",
    "        if np.isnan(selected_bets.loc[idx, 'bankroll_i']):\n",
    "            selected_bets.loc[idx, 'bankroll_i'] = selected_bets.loc[idx-1, 'bankroll_n']\n",
    "\n",
    "        selected_bets.loc[idx, 'bet_size'] = selected_bets.loc[idx, 'bankroll_i'] * unit_pct\n",
    "        if selected_bets.loc[idx, 'bet_won'] == 1:\n",
    "            selected_bets.loc[idx, 'bankroll_n'] = selected_bets.loc[idx, 'bankroll_i'] + (1/1.1)*selected_bets.loc[idx, 'bet_size']\n",
    "        elif selected_bets.loc[idx, 'bet_won'] == 0:\n",
    "            selected_bets.loc[idx, 'bankroll_n'] = selected_bets.loc[idx, 'bankroll_i'] - selected_bets.loc[idx, 'bet_size']\n",
    "        else:\n",
    "            selected_bets.loc[idx, 'bankroll_n'] = selected_bets.loc[idx, 'bankroll_i']\n",
    "            \n",
    "    plt.style.use('fivethirtyeight')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.plot(range(selected_bets.shape[0]), selected_bets['bankroll_i'], linewidth=1.5)\n",
    "    ax.set_ylabel(\"Bankroll\")\n",
    "    ax.set_xlabel(\"Games Bet\")\n",
    "    plt.show()\n",
    "    min_balance = selected_bets['bankroll_n'].min()\n",
    "    max_balance = selected_bets['bankroll_n'].max()\n",
    "    final_balance = selected_bets['bankroll_n'].iloc[-1]\n",
    "    win_pct = selected_bets.loc[selected_bets['bet_won'] != 0.5, 'bet_won'].mean()\n",
    "    \n",
    "    amt_won = selected_bets.loc[selected_bets['bet_won'] ==1, 'bet_size'].sum() * 1/1.1\n",
    "    amt_lost = selected_bets.loc[selected_bets['bet_won']==0, 'bet_size'].sum()\n",
    "    amt_risked = selected_bets['bet_size'].sum()\n",
    "\n",
    "    profit = amt_won - amt_lost\n",
    "    roi = profit/amt_risked\n",
    "    \n",
    "    print(\"min balance:\", min_balance,\n",
    "         \"\\nmax balance:\", max_balance,\n",
    "         \"\\nfinal balance:\", final_balance,\n",
    "         \"\\nwin percentage\", round(win_pct, 4) * 100,\n",
    "         \"\\nprofit:\", profit, \"risk:\", amt_risked,\n",
    "         \"\\nROI:\", round(roi, 4) * 100)\n",
    "    return selected_bets, roi, profit, win_pct\n",
    "\n",
    "\n",
    "def simulate_bets_3(selected_bets):\n",
    "    \"\"\"This function simulates betting unit_size (default 3%) of your bankroll on each bet in the\n",
    "    selected_bets df\"\"\"\n",
    "    selected_bets = selected_bets.copy()\n",
    "    selected_bets = selected_bets.reset_index()\n",
    "    selected_bets.loc[0, 'bankroll_i'] = 100\n",
    "    for idx in range(selected_bets.shape[0]):\n",
    "        if np.isnan(selected_bets.loc[idx, 'bankroll_i']):\n",
    "            selected_bets.loc[idx, 'bankroll_i'] = selected_bets.loc[idx-1, 'bankroll_n']\n",
    "\n",
    "        if abs(selected_bets.at[idx, 'prob_avg']-0.5) > 0.05:\n",
    "            bet_size = 4\n",
    "        elif abs(selected_bets.at[idx, 'prob_avg']-0.5) > 0.04:\n",
    "            bet_size = 3\n",
    "        elif abs(selected_bets.at[idx, 'prob_avg']-0.5) >= 0.03:\n",
    "            bet_size = 2\n",
    "        elif abs(selected_bets.at[idx, 'prob_avg']-0.5) > 0.01:\n",
    "            bet_size = 2\n",
    "        else:\n",
    "            bet_size = 1\n",
    "            \n",
    "        selected_bets.at[idx, 'bet_size'] = bet_size\n",
    "        if selected_bets.at[idx, 'bet_won'] == 1:\n",
    "            selected_bets.at[idx, 'bankroll_n'] = selected_bets.at[idx, 'bankroll_i'] + (1/1.1)*selected_bets.loc[idx, 'bet_size']\n",
    "        elif selected_bets.at[idx, 'bet_won'] == 0:\n",
    "            selected_bets.at[idx, 'bankroll_n'] = selected_bets.at[idx, 'bankroll_i'] - selected_bets.at[idx, 'bet_size']\n",
    "        else:\n",
    "            selected_bets.at[idx, 'bankroll_n'] = selected_bets.at[idx, 'bankroll_i']\n",
    "            \n",
    "    plt.style.use('fivethirtyeight')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.plot(range(selected_bets.shape[0]), selected_bets['bankroll_i'], linewidth=1.5)\n",
    "    ax.set_ylabel(\"Bankroll\")\n",
    "    ax.set_xlabel(\"Games Bet\")\n",
    "    plt.show()\n",
    "    min_balance = selected_bets['bankroll_n'].min()\n",
    "    max_balance = selected_bets['bankroll_n'].max()\n",
    "    final_balance = selected_bets['bankroll_n'].iloc[-1]\n",
    "    win_pct = selected_bets.loc[selected_bets['bet_won'] != 0.5, 'bet_won'].mean()\n",
    "    \n",
    "    amt_won = selected_bets.loc[selected_bets['bet_won'] ==1, 'bet_size'].sum() * 1/1.1\n",
    "    amt_lost = selected_bets.loc[selected_bets['bet_won']==0, 'bet_size'].sum()\n",
    "    amt_risked = selected_bets['bet_size'].sum()\n",
    "\n",
    "    profit = amt_won - amt_lost\n",
    "    roi = profit/amt_risked\n",
    "    \n",
    "    print(\"min balance:\", min_balance,\n",
    "         \"\\nmax balance:\", max_balance,\n",
    "         \"\\nfinal balance:\", final_balance,\n",
    "         \"\\nwin percentage\", round(win_pct, 4) * 100,\n",
    "         \"\\nprofit:\", profit, \"risk:\", amt_risked,\n",
    "         \"\\nROI:\", round(roi, 4) * 100)\n",
    "    return selected_bets, roi, profit, win_pct\n",
    "\n",
    "def simulate_bets_4(selected_bets):\n",
    "    \"\"\"This function simulates betting unit_size (default 3%) of your bankroll on each bet in the\n",
    "    selected_bets df\"\"\"\n",
    "    selected_bets = selected_bets.copy()\n",
    "    selected_bets = selected_bets.reset_index()\n",
    "    selected_bets.loc[0, 'bankroll_i'] = 100\n",
    "    for idx in range(selected_bets.shape[0]):\n",
    "        if np.isnan(selected_bets.loc[idx, 'bankroll_i']):\n",
    "            selected_bets.loc[idx, 'bankroll_i'] = selected_bets.loc[idx-1, 'bankroll_n']\n",
    "\n",
    "        if abs(selected_bets.at[idx, 'prob_avg']-0.5) > 0.04:\n",
    "            bet_size = 0.05\n",
    "        elif abs(selected_bets.at[idx, 'prob_avg']-0.5) > 0.03:\n",
    "            bet_size = 0.04\n",
    "        elif abs(selected_bets.at[idx, 'prob_avg']-0.5) > 0.02:\n",
    "            bet_size = 0.03\n",
    "        elif abs(selected_bets.at[idx, 'prob_avg']-0.5) > 0.01:\n",
    "            bet_size = 0.02\n",
    "        else:\n",
    "            bet_size = 0.01\n",
    "        \n",
    "        selected_bets.loc[idx, 'bankroll_i'] = selected_bets.loc[idx-1, 'bankroll_n']\n",
    "\n",
    "        selected_bets.loc[idx, 'bet_size'] = selected_bets.loc[idx, 'bankroll_i'] * bet_size\n",
    "        if selected_bets.loc[idx, 'bet_won'] == 1:\n",
    "            selected_bets.loc[idx, 'bankroll_n'] = selected_bets.loc[idx, 'bankroll_i'] + (1/1.1)*selected_bets.loc[idx, 'bet_size']\n",
    "        elif selected_bets.loc[idx, 'bet_won'] == 0:\n",
    "            selected_bets.loc[idx, 'bankroll_n'] = selected_bets.loc[idx, 'bankroll_i'] - selected_bets.loc[idx, 'bet_size']\n",
    "        else:\n",
    "            selected_bets.loc[idx, 'bankroll_n'] = selected_bets.loc[idx, 'bankroll_i']\n",
    "            \n",
    "            \n",
    "    plt.style.use('fivethirtyeight')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.plot(range(selected_bets.shape[0]), selected_bets['bankroll_i'], linewidth=1.5)\n",
    "    ax.set_ylabel(\"Bankroll\")\n",
    "    ax.set_xlabel(\"Games Bet\")\n",
    "    plt.show()\n",
    "    min_balance = selected_bets['bankroll_n'].min()\n",
    "    max_balance = selected_bets['bankroll_n'].max()\n",
    "    final_balance = selected_bets['bankroll_n'].iloc[-1]\n",
    "    win_pct = selected_bets.loc[selected_bets['bet_won'] != 0.5, 'bet_won'].mean()\n",
    "    \n",
    "    amt_won = selected_bets.loc[selected_bets['bet_won'] ==1, 'bet_size'].sum() * 1/1.1\n",
    "    amt_lost = selected_bets.loc[selected_bets['bet_won']==0, 'bet_size'].sum()\n",
    "    amt_risked = selected_bets['bet_size'].sum()\n",
    "\n",
    "    profit = amt_won - amt_lost\n",
    "    roi = profit/amt_risked\n",
    "    \n",
    "    print(\"min balance:\", min_balance,\n",
    "         \"\\nmax balance:\", max_balance,\n",
    "         \"\\nfinal balance:\", final_balance,\n",
    "         \"\\nwin percentage\", round(win_pct, 4) * 100,\n",
    "         \"\\nprofit:\", profit, \"risk:\", amt_risked,\n",
    "         \"\\nROI:\", round(roi, 4) * 100)\n",
    "    return selected_bets, roi, profit, win_pct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "continued-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ranges of model probability where the win percentage is higher than 52.8\n",
    "def find_optimal_threshold(df, test_probs, test_indices):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "    df:\n",
    "    test_preds: array of class predictions\n",
    "    test_indices: indices of full df for the test set \n",
    "    OUTPUTS:\n",
    "    select_bets: df of bets at the optimal thresholds\n",
    "    confidence_thresholds: df of thresholds, num_games_bet, win_percentage, expected_profits\n",
    "    best_thresholds: tuple of lower and upper thresholds\n",
    "    \n",
    "    \"\"\"\n",
    "    df=df.copy(deep=True)\n",
    "    \n",
    "    betting_df = create_betting_df(df, test_probs, test_indices)\n",
    "\n",
    "    confidence_range = []\n",
    "    win_percentages = []\n",
    "    num_games_bet = []\n",
    "    expected_profits = []\n",
    "#     for num in range(1, 4):\n",
    "#         strat_types = ['home', 'away', 'avg']\n",
    "#         strat = strat_types[num-1]\n",
    "    for i in range(1, 500):\n",
    "        select_bets = betting_df.loc[~betting_df['prob_avg'].between(0.5-i/1000, 0.5+i/1000)]\n",
    "        win_pct = select_bets['bet_won'].mean()\n",
    "        num_games = select_bets.shape[0]\n",
    "        confidence_range.append((0.5+i/1000))\n",
    "        win_percentages.append(win_pct)\n",
    "        num_games_bet.append(num_games)\n",
    "        bets_won = select_bets['bet_won'].sum()\n",
    "        bets_lost = num_games - bets_won\n",
    "        expected_profit = (bets_won*100 + bets_lost*-110)\n",
    "        expected_profits.append(expected_profit)\n",
    "\n",
    "    confidence_thresholds = pd.DataFrame({\n",
    "                                        'confidence_range':confidence_range, \n",
    "                                       'num_games_bet':num_games_bet, \n",
    "                                       'win_percentage':win_percentages,\n",
    "                                         'expected_profit':expected_profits})\n",
    "    \n",
    "    confidence_thresholds = confidence_thresholds.loc[confidence_thresholds['win_percentage'] > 0.5238]\n",
    "    confidence_thresholds.sort_values(['expected_profit', 'num_games_bet'], ascending=[False, False], inplace=True)\n",
    "    confidence_thresholds.reset_index(drop=False, inplace=True) \n",
    "    try:\n",
    "        best_threshold = confidence_thresholds.loc[0, 'confidence_range']\n",
    "#         print(\"best_strategy:\", confidence_thresholds.loc[0, 'strategy'])\n",
    "        print(\"best threshold for testset 1:\", best_threshold)\n",
    "        select_bets =  betting_df.loc[~(betting_df['prob_avg'].between(1-best_threshold, best_threshold))]\n",
    "        print(\"num_games_bet at threshold:\", select_bets.shape[0])\n",
    "        print(\"win percetange at threshold:\", select_bets['bet_won'].mean())\n",
    "    except:\n",
    "        print(\"no best threshold\")\n",
    "        select_bets = betting_df\n",
    "        best_threshold = 0.5\n",
    "        print(\"The except block executed\")\n",
    "    \n",
    "    return select_bets, confidence_thresholds, best_threshold\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "sitting-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_betting_df(df, probs, test_indices):\n",
    "    df=df.copy(deep=True)\n",
    "    \n",
    "    df = df.rename(columns= {'SPREAD_team':'SPREAD', \n",
    "                      'SCORE_team':'SCORE', \n",
    "                      'POINT_DIFF_team':'POINT_DIFF',\n",
    "                        'TEAM_COVERED_team':'cover'})\n",
    "    \n",
    "    betting_df = df.loc[test_indices, ['GAME_ID', 'HOME_GAME', 'MATCHUP', \n",
    "                                                 'SPREAD', 'SCORE', \n",
    "                                                 'POINT_DIFF', 'cover']]\n",
    "\n",
    "    betting_df['prob'] = probs[:, 1]\n",
    "    \n",
    "\n",
    "    home_df = betting_df.loc[betting_df['HOME_GAME']==1]\n",
    "    away_df = betting_df.loc[betting_df['HOME_GAME']==0]\n",
    "\n",
    "    betting_df = pd.merge(home_df, away_df, on=['GAME_ID'], suffixes=['_home', '_away'])\n",
    "\n",
    "      \n",
    "    betting_df = betting_df[['GAME_ID', 'MATCHUP_home', 'SPREAD_home',\n",
    "                             'SCORE_home', 'SCORE_away', 'POINT_DIFF_home', \n",
    "                                 'cover_home', 'prob_home', 'prob_away']]\n",
    "\n",
    "    betting_df['prob_avg'] = (betting_df['prob_home'] + (1-betting_df['prob_away']))/2\n",
    "\n",
    "    betting_df['bet_home'] = (betting_df['prob_avg'] > 0.5).astype(int)\n",
    "    betting_df['bet_won'] = (betting_df['bet_home'] == betting_df['cover_home']).astype(int)\n",
    "\n",
    "    betting_df = betting_df.loc[betting_df['SPREAD_home'] + betting_df['POINT_DIFF_home']!=0]\n",
    "\n",
    "\n",
    "    betting_df['bankroll_i'] = np.nan\n",
    "    betting_df['bankroll_n'] = np.nan\n",
    "    betting_df.loc[0, 'bankroll_i'] = 100\n",
    "    betting_df['bet_size'] = np.nan\n",
    "    \n",
    "    return betting_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "hairy-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ewm_19_diffs_clean = pd.read_csv(\"../data/clean/df_ewm_19_diffs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-possession",
   "metadata": {},
   "source": [
    "### Define Custom Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "civilian-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "headed-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_model_coefs(model, X_train):\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    try:\n",
    "        coefficients = model.coef_[0]\n",
    "    except:\n",
    "        print(\"LGBoost or XGBoost\")\n",
    "        coefficients = model.feature_importances_\n",
    "\n",
    "    coef_df = pd.DataFrame({'feature_name':feature_names,\n",
    "                'coef':coefficients})\n",
    "\n",
    "    coef_df = coef_df.loc[coef_df['coef']!=0].sort_values('coef')\n",
    "    \n",
    "    top_20_features = pd.concat([coef_df.head(10), coef_df.tail(10)])\n",
    "    top_20_features.plot.barh('feature_name', figsize=(6,12))\n",
    "    \n",
    "    return coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-corrections",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2f4f6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-08 18:28:30,962]\u001b[0m Using an existing study with name '../models/hyperparameter_tuning/study_logistic_regression' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 18:28:51,412]\u001b[0m Trial 64 finished with value: 0.7078037007240547 and parameters: {'C': 0.022590381982503942, 'l1_ratio': 0.519257308367584}. Best is trial 57 with value: 0.7161705551086082.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    lr_C = trial.suggest_float('C', 1e-5, 1e2, log=True)\n",
    "    lr_l1_ratio = trial.suggest_float('l1_ratio', 0, 1, log=False)\n",
    "    \n",
    "    classifier_obj = Pipeline([('scaler', StandardScaler()),\n",
    "                                ('logreg', LogisticRegression(solver='saga',\n",
    "                                                              C=lr_C,\n",
    "                                                            penalty='elasticnet',\n",
    "                                                            max_iter=10000,\n",
    "                                                            verbose=1,\n",
    "                                                            l1_ratio=lr_l1_ratio,\n",
    "                                                            random_state=23))])\n",
    "    \n",
    "    score = cross_val_score(classifier_obj, X_train, y_train, n_jobs=-1,\n",
    "                           cv=tscv, scoring='accuracy')\n",
    "    \n",
    "    \n",
    "    score_avg = score.mean()\n",
    "    \n",
    "    return score_avg\n",
    "\n",
    "study_name = '../models/hyperparameter_tuning/study_logistic_regression'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_lr = optuna.create_study(study_name = study_name, direction='maximize', \n",
    "                               storage = storage_name, load_if_exists=True)\n",
    "\n",
    "study_lr.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a3f13d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031670842561214795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jordan Nishimura\\NBA_Model_v1\\nba-model-venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 145 epochs took 10 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('logreg',\n",
      "                 LogisticRegression(C=0.031670842561214795,\n",
      "                                    l1_ratio=0.6782125608588861,\n",
      "                                    max_iter=100000, random_state=23,\n",
      "                                    solver='saga', verbose=1))])\n",
      "train_acc: 0.7349155269509252\n",
      "test_acc: 0.6676977463543968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>AWAY_FG2M_L5</td>\n",
       "      <td>-0.453485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>AWAY_EFG_PCT_L5</td>\n",
       "      <td>-0.354360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>AWAY_FG2M_L10</td>\n",
       "      <td>-0.247387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>AWAY_EFG_PCT_L10</td>\n",
       "      <td>-0.213602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>AWAY_COVER_PCT_L20</td>\n",
       "      <td>-0.158377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>AWAY_DFGA_L20</td>\n",
       "      <td>0.207610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>HOME_FG2M_L10</td>\n",
       "      <td>0.238587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>HOME_AVG_ATS_DIFF_L20</td>\n",
       "      <td>0.250353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>HOME_EFG_PCT_L5</td>\n",
       "      <td>0.336073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOME_FG2M_L5</td>\n",
       "      <td>0.385170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature_name      coef\n",
       "313           AWAY_FG2M_L5 -0.453485\n",
       "410        AWAY_EFG_PCT_L5 -0.354360\n",
       "417          AWAY_FG2M_L10 -0.247387\n",
       "514       AWAY_EFG_PCT_L10 -0.213602\n",
       "609     AWAY_COVER_PCT_L20 -0.158377\n",
       "..                     ...       ...\n",
       "555          AWAY_DFGA_L20  0.207610\n",
       "104          HOME_FG2M_L10  0.238587\n",
       "294  HOME_AVG_ATS_DIFF_L20  0.250353\n",
       "97         HOME_EFG_PCT_L5  0.336073\n",
       "0             HOME_FG2M_L5  0.385170\n",
       "\n",
       "[626 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_name = '../models/hyperparameter_tuning/study_logistic_regression'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_lr = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "\n",
    "lr_C = study_lr.best_params['C']\n",
    "lr_l1_ratio = study_lr.best_params['l1_ratio']\n",
    "print(lr_C)\n",
    "\n",
    "best_lr = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('logreg', LogisticRegression(solver='saga', C=lr_C,\n",
    "                                                  penalty='l2', max_iter=100000,\n",
    "                                                 verbose=1, l1_ratio = lr_l1_ratio,\n",
    "                                                 random_state=23))])\n",
    "best_lr.fit(X_train, y_train)\n",
    "\n",
    "print(best_lr)\n",
    "\n",
    "print(\"train_acc:\", best_lr.score(X_train, y_train))\n",
    "print(\"test_acc:\", best_lr.score(X_val, y_val))\n",
    "\n",
    "view_model_coefs(best_lr.named_steps['logreg'], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9610b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 56 features.\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(5)\n",
    "\n",
    "lr_pipe = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                ('logreg',\n",
    "                 LogisticRegression(C=0.031670842561214795,\n",
    "                                    l1_ratio=0.6782125608588861,\n",
    "                                    penalty = 'elasticnet',\n",
    "                                    max_iter=100000, random_state=23,\n",
    "                                    solver='saga'))])\n",
    "\n",
    "selector = RFECV(estimator = lr_pipe, step=10, cv=tscv, scoring='accuracy', importance_getter='named_steps.logreg.coef_', verbose=1)\n",
    "\n",
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7902b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 627 features.\n",
      "Fitting estimator with 625 features.\n",
      "Fitting estimator with 623 features.\n",
      "Fitting estimator with 621 features.\n",
      "Fitting estimator with 619 features.\n",
      "Fitting estimator with 617 features.\n",
      "Fitting estimator with 615 features.\n",
      "Fitting estimator with 613 features.\n",
      "Fitting estimator with 611 features.\n",
      "Fitting estimator with 609 features.\n",
      "Fitting estimator with 607 features.\n",
      "Fitting estimator with 605 features.\n",
      "Fitting estimator with 603 features.\n",
      "Fitting estimator with 601 features.\n",
      "Fitting estimator with 599 features.\n",
      "Fitting estimator with 597 features.\n",
      "Fitting estimator with 595 features.\n",
      "Fitting estimator with 593 features.\n",
      "Fitting estimator with 591 features.\n",
      "Fitting estimator with 589 features.\n",
      "Fitting estimator with 587 features.\n",
      "Fitting estimator with 585 features.\n",
      "Fitting estimator with 583 features.\n",
      "Fitting estimator with 581 features.\n",
      "Fitting estimator with 579 features.\n",
      "Fitting estimator with 577 features.\n",
      "Fitting estimator with 575 features.\n",
      "Fitting estimator with 573 features.\n",
      "Fitting estimator with 571 features.\n",
      "Fitting estimator with 569 features.\n",
      "Fitting estimator with 567 features.\n",
      "Fitting estimator with 565 features.\n",
      "Fitting estimator with 563 features.\n",
      "Fitting estimator with 561 features.\n",
      "Fitting estimator with 559 features.\n",
      "Fitting estimator with 557 features.\n",
      "Fitting estimator with 555 features.\n",
      "Fitting estimator with 553 features.\n",
      "Fitting estimator with 551 features.\n",
      "Fitting estimator with 549 features.\n",
      "Fitting estimator with 547 features.\n",
      "Fitting estimator with 545 features.\n",
      "Fitting estimator with 543 features.\n",
      "Fitting estimator with 541 features.\n",
      "Fitting estimator with 539 features.\n",
      "Fitting estimator with 537 features.\n",
      "Fitting estimator with 535 features.\n",
      "Fitting estimator with 533 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 529 features.\n",
      "Fitting estimator with 527 features.\n",
      "Fitting estimator with 525 features.\n",
      "Fitting estimator with 523 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 519 features.\n",
      "Fitting estimator with 517 features.\n",
      "Fitting estimator with 515 features.\n",
      "Fitting estimator with 513 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 509 features.\n",
      "Fitting estimator with 507 features.\n",
      "Fitting estimator with 505 features.\n",
      "Fitting estimator with 503 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 499 features.\n",
      "Fitting estimator with 497 features.\n",
      "Fitting estimator with 495 features.\n",
      "Fitting estimator with 493 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 489 features.\n",
      "Fitting estimator with 487 features.\n",
      "Fitting estimator with 485 features.\n",
      "Fitting estimator with 483 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 479 features.\n",
      "Fitting estimator with 477 features.\n",
      "Fitting estimator with 475 features.\n",
      "Fitting estimator with 473 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 469 features.\n",
      "Fitting estimator with 467 features.\n",
      "Fitting estimator with 465 features.\n",
      "Fitting estimator with 463 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 459 features.\n",
      "Fitting estimator with 457 features.\n",
      "Fitting estimator with 455 features.\n",
      "Fitting estimator with 453 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 449 features.\n",
      "Fitting estimator with 447 features.\n",
      "Fitting estimator with 445 features.\n",
      "Fitting estimator with 443 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 439 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 435 features.\n",
      "Fitting estimator with 433 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 429 features.\n",
      "Fitting estimator with 427 features.\n",
      "Fitting estimator with 425 features.\n",
      "Fitting estimator with 423 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 419 features.\n",
      "Fitting estimator with 417 features.\n",
      "Fitting estimator with 415 features.\n",
      "Fitting estimator with 413 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 409 features.\n",
      "Fitting estimator with 407 features.\n",
      "Fitting estimator with 405 features.\n",
      "Fitting estimator with 403 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 399 features.\n",
      "Fitting estimator with 397 features.\n",
      "Fitting estimator with 395 features.\n",
      "Fitting estimator with 393 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 389 features.\n",
      "Fitting estimator with 387 features.\n",
      "Fitting estimator with 385 features.\n",
      "Fitting estimator with 383 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 379 features.\n",
      "Fitting estimator with 377 features.\n",
      "Fitting estimator with 375 features.\n",
      "Fitting estimator with 373 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 369 features.\n",
      "Fitting estimator with 367 features.\n",
      "Fitting estimator with 365 features.\n",
      "Fitting estimator with 363 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 359 features.\n",
      "Fitting estimator with 357 features.\n",
      "Fitting estimator with 355 features.\n",
      "Fitting estimator with 353 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 347 features.\n",
      "Fitting estimator with 345 features.\n",
      "Fitting estimator with 343 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 337 features.\n",
      "Fitting estimator with 335 features.\n",
      "Fitting estimator with 333 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 327 features.\n",
      "Fitting estimator with 325 features.\n",
      "Fitting estimator with 323 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 317 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 313 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 305 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 297 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 293 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 287 features.\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(5)\n",
    "\n",
    "lr_pipe = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                ('logreg',\n",
    "                 LogisticRegression(C=0.031670842561214795,\n",
    "                                    l1_ratio=0.6782125608588861,\n",
    "                                    penalty = 'elasticnet',\n",
    "                                    max_iter=100000, random_state=23,\n",
    "                                    solver='saga'))])\n",
    "\n",
    "selector = RFE(estimator = lr_pipe, n_features_to_select=285, step=2, importance_getter='named_steps.logreg.coef_', verbose=1)\n",
    "\n",
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea4c46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train.iloc[:, selector.support_].columns, columns=['features']).to_csv('linear_regression_RFE_selected_features_no_ML.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c72e7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.iloc[:, selector.support_]\n",
    "\n",
    "features = pd.read_csv('linear_regression_RFE_selected_features_no_ML.csv')\n",
    "features = features['features'].tolist()\n",
    "\n",
    "\n",
    "X_train_selected = X_train[features]\n",
    "X_val_selected = X_val[features]\n",
    "X_test_selected = X_test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d26a7",
   "metadata": {},
   "source": [
    "## Logistic Regression (ElasticNet Penalty) With RFE Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6d3fc5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-08 19:07:02,424]\u001b[0m A new study created in RDB with name: ../models/hyperparameter_tuning/study_logistic_regression_rfe_no_ML\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:05,879]\u001b[0m Trial 0 finished with value: 0.713917940466613 and parameters: {'C': 1.1614848311770705, 'l1_ratio': 0.827808118422565}. Best is trial 0 with value: 0.713917940466613.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:06,255]\u001b[0m Trial 1 finished with value: 0.614320193081255 and parameters: {'C': 0.0007398504043236131, 'l1_ratio': 0.24959907463888398}. Best is trial 0 with value: 0.713917940466613.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:07,038]\u001b[0m Trial 2 finished with value: 0.7148833467417537 and parameters: {'C': 0.10477986047800653, 'l1_ratio': 0.6202928166261896}. Best is trial 2 with value: 0.7148833467417537.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:09,034]\u001b[0m Trial 3 finished with value: 0.7150442477876106 and parameters: {'C': 23.97081333197668, 'l1_ratio': 0.3079467619421281}. Best is trial 3 with value: 0.7150442477876106.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:09,349]\u001b[0m Trial 4 finished with value: 0.588897827835881 and parameters: {'C': 0.00021555045833528735, 'l1_ratio': 0.26708501495161974}. Best is trial 3 with value: 0.7150442477876106.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:10,548]\u001b[0m Trial 5 finished with value: 0.7145615446500402 and parameters: {'C': 0.30194427407879465, 'l1_ratio': 0.6317841978486236}. Best is trial 3 with value: 0.7150442477876106.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:10,972]\u001b[0m Trial 6 finished with value: 0.6133547868061142 and parameters: {'C': 0.0005873725103115759, 'l1_ratio': 0.19295496599232076}. Best is trial 3 with value: 0.7150442477876106.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:11,251]\u001b[0m Trial 7 finished with value: 0.588897827835881 and parameters: {'C': 0.00020951376336406056, 'l1_ratio': 0.6700151879985344}. Best is trial 3 with value: 0.7150442477876106.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:12,970]\u001b[0m Trial 8 finished with value: 0.7150442477876107 and parameters: {'C': 0.5872571110688701, 'l1_ratio': 0.8242401296680567}. Best is trial 8 with value: 0.7150442477876107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:13,231]\u001b[0m Trial 9 finished with value: 0.588897827835881 and parameters: {'C': 1.4609396185200654e-05, 'l1_ratio': 0.9747540547876203}. Best is trial 8 with value: 0.7150442477876107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:15,252]\u001b[0m Trial 10 finished with value: 0.7150442477876106 and parameters: {'C': 93.93439916977351, 'l1_ratio': 0.9871892313903446}. Best is trial 8 with value: 0.7150442477876107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:17,352]\u001b[0m Trial 11 finished with value: 0.7152051488334674 and parameters: {'C': 17.42476874735403, 'l1_ratio': 0.011496387398716779}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:19,039]\u001b[0m Trial 12 finished with value: 0.7150442477876107 and parameters: {'C': 3.8412621518098033, 'l1_ratio': 0.02666965113967977}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:19,499]\u001b[0m Trial 13 finished with value: 0.7044247787610619 and parameters: {'C': 0.016144507720934714, 'l1_ratio': 0.4587080942011422}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:21,301]\u001b[0m Trial 14 finished with value: 0.7150442477876107 and parameters: {'C': 5.329005001610992, 'l1_ratio': 0.021379455110877188}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:21,786]\u001b[0m Trial 15 finished with value: 0.6913917940466613 and parameters: {'C': 0.00989544764509114, 'l1_ratio': 0.7870553134894309}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:23,001]\u001b[0m Trial 16 finished with value: 0.7147224456958972 and parameters: {'C': 0.521013854419605, 'l1_ratio': 0.4518773557822654}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:25,163]\u001b[0m Trial 17 finished with value: 0.7147224456958969 and parameters: {'C': 15.583396405644399, 'l1_ratio': 0.8474988022601208}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:27,208]\u001b[0m Trial 18 finished with value: 0.7150442477876106 and parameters: {'C': 86.41127372070592, 'l1_ratio': 0.37229943193726}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:28,990]\u001b[0m Trial 19 finished with value: 0.7150442477876107 and parameters: {'C': 3.7500149591499476, 'l1_ratio': 0.0032608040492353354}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:29,550]\u001b[0m Trial 20 finished with value: 0.7142397425583267 and parameters: {'C': 0.07659571143649598, 'l1_ratio': 0.13537948010670836}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:31,303]\u001b[0m Trial 21 finished with value: 0.7150442477876107 and parameters: {'C': 3.514443428855054, 'l1_ratio': 0.1484693237806242}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:33,070]\u001b[0m Trial 22 finished with value: 0.7152051488334674 and parameters: {'C': 3.0253368306995414, 'l1_ratio': 0.11688495770759887}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:35,136]\u001b[0m Trial 23 finished with value: 0.7152051488334674 and parameters: {'C': 17.4306071886046, 'l1_ratio': 0.0967109275715512}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:37,208]\u001b[0m Trial 24 finished with value: 0.7152051488334674 and parameters: {'C': 32.335742151154314, 'l1_ratio': 0.09899968281402582}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:39,266]\u001b[0m Trial 25 finished with value: 0.7152051488334674 and parameters: {'C': 29.226360392713943, 'l1_ratio': 0.11468195634651766}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:40,841]\u001b[0m Trial 26 finished with value: 0.713917940466613 and parameters: {'C': 1.431008984292808, 'l1_ratio': 0.3723693917092364}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:42,837]\u001b[0m Trial 27 finished with value: 0.7152051488334674 and parameters: {'C': 27.98537851660068, 'l1_ratio': 0.08913865424315734}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:44,954]\u001b[0m Trial 28 finished with value: 0.7150442477876106 and parameters: {'C': 47.67803038541616, 'l1_ratio': 0.20886485569775085}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:46,922]\u001b[0m Trial 29 finished with value: 0.7148833467417537 and parameters: {'C': 10.420359267519537, 'l1_ratio': 0.34616819286350053}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:48,226]\u001b[0m Trial 30 finished with value: 0.7142397425583266 and parameters: {'C': 1.2248166764490562, 'l1_ratio': 0.07109658797626212}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:50,258]\u001b[0m Trial 31 finished with value: 0.7152051488334674 and parameters: {'C': 17.28194791113753, 'l1_ratio': 0.16109493252415572}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:52,161]\u001b[0m Trial 32 finished with value: 0.7150442477876106 and parameters: {'C': 7.629162663193243, 'l1_ratio': 0.1828971338583179}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:53,832]\u001b[0m Trial 33 finished with value: 0.7144006436041834 and parameters: {'C': 1.942521755982597, 'l1_ratio': 0.22444365785436673}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:55,911]\u001b[0m Trial 34 finished with value: 0.7150442477876106 and parameters: {'C': 37.700380516336054, 'l1_ratio': 0.27837149940526007}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:56,528]\u001b[0m Trial 35 finished with value: 0.7147224456958969 and parameters: {'C': 0.1480880173773951, 'l1_ratio': 0.0858108607704546}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:07:58,474]\u001b[0m Trial 36 finished with value: 0.7152051488334674 and parameters: {'C': 10.371361753798078, 'l1_ratio': 0.07063466773936918}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:00,459]\u001b[0m Trial 37 finished with value: 0.7150442477876106 and parameters: {'C': 9.978588699713393, 'l1_ratio': 0.16727399851396624}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:00,938]\u001b[0m Trial 38 finished with value: 0.6872083668543845 and parameters: {'C': 0.003404406645006746, 'l1_ratio': 0.2944179882709702}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:03,147]\u001b[0m Trial 39 finished with value: 0.7150442477876106 and parameters: {'C': 60.92526507187879, 'l1_ratio': 0.06501304560850209}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:04,195]\u001b[0m Trial 40 finished with value: 0.7142397425583267 and parameters: {'C': 0.493443008847065, 'l1_ratio': 0.24064021932177282}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:06,298]\u001b[0m Trial 41 finished with value: 0.7152051488334674 and parameters: {'C': 29.313880220979062, 'l1_ratio': 0.11503655981986455}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:08,526]\u001b[0m Trial 42 finished with value: 0.7152051488334674 and parameters: {'C': 36.2259594469699, 'l1_ratio': 0.11075785001061061}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:10,609]\u001b[0m Trial 43 finished with value: 0.7150442477876106 and parameters: {'C': 98.68780282183265, 'l1_ratio': 0.051055853307900995}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:12,371]\u001b[0m Trial 44 finished with value: 0.7145615446500402 and parameters: {'C': 2.602615615580932, 'l1_ratio': 0.5504699295438642}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:14,604]\u001b[0m Trial 45 finished with value: 0.7150442477876106 and parameters: {'C': 60.40367880456386, 'l1_ratio': 0.14021832955681085}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:16,643]\u001b[0m Trial 46 finished with value: 0.7152051488334674 and parameters: {'C': 23.554787031987075, 'l1_ratio': 0.20594199387828796}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:18,635]\u001b[0m Trial 47 finished with value: 0.7152051488334674 and parameters: {'C': 10.875776338882773, 'l1_ratio': 0.04296409587760221}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:20,675]\u001b[0m Trial 48 finished with value: 0.7148833467417537 and parameters: {'C': 7.263395822482334, 'l1_ratio': 0.3239846557751681}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:21,966]\u001b[0m Trial 49 finished with value: 0.713917940466613 and parameters: {'C': 0.796888903706659, 'l1_ratio': 0.2545145332343735}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:24,036]\u001b[0m Trial 50 finished with value: 0.7152051488334674 and parameters: {'C': 13.474654813456263, 'l1_ratio': 0.18339750735075894}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:26,174]\u001b[0m Trial 51 finished with value: 0.7152051488334674 and parameters: {'C': 27.342091033230155, 'l1_ratio': 0.03598279762850157}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:26,553]\u001b[0m Trial 52 finished with value: 0.588897827835881 and parameters: {'C': 2.0938289708166445e-05, 'l1_ratio': 0.005092760032389704}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:28,533]\u001b[0m Trial 53 finished with value: 0.7152051488334674 and parameters: {'C': 15.776295693341376, 'l1_ratio': 0.1734895779657013}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:30,449]\u001b[0m Trial 54 finished with value: 0.7150442477876106 and parameters: {'C': 6.845457429229172, 'l1_ratio': 0.14905141882405798}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:31,277]\u001b[0m Trial 55 finished with value: 0.7142397425583266 and parameters: {'C': 0.22556732065239218, 'l1_ratio': 0.09142861871775579}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:33,420]\u001b[0m Trial 56 finished with value: 0.7150442477876106 and parameters: {'C': 40.55446364839869, 'l1_ratio': 0.10807050169037509}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:35,191]\u001b[0m Trial 57 finished with value: 0.7150442477876107 and parameters: {'C': 4.3684026987604385, 'l1_ratio': 0.11871687844098837}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:36,801]\u001b[0m Trial 58 finished with value: 0.7148833467417538 and parameters: {'C': 2.3937426957857686, 'l1_ratio': 0.061151822808928356}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:39,003]\u001b[0m Trial 59 finished with value: 0.7148833467417537 and parameters: {'C': 59.342202812776456, 'l1_ratio': 0.7313308838647586}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:41,099]\u001b[0m Trial 60 finished with value: 0.7152051488334674 and parameters: {'C': 25.96842774225149, 'l1_ratio': 0.11339561043483268}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:43,289]\u001b[0m Trial 61 finished with value: 0.7152051488334674 and parameters: {'C': 16.82244649494855, 'l1_ratio': 0.18118899030764052}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:45,345]\u001b[0m Trial 62 finished with value: 0.7152051488334674 and parameters: {'C': 19.042635859983253, 'l1_ratio': 0.19871600647471294}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:47,400]\u001b[0m Trial 63 finished with value: 0.7152051488334674 and parameters: {'C': 17.491679732036136, 'l1_ratio': 0.034690718859626976}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:49,593]\u001b[0m Trial 64 finished with value: 0.7150442477876106 and parameters: {'C': 29.065870374598973, 'l1_ratio': 0.23526031180694135}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:51,539]\u001b[0m Trial 65 finished with value: 0.7150442477876107 and parameters: {'C': 5.729390669030307, 'l1_ratio': 0.1337847473509971}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:52,126]\u001b[0m Trial 66 finished with value: 0.7113435237329042 and parameters: {'C': 0.04034239758487959, 'l1_ratio': 0.43720264816778487}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:54,156]\u001b[0m Trial 67 finished with value: 0.7150442477876106 and parameters: {'C': 94.85289092067329, 'l1_ratio': 0.08389555385899146}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:56,129]\u001b[0m Trial 68 finished with value: 0.7150442477876106 and parameters: {'C': 44.59643524508579, 'l1_ratio': 0.038538227014138345}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:56,550]\u001b[0m Trial 69 finished with value: 0.5943684633950121 and parameters: {'C': 0.0016480809044553723, 'l1_ratio': 0.9213848971689015}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:57,948]\u001b[0m Trial 70 finished with value: 0.7144006436041834 and parameters: {'C': 1.5464181228385616, 'l1_ratio': 0.08351083257903878}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:08:59,883]\u001b[0m Trial 71 finished with value: 0.7150442477876106 and parameters: {'C': 9.055640856741109, 'l1_ratio': 0.15977643428500313}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:01,763]\u001b[0m Trial 72 finished with value: 0.7152051488334674 and parameters: {'C': 12.814651388531765, 'l1_ratio': 6.597629076243727e-05}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:03,789]\u001b[0m Trial 73 finished with value: 0.7150442477876106 and parameters: {'C': 31.34741669402242, 'l1_ratio': 0.20793388181007888}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:05,892]\u001b[0m Trial 74 finished with value: 0.7150442477876106 and parameters: {'C': 57.021405732550846, 'l1_ratio': 0.05888666352570006}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:07,827]\u001b[0m Trial 75 finished with value: 0.7152051488334674 and parameters: {'C': 12.419721742265661, 'l1_ratio': 0.17541438893796568}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:09,572]\u001b[0m Trial 76 finished with value: 0.7148833467417539 and parameters: {'C': 3.17569712143562, 'l1_ratio': 0.2684238635306691}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:11,356]\u001b[0m Trial 77 finished with value: 0.7148833467417538 and parameters: {'C': 5.5454807115409706, 'l1_ratio': 0.1607154876532557}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:13,349]\u001b[0m Trial 78 finished with value: 0.7152051488334674 and parameters: {'C': 23.72836144700374, 'l1_ratio': 0.08965157587662655}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:15,425]\u001b[0m Trial 79 finished with value: 0.7152051488334674 and parameters: {'C': 11.500445011482887, 'l1_ratio': 0.038661259338804425}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:16,954]\u001b[0m Trial 80 finished with value: 0.7142397425583267 and parameters: {'C': 0.9185055806922429, 'l1_ratio': 0.02941490750405397}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:18,987]\u001b[0m Trial 81 finished with value: 0.7150442477876106 and parameters: {'C': 43.163508987279755, 'l1_ratio': 0.125718222067558}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:21,007]\u001b[0m Trial 82 finished with value: 0.7152051488334674 and parameters: {'C': 20.985685521003003, 'l1_ratio': 0.10188010356128006}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:23,136]\u001b[0m Trial 83 finished with value: 0.7150442477876106 and parameters: {'C': 68.81589640407299, 'l1_ratio': 0.21694487181794597}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:25,107]\u001b[0m Trial 84 finished with value: 0.7152051488334674 and parameters: {'C': 32.43450789845168, 'l1_ratio': 0.12362327896948147}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:27,054]\u001b[0m Trial 85 finished with value: 0.7150442477876106 and parameters: {'C': 7.959212965572084, 'l1_ratio': 0.14550244938046314}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:29,064]\u001b[0m Trial 86 finished with value: 0.7152051488334674 and parameters: {'C': 17.38063231970017, 'l1_ratio': 0.192954164859111}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:31,055]\u001b[0m Trial 87 finished with value: 0.7152051488334674 and parameters: {'C': 18.589748891902026, 'l1_ratio': 0.1951900892528688}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:33,064]\u001b[0m Trial 88 finished with value: 0.7152051488334674 and parameters: {'C': 20.61833817633469, 'l1_ratio': 0.2406159341501613}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:34,770]\u001b[0m Trial 89 finished with value: 0.7150442477876107 and parameters: {'C': 3.73207581122402, 'l1_ratio': 0.0016025613457364394}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:36,711]\u001b[0m Trial 90 finished with value: 0.7152051488334674 and parameters: {'C': 9.844517874233812, 'l1_ratio': 0.07583414154663035}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:38,656]\u001b[0m Trial 91 finished with value: 0.7152051488334674 and parameters: {'C': 25.064681398370798, 'l1_ratio': 0.0695919994913306}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:40,473]\u001b[0m Trial 92 finished with value: 0.7150442477876107 and parameters: {'C': 5.364605435657048, 'l1_ratio': 0.04904601996642818}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:42,556]\u001b[0m Trial 93 finished with value: 0.7148833467417537 and parameters: {'C': 36.18044489613892, 'l1_ratio': 0.546569867447447}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:44,522]\u001b[0m Trial 94 finished with value: 0.7152051488334674 and parameters: {'C': 12.320393746894139, 'l1_ratio': 0.016311850850708146}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:44,844]\u001b[0m Trial 95 finished with value: 0.588897827835881 and parameters: {'C': 8.697591196751186e-05, 'l1_ratio': 0.120991237696115}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:46,958]\u001b[0m Trial 96 finished with value: 0.7150442477876106 and parameters: {'C': 77.0123456195436, 'l1_ratio': 0.04789462816423906}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:48,561]\u001b[0m Trial 97 finished with value: 0.7148833467417538 and parameters: {'C': 2.1190932255906842, 'l1_ratio': 0.08418956419906246}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:50,425]\u001b[0m Trial 98 finished with value: 0.7150442477876106 and parameters: {'C': 10.133420362005578, 'l1_ratio': 0.09596767063501926}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:52,456]\u001b[0m Trial 99 finished with value: 0.7152051488334674 and parameters: {'C': 18.082448926944227, 'l1_ratio': 0.27829998382913274}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:54,420]\u001b[0m Trial 100 finished with value: 0.7150442477876106 and parameters: {'C': 49.498239790904506, 'l1_ratio': 0.2808532807141757}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:56,383]\u001b[0m Trial 101 finished with value: 0.7152051488334674 and parameters: {'C': 12.948890111155835, 'l1_ratio': 0.14934194635314846}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:09:58,475]\u001b[0m Trial 102 finished with value: 0.7152051488334674 and parameters: {'C': 23.40992782073876, 'l1_ratio': 0.17804580000716258}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:00,449]\u001b[0m Trial 103 finished with value: 0.7152051488334674 and parameters: {'C': 15.811966947067882, 'l1_ratio': 0.2010600748339632}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:02,481]\u001b[0m Trial 104 finished with value: 0.7152051488334674 and parameters: {'C': 29.14959611463146, 'l1_ratio': 0.18046177905018265}. Best is trial 11 with value: 0.7152051488334674.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:04,323]\u001b[0m Trial 105 finished with value: 0.7152051488334675 and parameters: {'C': 6.6598832356058795, 'l1_ratio': 0.01983960211114316}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:06,177]\u001b[0m Trial 106 finished with value: 0.7150442477876106 and parameters: {'C': 6.944193920021651, 'l1_ratio': 0.019062616116791452}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:08,158]\u001b[0m Trial 107 finished with value: 0.7150442477876106 and parameters: {'C': 37.19158700774418, 'l1_ratio': 0.10981805560090327}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:09,956]\u001b[0m Trial 108 finished with value: 0.7148833467417538 and parameters: {'C': 5.1448168555274245, 'l1_ratio': 0.10151344144421887}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:11,569]\u001b[0m Trial 109 finished with value: 0.7150442477876107 and parameters: {'C': 2.9922693992341127, 'l1_ratio': 0.061555253716153516}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:13,524]\u001b[0m Trial 110 finished with value: 0.7150442477876106 and parameters: {'C': 20.914123682550663, 'l1_ratio': 0.3219189957463696}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:15,414]\u001b[0m Trial 111 finished with value: 0.7152051488334674 and parameters: {'C': 14.142808060311712, 'l1_ratio': 0.02178110387588464}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:17,493]\u001b[0m Trial 112 finished with value: 0.7150442477876106 and parameters: {'C': 49.08412843785271, 'l1_ratio': 0.22579822750422565}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:19,568]\u001b[0m Trial 113 finished with value: 0.7148833467417537 and parameters: {'C': 9.654887895596476, 'l1_ratio': 0.2567502108605441}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:21,723]\u001b[0m Trial 114 finished with value: 0.7150442477876106 and parameters: {'C': 68.64121539721016, 'l1_ratio': 0.13562633434511573}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:23,646]\u001b[0m Trial 115 finished with value: 0.7152051488334674 and parameters: {'C': 22.002494797143235, 'l1_ratio': 0.19554168541632566}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:25,587]\u001b[0m Trial 116 finished with value: 0.7152051488334674 and parameters: {'C': 14.272769882174002, 'l1_ratio': 0.16209130035838754}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:27,380]\u001b[0m Trial 117 finished with value: 0.7152051488334675 and parameters: {'C': 6.616918730204441, 'l1_ratio': 0.07234717148077478}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:29,142]\u001b[0m Trial 118 finished with value: 0.7150442477876107 and parameters: {'C': 4.168809839737659, 'l1_ratio': 0.06869003508760857}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:29,584]\u001b[0m Trial 119 finished with value: 0.7066773934030571 and parameters: {'C': 0.008343382086138013, 'l1_ratio': 0.19179608507081225}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:31,489]\u001b[0m Trial 120 finished with value: 0.7147224456958969 and parameters: {'C': 7.521303299457313, 'l1_ratio': 0.4014423313920136}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:33,507]\u001b[0m Trial 121 finished with value: 0.7152051488334674 and parameters: {'C': 28.418458998218682, 'l1_ratio': 0.1462843278543483}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:35,395]\u001b[0m Trial 122 finished with value: 0.7152051488334674 and parameters: {'C': 12.893027153307935, 'l1_ratio': 0.031073100050344638}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:37,206]\u001b[0m Trial 123 finished with value: 0.7150442477876107 and parameters: {'C': 5.980776296882645, 'l1_ratio': 0.037821677550775055}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:39,193]\u001b[0m Trial 124 finished with value: 0.7152051488334674 and parameters: {'C': 18.310088043313993, 'l1_ratio': 0.0947029048631144}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:41,095]\u001b[0m Trial 125 finished with value: 0.7152051488334674 and parameters: {'C': 11.358632450770987, 'l1_ratio': 0.012991154725972764}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:43,053]\u001b[0m Trial 126 finished with value: 0.7152051488334674 and parameters: {'C': 21.827543248693196, 'l1_ratio': 0.006426914451980625}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:44,967]\u001b[0m Trial 127 finished with value: 0.7152051488334674 and parameters: {'C': 8.413580481249957, 'l1_ratio': 0.00012919254763885032}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:46,855]\u001b[0m Trial 128 finished with value: 0.7152051488334674 and parameters: {'C': 15.30656059348785, 'l1_ratio': 0.05358278785318058}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:48,870]\u001b[0m Trial 129 finished with value: 0.7150442477876106 and parameters: {'C': 43.97264027283352, 'l1_ratio': 0.06879845549080407}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:50,791]\u001b[0m Trial 130 finished with value: 0.7150442477876106 and parameters: {'C': 9.085452836051799, 'l1_ratio': 0.07531563625275209}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:52,833]\u001b[0m Trial 131 finished with value: 0.7152051488334674 and parameters: {'C': 32.14108829973313, 'l1_ratio': 0.16430394568424472}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:54,889]\u001b[0m Trial 132 finished with value: 0.7150442477876106 and parameters: {'C': 99.99278514875294, 'l1_ratio': 0.12650770365228298}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:57,022]\u001b[0m Trial 133 finished with value: 0.7152051488334674 and parameters: {'C': 28.410361311293574, 'l1_ratio': 0.024558479353787327}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:10:58,950]\u001b[0m Trial 134 finished with value: 0.7152051488334674 and parameters: {'C': 12.549576002802041, 'l1_ratio': 0.030374345167723703}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:00,968]\u001b[0m Trial 135 finished with value: 0.7150442477876106 and parameters: {'C': 12.76922479832678, 'l1_ratio': 0.21749872524423927}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:03,022]\u001b[0m Trial 136 finished with value: 0.7150442477876106 and parameters: {'C': 54.815055586382826, 'l1_ratio': 0.1854579348122438}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:04,729]\u001b[0m Trial 137 finished with value: 0.7150442477876107 and parameters: {'C': 4.880963470664519, 'l1_ratio': 0.016770568636126873}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:06,787]\u001b[0m Trial 138 finished with value: 0.7148833467417537 and parameters: {'C': 23.73061263844044, 'l1_ratio': 0.6767913562640024}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:08,595]\u001b[0m Trial 139 finished with value: 0.7150442477876107 and parameters: {'C': 3.719428919109338, 'l1_ratio': 0.0040060169329004785}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:10,379]\u001b[0m Trial 140 finished with value: 0.7150442477876106 and parameters: {'C': 6.809020240009226, 'l1_ratio': 0.10961892638227738}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:12,254]\u001b[0m Trial 141 finished with value: 0.7150442477876106 and parameters: {'C': 8.479869451444385, 'l1_ratio': 0.05221566525147339}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:14,208]\u001b[0m Trial 142 finished with value: 0.7152051488334674 and parameters: {'C': 21.049942890391172, 'l1_ratio': 0.050878818510310626}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:16,238]\u001b[0m Trial 143 finished with value: 0.7150442477876106 and parameters: {'C': 35.51656184939903, 'l1_ratio': 0.17793891832264644}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:18,211]\u001b[0m Trial 144 finished with value: 0.7150442477876106 and parameters: {'C': 33.37523951229965, 'l1_ratio': 0.1988352401939948}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:20,182]\u001b[0m Trial 145 finished with value: 0.7152051488334674 and parameters: {'C': 15.421898009699557, 'l1_ratio': 0.23319384806824328}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:22,077]\u001b[0m Trial 146 finished with value: 0.7152051488334674 and parameters: {'C': 11.10283946661083, 'l1_ratio': 0.08033028412178862}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:24,029]\u001b[0m Trial 147 finished with value: 0.7152051488334674 and parameters: {'C': 16.340625292309173, 'l1_ratio': 0.20580666675984904}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:26,002]\u001b[0m Trial 148 finished with value: 0.7152051488334674 and parameters: {'C': 17.08981659503197, 'l1_ratio': 0.1625259599757804}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:28,027]\u001b[0m Trial 149 finished with value: 0.7152051488334674 and parameters: {'C': 28.201106675769367, 'l1_ratio': 0.1403534054713803}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:29,947]\u001b[0m Trial 150 finished with value: 0.7150442477876106 and parameters: {'C': 60.582751178540015, 'l1_ratio': 0.1417688149989651}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:32,023]\u001b[0m Trial 151 finished with value: 0.7150442477876106 and parameters: {'C': 42.47072156385064, 'l1_ratio': 0.1686848264384998}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:34,162]\u001b[0m Trial 152 finished with value: 0.7152051488334674 and parameters: {'C': 15.622051226135786, 'l1_ratio': 0.10427388952392397}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:36,032]\u001b[0m Trial 153 finished with value: 0.7150442477876106 and parameters: {'C': 7.5939446264513, 'l1_ratio': 0.03886567596379957}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:37,979]\u001b[0m Trial 154 finished with value: 0.7152051488334674 and parameters: {'C': 10.553682064424333, 'l1_ratio': 0.05742057714942313}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:39,825]\u001b[0m Trial 155 finished with value: 0.7152051488334674 and parameters: {'C': 11.073147934873058, 'l1_ratio': 0.031953952317381545}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:41,694]\u001b[0m Trial 156 finished with value: 0.7152051488334675 and parameters: {'C': 6.130205013699228, 'l1_ratio': 0.003641102063642617}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:43,218]\u001b[0m Trial 157 finished with value: 0.7148833467417538 and parameters: {'C': 1.9840841186550082, 'l1_ratio': 0.077564603541222}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:45,010]\u001b[0m Trial 158 finished with value: 0.7150442477876107 and parameters: {'C': 5.529357462692991, 'l1_ratio': 0.0019276700275270198}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:47,049]\u001b[0m Trial 159 finished with value: 0.7152051488334674 and parameters: {'C': 23.170046460170187, 'l1_ratio': 0.25499839555471204}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:49,026]\u001b[0m Trial 160 finished with value: 0.7152051488334674 and parameters: {'C': 20.968172427411183, 'l1_ratio': 0.3062998291480208}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:51,141]\u001b[0m Trial 161 finished with value: 0.7152051488334674 and parameters: {'C': 21.495493358021708, 'l1_ratio': 0.30006250478578994}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:53,042]\u001b[0m Trial 162 finished with value: 0.7152051488334674 and parameters: {'C': 14.809240161044904, 'l1_ratio': 0.2317491334488265}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:53,582]\u001b[0m Trial 163 finished with value: 0.7140788415124698 and parameters: {'C': 0.08547903737652816, 'l1_ratio': 0.0017766500977647696}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:55,602]\u001b[0m Trial 164 finished with value: 0.7152051488334674 and parameters: {'C': 15.529905069941197, 'l1_ratio': 0.2026242347447798}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:57,424]\u001b[0m Trial 165 finished with value: 0.7148833467417537 and parameters: {'C': 8.963076134513981, 'l1_ratio': 0.26595838746148825}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:11:59,277]\u001b[0m Trial 166 finished with value: 0.7150442477876106 and parameters: {'C': 6.532903214760619, 'l1_ratio': 0.1252336729743008}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:01,371]\u001b[0m Trial 167 finished with value: 0.7152051488334674 and parameters: {'C': 33.40712683495498, 'l1_ratio': 0.03442046432071074}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:01,816]\u001b[0m Trial 168 finished with value: 0.7144006436041834 and parameters: {'C': 0.03764449236871124, 'l1_ratio': 0.034953288976006455}. Best is trial 105 with value: 0.7152051488334675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:02,661]\u001b[0m Trial 169 finished with value: 0.7153660498793242 and parameters: {'C': 0.2884018101384221, 'l1_ratio': 0.08320137486963063}. Best is trial 169 with value: 0.7153660498793242.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:03,457]\u001b[0m Trial 170 finished with value: 0.7155269509251809 and parameters: {'C': 0.27677434769738374, 'l1_ratio': 0.06855329257415738}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:04,375]\u001b[0m Trial 171 finished with value: 0.7142397425583267 and parameters: {'C': 0.44035071349287097, 'l1_ratio': 0.019733451253188896}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:05,140]\u001b[0m Trial 172 finished with value: 0.7145615446500402 and parameters: {'C': 0.16668534486889033, 'l1_ratio': 0.05671230538238867}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:05,796]\u001b[0m Trial 173 finished with value: 0.7111826226870475 and parameters: {'C': 0.0120769685122554, 'l1_ratio': 0.1447060378729253}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:07,656]\u001b[0m Trial 174 finished with value: 0.7150442477876107 and parameters: {'C': 4.184139220917719, 'l1_ratio': 0.07341642696091366}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:08,495]\u001b[0m Trial 175 finished with value: 0.7144006436041834 and parameters: {'C': 0.307132282224173, 'l1_ratio': 0.16665667194576858}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:09,850]\u001b[0m Trial 176 finished with value: 0.7142397425583266 and parameters: {'C': 1.4423500227178925, 'l1_ratio': 0.09830705151250627}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:10,292]\u001b[0m Trial 177 finished with value: 0.7145615446500402 and parameters: {'C': 0.02197800750797636, 'l1_ratio': 0.08910634553495403}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:10,957]\u001b[0m Trial 178 finished with value: 0.7144006436041834 and parameters: {'C': 0.0696185487040879, 'l1_ratio': 0.11310338950586613}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:12,111]\u001b[0m Trial 179 finished with value: 0.7134352373290426 and parameters: {'C': 0.6936858748157577, 'l1_ratio': 0.28710923302924396}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:14,097]\u001b[0m Trial 180 finished with value: 0.7152051488334674 and parameters: {'C': 37.265150882407234, 'l1_ratio': 0.04710284534120568}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:16,111]\u001b[0m Trial 181 finished with value: 0.7152051488334674 and parameters: {'C': 19.334266308854094, 'l1_ratio': 0.24192816468105668}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:16,533]\u001b[0m Trial 182 finished with value: 0.6920353982300885 and parameters: {'C': 0.006300945243161573, 'l1_ratio': 0.5079240168351358}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:18,467]\u001b[0m Trial 183 finished with value: 0.7152051488334674 and parameters: {'C': 28.335511110631884, 'l1_ratio': 0.022818976536334697}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:20,521]\u001b[0m Trial 184 finished with value: 0.7152051488334674 and parameters: {'C': 12.76059813361837, 'l1_ratio': 0.187366933709406}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:20,936]\u001b[0m Trial 185 finished with value: 0.5975864843121481 and parameters: {'C': 0.0004152341337096023, 'l1_ratio': 0.18873998766492578}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:23,118]\u001b[0m Trial 186 finished with value: 0.7152051488334674 and parameters: {'C': 24.820906240021234, 'l1_ratio': 0.1521887180288634}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:25,188]\u001b[0m Trial 187 finished with value: 0.7150442477876106 and parameters: {'C': 12.141128182315652, 'l1_ratio': 0.22761443061987022}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:27,368]\u001b[0m Trial 188 finished with value: 0.7150442477876106 and parameters: {'C': 46.927601639650966, 'l1_ratio': 0.11794525749880319}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:29,199]\u001b[0m Trial 189 finished with value: 0.7150442477876106 and parameters: {'C': 7.950537483129577, 'l1_ratio': 0.004970915809240326}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:30,886]\u001b[0m Trial 190 finished with value: 0.7150442477876107 and parameters: {'C': 3.125879520007602, 'l1_ratio': 0.002208180479083344}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:32,979]\u001b[0m Trial 191 finished with value: 0.7152051488334674 and parameters: {'C': 28.12337172587549, 'l1_ratio': 0.15733534007322794}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:34,906]\u001b[0m Trial 192 finished with value: 0.7152051488334674 and parameters: {'C': 10.707782890308057, 'l1_ratio': 0.027617477443031214}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:36,689]\u001b[0m Trial 193 finished with value: 0.7150442477876106 and parameters: {'C': 8.446035569921085, 'l1_ratio': 0.04624686156283499}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:38,721]\u001b[0m Trial 194 finished with value: 0.7152051488334674 and parameters: {'C': 16.04479669993495, 'l1_ratio': 0.0665652420951692}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:40,628]\u001b[0m Trial 195 finished with value: 0.7152051488334674 and parameters: {'C': 18.93681229552914, 'l1_ratio': 0.09174604335012113}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:42,468]\u001b[0m Trial 196 finished with value: 0.7148833467417538 and parameters: {'C': 4.811928794941547, 'l1_ratio': 0.07859222096226672}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:44,348]\u001b[0m Trial 197 finished with value: 0.7152051488334674 and parameters: {'C': 13.336557479765759, 'l1_ratio': 0.04868128142690679}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:46,527]\u001b[0m Trial 198 finished with value: 0.7152051488334674 and parameters: {'C': 16.296956645035745, 'l1_ratio': 0.04446560532983636}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:48,496]\u001b[0m Trial 199 finished with value: 0.7152051488334674 and parameters: {'C': 23.92404512079628, 'l1_ratio': 0.011572514746626829}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:50,463]\u001b[0m Trial 200 finished with value: 0.7152051488334675 and parameters: {'C': 6.547571423617967, 'l1_ratio': 0.01617306005932831}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:52,258]\u001b[0m Trial 201 finished with value: 0.7150442477876107 and parameters: {'C': 5.980060010843753, 'l1_ratio': 0.02557514612729267}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:54,121]\u001b[0m Trial 202 finished with value: 0.7150442477876106 and parameters: {'C': 10.487451725622966, 'l1_ratio': 0.13912607675764307}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:56,044]\u001b[0m Trial 203 finished with value: 0.7152051488334674 and parameters: {'C': 14.33139031520466, 'l1_ratio': 0.10484738710412667}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:57,919]\u001b[0m Trial 204 finished with value: 0.7150442477876106 and parameters: {'C': 7.4893008174095375, 'l1_ratio': 0.01968531068541072}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:12:59,801]\u001b[0m Trial 205 finished with value: 0.7152051488334674 and parameters: {'C': 10.423444990943182, 'l1_ratio': 0.06277518876625009}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:01,737]\u001b[0m Trial 206 finished with value: 0.7150442477876106 and parameters: {'C': 6.759504182120621, 'l1_ratio': 0.023292768747038756}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:02,994]\u001b[0m Trial 207 finished with value: 0.713917940466613 and parameters: {'C': 0.9723118049294366, 'l1_ratio': 0.08155923895638509}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:03,516]\u001b[0m Trial 208 finished with value: 0.7140788415124699 and parameters: {'C': 0.05545414264483101, 'l1_ratio': 0.17842566741286503}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:04,058]\u001b[0m Trial 209 finished with value: 0.7152051488334674 and parameters: {'C': 0.13933104451862555, 'l1_ratio': 0.2163816043462583}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:06,029]\u001b[0m Trial 210 finished with value: 0.7152051488334674 and parameters: {'C': 24.30484356364435, 'l1_ratio': 0.0044010167219349534}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:06,641]\u001b[0m Trial 211 finished with value: 0.7148833467417537 and parameters: {'C': 0.13927039999296453, 'l1_ratio': 0.054185018896822194}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:08,702]\u001b[0m Trial 212 finished with value: 0.7150442477876106 and parameters: {'C': 41.667216560720085, 'l1_ratio': 0.24438969190494245}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:10,607]\u001b[0m Trial 213 finished with value: 0.7152051488334674 and parameters: {'C': 11.482761586904548, 'l1_ratio': 0.07105245179570828}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:12,516]\u001b[0m Trial 214 finished with value: 0.7152051488334674 and parameters: {'C': 10.422714003185037, 'l1_ratio': 0.06363619665833467}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:14,457]\u001b[0m Trial 215 finished with value: 0.7150442477876106 and parameters: {'C': 9.377543107411707, 'l1_ratio': 0.08402324421267889}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:16,382]\u001b[0m Trial 216 finished with value: 0.7152051488334674 and parameters: {'C': 16.554238466283184, 'l1_ratio': 0.03853352027155965}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:18,362]\u001b[0m Trial 217 finished with value: 0.7150442477876106 and parameters: {'C': 37.148196078545446, 'l1_ratio': 0.12215039450507365}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:20,277]\u001b[0m Trial 218 finished with value: 0.7152051488334674 and parameters: {'C': 21.193605483029387, 'l1_ratio': 0.26601944871729316}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:22,231]\u001b[0m Trial 219 finished with value: 0.7152051488334674 and parameters: {'C': 19.331451393617215, 'l1_ratio': 0.046285298747749073}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:24,164]\u001b[0m Trial 220 finished with value: 0.7152051488334674 and parameters: {'C': 16.41949544837463, 'l1_ratio': 0.036637515754624435}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:26,180]\u001b[0m Trial 221 finished with value: 0.7150442477876106 and parameters: {'C': 21.596935336594658, 'l1_ratio': 0.34827078309441806}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:28,130]\u001b[0m Trial 222 finished with value: 0.7150442477876106 and parameters: {'C': 33.074033678378285, 'l1_ratio': 0.25176331240704836}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:30,098]\u001b[0m Trial 223 finished with value: 0.7148833467417537 and parameters: {'C': 14.105786884490529, 'l1_ratio': 0.3841995427387529}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:31,959]\u001b[0m Trial 224 finished with value: 0.7152051488334674 and parameters: {'C': 12.91765971388511, 'l1_ratio': 0.022482068522277503}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:33,898]\u001b[0m Trial 225 finished with value: 0.7150442477876106 and parameters: {'C': 31.133981875629768, 'l1_ratio': 0.3361069689083285}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:35,667]\u001b[0m Trial 226 finished with value: 0.7147224456958969 and parameters: {'C': 4.676578308153037, 'l1_ratio': 0.30081038083288475}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:37,636]\u001b[0m Trial 227 finished with value: 0.7152051488334674 and parameters: {'C': 14.487635224982121, 'l1_ratio': 0.19744482514475284}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:39,631]\u001b[0m Trial 228 finished with value: 0.7152051488334674 and parameters: {'C': 26.18821741202913, 'l1_ratio': 0.21013862351055287}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:41,729]\u001b[0m Trial 229 finished with value: 0.7150442477876106 and parameters: {'C': 69.10411330791044, 'l1_ratio': 0.033027589217215075}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:43,777]\u001b[0m Trial 230 finished with value: 0.7150442477876106 and parameters: {'C': 45.21391915373222, 'l1_ratio': 0.17846519573930192}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:45,781]\u001b[0m Trial 231 finished with value: 0.7152051488334674 and parameters: {'C': 21.882502416830558, 'l1_ratio': 0.24275896271777045}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:47,611]\u001b[0m Trial 232 finished with value: 0.7152051488334674 and parameters: {'C': 8.36415552126787, 'l1_ratio': 0.001097551453180635}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:49,482]\u001b[0m Trial 233 finished with value: 0.7152051488334675 and parameters: {'C': 6.270029714675203, 'l1_ratio': 0.017941014963912344}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:51,123]\u001b[0m Trial 234 finished with value: 0.7152051488334674 and parameters: {'C': 3.285765551641069, 'l1_ratio': 0.0589699964114981}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:52,975]\u001b[0m Trial 235 finished with value: 0.7150442477876106 and parameters: {'C': 6.7932870359115896, 'l1_ratio': 0.01946697215999907}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:54,966]\u001b[0m Trial 236 finished with value: 0.7152051488334674 and parameters: {'C': 20.60338983849315, 'l1_ratio': 0.2352033028057326}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:56,753]\u001b[0m Trial 237 finished with value: 0.7148833467417538 and parameters: {'C': 5.067402487651474, 'l1_ratio': 0.10058444122495405}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:58,719]\u001b[0m Trial 238 finished with value: 0.7152051488334674 and parameters: {'C': 17.578087965269436, 'l1_ratio': 0.06715737689807984}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:13:59,167]\u001b[0m Trial 239 finished with value: 0.6994368463395013 and parameters: {'C': 0.001793592980087231, 'l1_ratio': 0.03216858261804001}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:01,307]\u001b[0m Trial 240 finished with value: 0.7148833467417537 and parameters: {'C': 12.532962677815693, 'l1_ratio': 0.2816581949226825}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:03,287]\u001b[0m Trial 241 finished with value: 0.7150442477876106 and parameters: {'C': 23.557189865880265, 'l1_ratio': 0.3110584010104181}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:05,117]\u001b[0m Trial 242 finished with value: 0.7152051488334674 and parameters: {'C': 8.475821134178858, 'l1_ratio': 0.001144738257337477}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:07,020]\u001b[0m Trial 243 finished with value: 0.7152051488334674 and parameters: {'C': 9.865929570447223, 'l1_ratio': 0.05421726301861097}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:08,819]\u001b[0m Trial 244 finished with value: 0.7152051488334675 and parameters: {'C': 6.478514055138407, 'l1_ratio': 0.05185899957067354}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:10,617]\u001b[0m Trial 245 finished with value: 0.7152051488334675 and parameters: {'C': 6.467548249277595, 'l1_ratio': 0.04843710005144118}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:12,371]\u001b[0m Trial 246 finished with value: 0.7150442477876107 and parameters: {'C': 5.819281721819109, 'l1_ratio': 0.05409818678595271}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:14,021]\u001b[0m Trial 247 finished with value: 0.7150442477876107 and parameters: {'C': 2.4485282370554176, 'l1_ratio': 0.21953156240861182}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:15,783]\u001b[0m Trial 248 finished with value: 0.7150442477876107 and parameters: {'C': 4.213320168921133, 'l1_ratio': 0.0822040881587361}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:17,556]\u001b[0m Trial 249 finished with value: 0.7150442477876107 and parameters: {'C': 6.204548603951436, 'l1_ratio': 0.1344610031379541}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:18,409]\u001b[0m Trial 250 finished with value: 0.7152051488334674 and parameters: {'C': 0.35376076607073026, 'l1_ratio': 0.2086165221217388}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:20,313]\u001b[0m Trial 251 finished with value: 0.7150442477876106 and parameters: {'C': 8.436148279114395, 'l1_ratio': 0.02869069916587263}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:22,332]\u001b[0m Trial 252 finished with value: 0.7152051488334674 and parameters: {'C': 33.773779216236775, 'l1_ratio': 0.1049922495731981}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:24,174]\u001b[0m Trial 253 finished with value: 0.7152051488334674 and parameters: {'C': 11.867893106451389, 'l1_ratio': 0.048094452186024726}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:25,990]\u001b[0m Trial 254 finished with value: 0.7152051488334675 and parameters: {'C': 6.555797490777726, 'l1_ratio': 0.08997968962582042}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:27,683]\u001b[0m Trial 255 finished with value: 0.7150442477876107 and parameters: {'C': 4.356891971720534, 'l1_ratio': 0.08467008982294699}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:29,467]\u001b[0m Trial 256 finished with value: 0.7150442477876107 and parameters: {'C': 6.444666072415685, 'l1_ratio': 0.13230665897883667}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:31,269]\u001b[0m Trial 257 finished with value: 0.7150442477876107 and parameters: {'C': 5.963480186850708, 'l1_ratio': 0.09239775978072065}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:32,955]\u001b[0m Trial 258 finished with value: 0.7150442477876107 and parameters: {'C': 2.9834353751820872, 'l1_ratio': 0.06380176929771658}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:33,681]\u001b[0m Trial 259 finished with value: 0.7152051488334674 and parameters: {'C': 0.23043305767346106, 'l1_ratio': 0.010004258635158855}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:35,648]\u001b[0m Trial 260 finished with value: 0.7150442477876106 and parameters: {'C': 8.583874248434899, 'l1_ratio': 0.09836211711936024}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:36,577]\u001b[0m Trial 261 finished with value: 0.7142397425583267 and parameters: {'C': 0.4881714750739675, 'l1_ratio': 0.014303612189899922}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:38,381]\u001b[0m Trial 262 finished with value: 0.7148833467417539 and parameters: {'C': 4.074724216963614, 'l1_ratio': 0.1827362381239252}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:40,116]\u001b[0m Trial 263 finished with value: 0.7150442477876106 and parameters: {'C': 7.607176634976527, 'l1_ratio': 0.034645976578761874}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:41,999]\u001b[0m Trial 264 finished with value: 0.7152051488334674 and parameters: {'C': 16.24028858108672, 'l1_ratio': 0.16319019923398467}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:43,991]\u001b[0m Trial 265 finished with value: 0.7152051488334674 and parameters: {'C': 13.693664224831707, 'l1_ratio': 0.07676406823466049}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:45,923]\u001b[0m Trial 266 finished with value: 0.7152051488334674 and parameters: {'C': 24.529249610770712, 'l1_ratio': 0.07603912008103748}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:47,939]\u001b[0m Trial 267 finished with value: 0.7145615446500402 and parameters: {'C': 9.993553476799404, 'l1_ratio': 0.8494821673048323}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:49,738]\u001b[0m Trial 268 finished with value: 0.7150442477876107 and parameters: {'C': 5.470987103383357, 'l1_ratio': 0.02222227322399306}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:51,750]\u001b[0m Trial 269 finished with value: 0.7150442477876106 and parameters: {'C': 50.48043112339463, 'l1_ratio': 0.22947038524987992}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:53,574]\u001b[0m Trial 270 finished with value: 0.7152051488334674 and parameters: {'C': 13.531541757824314, 'l1_ratio': 0.050897007418002266}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:55,582]\u001b[0m Trial 271 finished with value: 0.7152051488334674 and parameters: {'C': 17.705021141719833, 'l1_ratio': 0.05291878345343041}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:57,485]\u001b[0m Trial 272 finished with value: 0.7152051488334674 and parameters: {'C': 11.211091286938977, 'l1_ratio': 0.06494415390372665}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:14:59,457]\u001b[0m Trial 273 finished with value: 0.7152051488334674 and parameters: {'C': 16.753998955453188, 'l1_ratio': 0.06442682204415838}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:00,967]\u001b[0m Trial 274 finished with value: 0.714722445695897 and parameters: {'C': 1.831114002077708, 'l1_ratio': 0.06578370954125223}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:02,658]\u001b[0m Trial 275 finished with value: 0.7150442477876107 and parameters: {'C': 3.455440167144166, 'l1_ratio': 0.11394990812774455}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:04,560]\u001b[0m Trial 276 finished with value: 0.7148833467417537 and parameters: {'C': 32.65497539261722, 'l1_ratio': 0.5975203882698227}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:06,454]\u001b[0m Trial 277 finished with value: 0.7152051488334674 and parameters: {'C': 9.659677425976657, 'l1_ratio': 0.040827952940999584}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:08,336]\u001b[0m Trial 278 finished with value: 0.7150442477876106 and parameters: {'C': 6.995323086123797, 'l1_ratio': 0.0022384121505030974}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:10,277]\u001b[0m Trial 279 finished with value: 0.7152051488334674 and parameters: {'C': 20.287559059537504, 'l1_ratio': 0.04162283430379973}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:12,300]\u001b[0m Trial 280 finished with value: 0.7150442477876106 and parameters: {'C': 46.87647457042109, 'l1_ratio': 0.1290976380657692}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:14,432]\u001b[0m Trial 281 finished with value: 0.7152051488334674 and parameters: {'C': 13.890616969070845, 'l1_ratio': 0.1539598586417999}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:15,319]\u001b[0m Trial 282 finished with value: 0.7150442477876107 and parameters: {'C': 0.3200467294548996, 'l1_ratio': 0.03042544632622265}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:17,108]\u001b[0m Trial 283 finished with value: 0.7148833467417538 and parameters: {'C': 4.840143370657201, 'l1_ratio': 0.09357374713845171}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:19,016]\u001b[0m Trial 284 finished with value: 0.7150442477876106 and parameters: {'C': 8.061694481638018, 'l1_ratio': 0.02459998777778946}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:19,703]\u001b[0m Trial 285 finished with value: 0.7144006436041834 and parameters: {'C': 0.2040892281139527, 'l1_ratio': 0.06362571754558448}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:21,509]\u001b[0m Trial 286 finished with value: 0.7150442477876107 and parameters: {'C': 5.701422145603798, 'l1_ratio': 0.04299760942677611}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:23,529]\u001b[0m Trial 287 finished with value: 0.7152051488334674 and parameters: {'C': 24.818906550607622, 'l1_ratio': 0.08907764094816292}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:25,617]\u001b[0m Trial 288 finished with value: 0.7147224456958969 and parameters: {'C': 12.060105090222468, 'l1_ratio': 0.4480955527501467}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:27,026]\u001b[0m Trial 289 finished with value: 0.7140788415124698 and parameters: {'C': 1.0863748102835773, 'l1_ratio': 0.15169155314051852}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:28,948]\u001b[0m Trial 290 finished with value: 0.7152051488334674 and parameters: {'C': 14.222673409298112, 'l1_ratio': 0.08481469783244511}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:31,051]\u001b[0m Trial 291 finished with value: 0.7150442477876106 and parameters: {'C': 31.872552024712277, 'l1_ratio': 0.2444868719353209}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:31,512]\u001b[0m Trial 292 finished with value: 0.7142397425583267 and parameters: {'C': 0.0275230306396429, 'l1_ratio': 0.016516127884798067}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:33,485]\u001b[0m Trial 293 finished with value: 0.7152051488334674 and parameters: {'C': 16.62128593671538, 'l1_ratio': 0.29751361696200274}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:35,622]\u001b[0m Trial 294 finished with value: 0.7150442477876106 and parameters: {'C': 67.1516004001057, 'l1_ratio': 0.03926577621977324}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:36,253]\u001b[0m Trial 295 finished with value: 0.7150442477876104 and parameters: {'C': 0.1386384558660036, 'l1_ratio': 0.20369191083146715}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:36,648]\u001b[0m Trial 296 finished with value: 0.588897827835881 and parameters: {'C': 4.411393522445246e-05, 'l1_ratio': 0.012085412328459054}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:38,579]\u001b[0m Trial 297 finished with value: 0.7150442477876106 and parameters: {'C': 10.086884220978336, 'l1_ratio': 0.22216090052299456}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:40,399]\u001b[0m Trial 298 finished with value: 0.7150442477876106 and parameters: {'C': 7.487031221508137, 'l1_ratio': 0.03375913637246512}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:15:42,071]\u001b[0m Trial 299 finished with value: 0.7150442477876107 and parameters: {'C': 3.8161248991668044, 'l1_ratio': 0.029728266483166454}. Best is trial 170 with value: 0.7155269509251809.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    lr_C = trial.suggest_float('C', 1e-5, 1e2, log=True)\n",
    "    lr_l1_ratio = trial.suggest_float('l1_ratio', 0, 1, log=False)\n",
    "    \n",
    "    classifier_obj = Pipeline([('scaler', StandardScaler()),\n",
    "                                ('logreg', LogisticRegression(solver='saga',\n",
    "                                                              C=lr_C,\n",
    "                                                            penalty='elasticnet',\n",
    "                                                            max_iter=10000,\n",
    "                                                            verbose=1,\n",
    "                                                            l1_ratio=lr_l1_ratio,\n",
    "                                                            random_state=23))])\n",
    "    \n",
    "    score = cross_val_score(classifier_obj, X_train_selected, y_train, n_jobs=-1,\n",
    "                           cv=tscv, scoring='accuracy')\n",
    "    \n",
    "    \n",
    "    score_avg = score.mean()\n",
    "    \n",
    "    return score_avg\n",
    "\n",
    "study_name = '../models/hyperparameter_tuning/study_logistic_regression_rfe_no_ML'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_lr = optuna.create_study(study_name = study_name, direction='maximize', \n",
    "                               storage = storage_name, load_if_exists=True)\n",
    "\n",
    "study_lr.optimize(objective, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "71ca8155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27677434769738374 0.06855329257415738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jordan Nishimura\\NBA_Model_v1\\nba-model-venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 43 epochs took 0 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('logreg',\n",
      "                 LogisticRegression(C=0.27677434769738374,\n",
      "                                    l1_ratio=0.06855329257415738,\n",
      "                                    max_iter=10000, random_state=23,\n",
      "                                    solver='saga', verbose=1))])\n",
      "train_acc: 0.7264682220434433\n",
      "test_acc: 0.6743261157755193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AWAY_EFG_PCT_L5</td>\n",
       "      <td>-0.647334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AWAY_FG2M_L5</td>\n",
       "      <td>-0.548273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HOME_TS_PCT_L5</td>\n",
       "      <td>-0.375517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOME_AST_2PM_L5</td>\n",
       "      <td>-0.273866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOME_UAST_2PM_L5</td>\n",
       "      <td>-0.260442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AWAY_FG3A_L10</td>\n",
       "      <td>-0.254344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HOME_PLUS_MINUS_opp_L20</td>\n",
       "      <td>-0.203113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>AWAY_EFG_PCT_L20</td>\n",
       "      <td>-0.200242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>AWAY_WIN_PCT_L20</td>\n",
       "      <td>-0.151859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HOME_UFGA_opp_L5</td>\n",
       "      <td>-0.150051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HOME_FG3A_opp_L20</td>\n",
       "      <td>-0.145983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AWAY_FG3A_L20</td>\n",
       "      <td>-0.136720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AWAY_FTM_L5</td>\n",
       "      <td>-0.133393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>AWAY_COVER_PCT_L20</td>\n",
       "      <td>-0.127602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AWAY_FTM_L20</td>\n",
       "      <td>-0.115014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AWAY_DFGA_opp_L5</td>\n",
       "      <td>-0.111914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AWAY_RBC_L20</td>\n",
       "      <td>-0.111767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AWAY_AVG_ATS_DIFF_L20</td>\n",
       "      <td>-0.097577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HOME_PF_L20</td>\n",
       "      <td>-0.088825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOME_POSS_opp_L5</td>\n",
       "      <td>-0.087740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AWAY_NET_RATING_L20</td>\n",
       "      <td>-0.082044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HOME_ORBC_opp_L5</td>\n",
       "      <td>-0.080997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HOME_FTAST_opp_L20</td>\n",
       "      <td>-0.067763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AWAY_AVG_ATS_DIFF_L5</td>\n",
       "      <td>-0.041879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HOME_FG3A_L10</td>\n",
       "      <td>0.035455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AWAY_UFGA_opp_L5</td>\n",
       "      <td>0.058800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HOME_WIN_PCT_L20</td>\n",
       "      <td>0.060699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AWAY_SAST_opp_L20</td>\n",
       "      <td>0.062270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>AWAY_EFG_PCT_opp_L20</td>\n",
       "      <td>0.067662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AWAY_NET_RATING_opp_L20</td>\n",
       "      <td>0.082044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOME_FTM_L5</td>\n",
       "      <td>0.091509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AWAY_FTA_opp_L10</td>\n",
       "      <td>0.107089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AWAY_PTS_PAINT_L5</td>\n",
       "      <td>0.108998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AWAY_DFGA_L20</td>\n",
       "      <td>0.109204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AWAY_PTS_2PT_MR_opp_L5</td>\n",
       "      <td>0.116162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HOME_FTM_L10</td>\n",
       "      <td>0.129458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AWAY_CFGM_L10</td>\n",
       "      <td>0.141012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AWAY_UFGM_L5</td>\n",
       "      <td>0.156571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HOME_PIE_L20</td>\n",
       "      <td>0.165411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HOME_PLUS_MINUS_L20</td>\n",
       "      <td>0.203113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AWAY_FG3A_opp_L10</td>\n",
       "      <td>0.206673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HOME_AVG_ATS_DIFF_L20</td>\n",
       "      <td>0.225762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HOME_FG3A_L20</td>\n",
       "      <td>0.294964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HOME_EFG_PCT_L5</td>\n",
       "      <td>0.461233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AWAY_TS_PCT_L5</td>\n",
       "      <td>0.466128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOME_FG2M_L5</td>\n",
       "      <td>0.663093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature_name      coef\n",
       "29          AWAY_EFG_PCT_L5 -0.647334\n",
       "20             AWAY_FG2M_L5 -0.548273\n",
       "7            HOME_TS_PCT_L5 -0.375517\n",
       "2           HOME_AST_2PM_L5 -0.273866\n",
       "3          HOME_UAST_2PM_L5 -0.260442\n",
       "30            AWAY_FG3A_L10 -0.254344\n",
       "15  HOME_PLUS_MINUS_opp_L20 -0.203113\n",
       "44         AWAY_EFG_PCT_L20 -0.200242\n",
       "42         AWAY_WIN_PCT_L20 -0.151859\n",
       "6          HOME_UFGA_opp_L5 -0.150051\n",
       "14        HOME_FG3A_opp_L20 -0.145983\n",
       "34            AWAY_FG3A_L20 -0.136720\n",
       "21              AWAY_FTM_L5 -0.133393\n",
       "43       AWAY_COVER_PCT_L20 -0.127602\n",
       "35             AWAY_FTM_L20 -0.115014\n",
       "25         AWAY_DFGA_opp_L5 -0.111914\n",
       "37             AWAY_RBC_L20 -0.111767\n",
       "41    AWAY_AVG_ATS_DIFF_L20 -0.097577\n",
       "12              HOME_PF_L20 -0.088825\n",
       "4          HOME_POSS_opp_L5 -0.087740\n",
       "36      AWAY_NET_RATING_L20 -0.082044\n",
       "5          HOME_ORBC_opp_L5 -0.080997\n",
       "16       HOME_FTAST_opp_L20 -0.067763\n",
       "27     AWAY_AVG_ATS_DIFF_L5 -0.041879\n",
       "9             HOME_FG3A_L10  0.035455\n",
       "24         AWAY_UFGA_opp_L5  0.058800\n",
       "18         HOME_WIN_PCT_L20  0.060699\n",
       "40        AWAY_SAST_opp_L20  0.062270\n",
       "45     AWAY_EFG_PCT_opp_L20  0.067662\n",
       "39  AWAY_NET_RATING_opp_L20  0.082044\n",
       "1               HOME_FTM_L5  0.091509\n",
       "33         AWAY_FTA_opp_L10  0.107089\n",
       "23        AWAY_PTS_PAINT_L5  0.108998\n",
       "38            AWAY_DFGA_L20  0.109204\n",
       "26   AWAY_PTS_2PT_MR_opp_L5  0.116162\n",
       "10             HOME_FTM_L10  0.129458\n",
       "31            AWAY_CFGM_L10  0.141012\n",
       "22             AWAY_UFGM_L5  0.156571\n",
       "19             HOME_PIE_L20  0.165411\n",
       "13      HOME_PLUS_MINUS_L20  0.203113\n",
       "32        AWAY_FG3A_opp_L10  0.206673\n",
       "17    HOME_AVG_ATS_DIFF_L20  0.225762\n",
       "11            HOME_FG3A_L20  0.294964\n",
       "8           HOME_EFG_PCT_L5  0.461233\n",
       "28           AWAY_TS_PCT_L5  0.466128\n",
       "0              HOME_FG2M_L5  0.663093"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_C = study_lr.best_params['C']\n",
    "lr_l1_ratio = study_lr.best_params['l1_ratio']\n",
    "print(lr_C, lr_l1_ratio)\n",
    "\n",
    "best_lr = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('logreg', LogisticRegression(solver='saga', C=lr_C,\n",
    "                                                  penalty='l2', max_iter=10000,\n",
    "                                                 verbose=1, l1_ratio = lr_l1_ratio,\n",
    "                                                 random_state=23))])\n",
    "best_lr.fit(X_train_selected, y_train)\n",
    "\n",
    "print(best_lr)\n",
    "\n",
    "print(\"train_acc:\", best_lr.score(X_train_selected, y_train))\n",
    "print(\"test_acc:\", best_lr.score(X_val_selected, y_val))\n",
    "\n",
    "view_model_coefs(best_lr.named_steps['logreg'], X_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e21a0df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAKrCAYAAAAH5n81AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABfNElEQVR4nO3debxdVX3//9cbRAbBUuBKkekyqZUpkCtUiIxFqMyKNVGGIBT5FqvWQsHiz4KVOmFBZFCqDFIlKAoiKFaByJAw3GAgBBCJRAmiBkQBDVTI+/fHXgc2J3c49+YOYef9fDzO4+691tprffaJ8jlr7X3Olm0iIiLi5W2F8Q4gIiIill4SekRERAMkoUdERDRAEnpEREQDJKFHREQ0wCvGO4BYfq2zzjru7u4e7zAiIl5WZs2a9ZjtrvbyJPQYN93d3fT29o53GBERLyuSftFXeZbcIyIiGiAJPSIiogGS0CMiIhog19BjmfLnP/+ZBQsW8Mwzz4x3KKNilVVWYYMNNmCllVYa71AiomGS0GOZsmDBAtZYYw26u7uRNN7hjCjbPP744yxYsIBNNtlkvMOJiIbJknssU5555hnWXnvtxiVzAEmsvfbajV19iIjxlYQey5wmJvOWJp9bRIyvLLlHRHSg+6RrxjuEaIj5n9p3VPpNQo9l2kj/R3S0/o9U9+yzz7Lvvvvy2GOP8ZGPfIR3vetdoz5mREQSesQI+8lPfgLA7NmzxzeQiFiu5Bp6RJuvfvWrbLPNNmy77bYcdthhzJ8/nz322INtttmGPffck1/+8pcALFy4kHe84x286U1v4k1vehO33HILv/3tbzn00EO54447mDBhAvPmzRvns4mI5UVm6BE1c+fO5ROf+AQzZsxgnXXW4Xe/+x1HHHHEC68LLriAD3zgA1x55ZV88IMf5J//+Z+ZNGkSv/zlL9l777257777+PKXv8zpp5/O1VdfPd6nExHLkczQByHp6bb9qZLOru0fI+n+8rpd0qRa3XRJv1Tt1mZJV7b6lNQtaZGk2bXX4QPEMl/SnFrbnUr5FpKuljRP0ixJN0japdS9R9Ld5bgZkrat9WdJ/1Pbf4WkhZL6zUTt5992rj+txfaa/t/VZdf111/PO9/5TtZZZx0A1lprLWbOnMm73/1uAA477DBuvvlmAH70ox/x/ve/nwkTJnDAAQfw5JNP8vTTT/fbd0TEaMoMfSlI2g94HzDJ9mOStgeulLSD7V+XZr8HdgZulrQmsF5bN/NsTxjCsLvbfqwWwyrANcDxtq8qZVsBPcCNwEPArrafkPR3wPnAjuXwPwJbSVrV9iJgL+CRIcTS7j22l5vHpy1evJhbb72VVVZZZbxDiYjIDH0pnQic0Eqwtu8ELgaOq7WZBkwu228Hvj3CMbwHmNlK5iWOe2xfVLZn2H6iVN0KbNB2/PeA1q3fU4BLRzi+l5U99tiDb37zmzz++OMA/O53v2OnnXZi2rRpAHzta1/jLW95CwBvfetb+cIXvvDCsbkJLiLGU2bog1tV0uza/lpAK3luCcxqa98LHFHbvw74b0krUiX2Y4D/r1a/WVv//2T7pgHiuUHS88CztncsMdzZ4bkcBXy/rWwa8LGyzL4NcAHwlg77a3dhie1bwCdsu72BpGOo3gM22mijQTsci6+Z1W255ZacfPLJ7Lrrrqy44opst912fOELX+DII4/ks5/9LF1dXVx44YUAnHXWWRx33HFss802PPfcc+yyyy588YtfHNN4IyJaktAHt6i+JC5pKtVydqeeB26mSuar2p7f9mthS7Xk3k7SFcAWwAO2314r350qoU+qt7d9t6Ruqtn594YQR7v32H5E0hpUCf0w4KvtjWyfT7XsT09PzxIJf1nQugGu7vrrr1+i3TrrrMNll122RPluu+3GbrvtNlrhRUT0KUvuS+deYGJb2URgblvZNOAs4BujEMNcYPvWju2DgalUKwkASNoG+DJwoO3H++jjKuB0lmK53fYj5e9TwNeBHYbbV0REDF0S+tL5DPBpSWsDSJpAlUzPbWt3E/BJRuf69NeBnSUdUCtbrbUhaSOq6/aH2X6gnz4uAE61PWc4AZS749cp2ysB+wH3DKeviIgYniy5LwXbV0laH5ghycBTwKG2H21rZ6oZcF/ar6FfYPusIcSwqNxt/1+SzgR+U+L4RGnyMWBt4Nyy1P+c7Z62PhZQrSB0aqqkg2r7OwPfLsl8ReBHwH8Pob+XsN3Yh5j0cVtBRMSIUP4DE+Olp6fHvb0v/ZbbQw89xBprrNHIR6i2nof+1FNP5XnoL0N5OEuMlKW92VfSrPaJGWSGHsuYDTbYgAULFrBw4cLxDmVUrLLKKmywQfs3ByMill4S+jJI0m3Aym3Fhw33GvcwYzgS+GBb8S22j+ur/UhZaaWVMnuNiBiGLLnHuOlryT0iIgbW35J77nKPiIhogCT0iIiIBkhCj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBkhCj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBkhCj4iIaIBXjHcAEREvB90nXTPeIcQ4m/+pfcc7hAFlhh4REdEASegRERENkIQeERHRAEnoERERDZCEHhER0QDLRUKX9HTb/lRJZ9f2j5F0f3ndLmlSrW66pF9KUq3sylafkrolLZI0u/Y6fIBY5kuaU2t7Vim/SNJDtfIPlPLVJZ0naZ6kOyXNkvQPA/Rfj+deSV+UtEKpe52k70n6WenrG5LeVRvzaUk/Ldtf7af/3SRd3Ud5e/wT+osxIiJG3nL/tTVJ+wHvAybZfkzS9sCVknaw/evS7PfAzsDNktYE1mvrZp7tCUMYdnfbj/VRfoLty9vKvgz8HNjC9mJJXcB7B+l/nu0Jkl4BXA8cJOl7wDXAh21/F6rkDDzWil3SdOB4271DOJfB4o+IiDGwXMzQB3EiVSJ6DMD2ncDFwHG1NtOAyWX77cC3xyIwSZsBOwAftb24xLfQ9qc7Od72c8AMYHPg3cDMVjIv9dNt3zPykfevrIb0SupduHDhWA4dEdFoy0tCX7W+JA58vFa3JTCrrX1vKW+5DthF0opUif2ytvabtS25v2WQeG6otf3nWvlna+VblxjuaiXzoZK0GrAnMAfYiiXPc6SdJuluSWdIWrmvBrbPt91ju6erq2uUw4mIWH4sL0vui+pL4pKmAj1DOP554GaqZL6q7fm1S+owSkvukjapV0o6GXgn8Brbrx2g/83KBxcD37H9fUl7DSG+4fgI8GvglcD5VCsfHx/wiIiIGDHLywx9IPcCE9vKJgJz28qmAWcB3xiLoIp7gW1bN7XZPq18cHj1IMfNsz3B9na2Tyllc1nyPEeM7UddeRa4kOpSQUREjJEkdPgM8GlJawOUu7OnAue2tbsJ+CRw6VgFZvtBquX/T5TlfiStAmjAA/v2dWAnSS/8GLGkXSRtNRKxSlqv/BVwEDCm1+YjIpZ3y8uSe79sXyVpfWCGJANPAYfafrStnYHT++mmtcTdcoHtswYY9gZJz5ftu233+zU34Gjgs8CDkh4HFgH/OkD7PtleVO7oP1PSmcCfgbuBDw61L2BPSQtq+++kun7eRfVhYzZw7DD6jYiIYVKVpyLGXk9Pj3t7h/sNuYixlaetxbLytDVJs2wvcR9YltwjIiIaYLlfch8tkm4D2r+6dZjtOSPU/9bAJW3Fz9recYT63xto/777Q7YPHon+IyJiZGXJPcZNltwjIoYuS+4RERENloQeERHRAEnoERERDZCEHhER0QBJ6BEREQ2QhB4REdEASegRERENkIQeERHRAEnoERERDZCEHhER0QBJ6BEREQ2QhB4REdEASegRERENkIQeERHRAEnoERERDfCK8Q4gIuLloPuka8Y7hOXO/E/tO94hvKxkhh4REdEASegRERENkIQeERHRAEnoERERDZCEHhER0QBJ6IWkp9v2p0o6u7Z/jKT7y+t2SZNqddMl/VKSamVXtvqU1C1pkaTZtdfhA8QyX9KcWtudSvkWkq6WNE/SLEk3SNql1L1H0t3luBmStq31Z0n/U9t/haSFkq4eIIaXnH+t/DRJD/fxfq0s6TJJD0q6TVJ3f31HRMTIy9fWOiBpP+B9wCTbj0naHrhS0g62f12a/R7YGbhZ0prAem3dzLM9YQjD7m77sVoMqwDXAMfbvqqUbQX0ADcCDwG72n5C0t8B5wM7lsP/CGwlaVXbi4C9gEeGEEvdd4GzgZ+1lR8FPGF7c0mTgU8D7xrmGBERMUSZoXfmROCEVoK1fSdwMXBcrc00YHLZfjvw7RGO4T3AzFYyL3HcY/uisj3D9hOl6lZgg7bjvwe0vtQ5Bbh0OEHYvtX2o31UHUj1ngBcDuxZX7FoKSsdvZJ6Fy5cOJwQIiKiD0noL1q1viQOfLxWtyUwq619bylvuQ7YRdKKVIn9srb2m7Utub9lkHhuKO1uq8VwZ4fnchTw/bayacDkMtPfBrhtiaOWzvrAwwC2nwP+AKzd3sj2+bZ7bPd0dXWNcAgREcuvLLm/aFF9SVzSVKrl7E49D9xMlcxXtT2/bYK6VEvu7SRdAWwBPGD77bXy3akS+qR6e9t3l+vaU6hm6xER0SCZoXfmXmBiW9lEYG5b2TTgLOAboxDDXGD71o7tg4GpwFqtMknbAF8GDrT9eB99XAWczjCX2wfxCLBhieMVwF8AfcUQERGjIAm9M58BPi1pbQBJE6iS6blt7W4CPsnoJMyvAztLOqBWtlprQ9JGVNftD7P9QD99XACcanvOKMR3FXBE2T4EuN62R2GciIjoQ5bcO2D7KknrAzMkGXgKOLT95rCSwE7vp5vNyrX5lgtsnzWEGBaVu+3/S9KZwG9KHJ8oTT5Gdc363LLU/5ztnrY+FlCtIHRqqqSDavt/A3wAeDewmqQFwJdtnwJ8BbhE0oPA73jxBsGIiBgDyiQqxktPT497e3vHO4yIjuRpa2MvT1vrm6RZ7RM2yJJ7REREI2TJfRyVr6St3FZ82Chd4+4vhiOBD7YV32L7uL7aRyyvMluMZV0S+jiyvePgrUY9hguBC8c7joiIWDpZco+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBkhCj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBkhCj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGyONTIyI60H3SNeMdwstGnh0/PjJDj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0NpKebtufKuns2v4xku4vr9slTarVTZf0S0mqlV3Z6lNSt6RFkmbXXocPEMt8SXNqbXcq5VtIulrSPEmzJN0gaZdSd6Cku0v73np8pf5Dkp6R9BeDvA+7Sbq6j/KvSfqppHskXSBppVIuSWdJerCMv/1A/UdExMjK19aGQNJ+wPuASbYfK0nrSkk72P51afZ7YGfgZklrAuu1dTPP9oQhDLu77cdqMawCXAMcb/uqUrYV0APcCFwHXGXbkrYBvgG8odbfFOAO4O3AhUOIo+VrwKFl++vA0cB5wN8BW5TXjqVsx2H0HxERw5AZ+tCcCJzQSrC27wQuBo6rtZkGTC7bbwe+PcIxvAeY2UrmJY57bF9Utp+27VL1KqC1jaTNgNWBj1Il9iGz/T0XwO3ABqXqQOCrpepWYE1J7R9mIiJilCShL2nV+pI48PFa3ZbArLb2vaW85TpgF0krUiX2y9rab9a25P6WQeK5obS7rRbDnQMdIOlgSfdTzeTfW6uaTPWB4ybg9ZLWHWTsgcZYCTgMuLYUrQ88XGuyoJS1H3dMuRTQu3DhwuEOHxERbbLkvqRF9SVxSVOplrM79TxwM1XyXNX2/NoldVjKJfd2kq6gWuZ+wPbbAWxfAVxRrqv/B/C3pfkU4GDbiyV9C3gncHYf3XbiXOBG2zcN5SDb5wPnA/T09HiQ5hER0aHM0IfmXmBiW9lEYG5b2TTgLKrr1yNtLvDCDWe2DwamAmu1N7R9I7CppHUkbU2V+H8oaT7VB45hLbtL+negC/hwrfgRYMPa/galLCIixkAS+tB8Bvi0pLUBJE2gSqbntrW7CfgkcOkoxPB1YGdJB9TKVmttSNq8dZd9uWlvZeBxquR9iu3u8not8FpJGw9lcElHA3sDU2wvrlVdBRxe7nb/G+APth8dzglGRMTQZcl9CGxfJWl9YIYkA08Bh7YnrnLD2On9dLNZuTbfcoHts4YQw6Jyt/1/SToT+E2J4xOlyTuoEuufgUXAu8od75OBt7V1dwXVTP3T/Qy3p6QFtf13Al8EfgHMLJ8bvm3748D3Sv8PAn8Cjuz0nCIiYunpxRuiI8ZWT0+Pe3t7xzuMiI7kaWudy9PWRpekWbaXuLcrS+4RERENkCX3ZUD5StrKbcWH2Z4zBmPvzZJL7g+Vm+0iIuJlIkvuMW6y5B4RMXRZco+IiGiwJPSIiIgGSEKPiIhogCT0iIiIBkhCj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBkhCj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGSEKPiIhogFeMdwARES8H3SddM94hLPPmf2rf8Q5huZYZekRERAMkoUdERDRAEnpEREQDJKFHREQ0QBJ6REREAyShD4GkgyRZ0hskbStpdq1uiqRFklYq+1tLurtWf6akRyStIGkVSfdL2rpWf4KkL/Uz7m6Srm4ru0jSIWV7uqSfSppdXq3ydSV9XdLPJc2SNFPSwbU+LenoWp8TStnxA7wHL4zbVv58bfyrBn0zIyJiRCWhD80U4Obydw6wkaQ1St1OwH3AdrX9GQCSVgAOBh4GdrX9DPAh4FxV1geOBU5aitjeY3tCeV0uScCVwI22N7U9EZgMbFA75h7g79vO765hjr+oNv4Bw+wjIiKGKQm9Q5JWByYBRwGTbS8GeoEdS5OJwDlUiZzy95ayvRswFziPKmli+1rgUeBw4AzgFNtPjGDIewD/Z/uLrQLbv7D9hVqbXwCrlJm8gH2A749gDEuQdIykXkm9CxcuHM2hIiKWK0nonTsQuNb2A8DjkiZSJeydJL0KWAxM56UJfUbZngJcClwB7NtalqeapZ8GdNm+ZCnj+1ptyXttYEvgzg6Ouxx4Z4n3TuDZYY6/SknUt0o6qL9Gts+33WO7p6ura5hDRUREuyT0zk0BppXtaWV/BlUi3AG4w/Y8YHNJXcDqtudJeiXwNuBK208CtwF7A9j+FXA91cx9IO6gvL7k/nh7Q0nnSLpL0h1tVd+gSuitDx3DtbHtHuDdwJmSNluKviIiYojy068dkLQW1RL21pIMrEiVTE8F3gTsDMwszRdQXatu7e8NrAnMqVa1WQ1YBLRucltcXgN5HPjLtrK1gMcGOGYu8I7Wju3jJK1DdZmAWvmvJf0Z2Av4IC+uMAyJ7UfK359Lmk51L8G84fQVERFDlxl6Zw4BLrG9se1u2xsCD1ElrYeBI3kxgc+kWkpvXT+fAhxdjusGNgH2krTaEMb/GfBaSX8NIGljYFtg9gDHXE+1DP7/amX9jfkx4ETbzw8hphdI+ktJK5ftdag+4Nw7nL4iImJ4ktA7M4Xq+nfdt0r5LcDKth8u5TOBTYEZJWnvA7zwVAfbf6S6U37/Tge3/SxwKHBh+arc5VQfEv4wwDEGDgJ2lfSQpNuBi4ET+2g7w/aVncYDfEnSgvKaCfw10CvpLuAG4FO2k9AjIsaQqv/uR4y9np4e9/b2Dt4wYhmQp60NLk9bGxuSZpV7ll4iM/SIiIgGyE1xy5Dyy3HtX1971vaOfbUf5VjOoboWXvd52xeOdSwRy4LMPmNZl4S+DLE9B5gw3nFAdVf8eMcQERGdy5J7REREAyShR0RENEASekRERAMkoUdERDRAEnpEREQDJKFHREQ0QBJ6REREAyShR0RENEASekRERAMkoUdERDRAEnpEREQDJKFHREQ0QBJ6REREAyShR0RENEASekRERAPkeegRER3oPuma8Q5hmTX/U/uOdwhBZugRERGNkIQeERHRAEnoERERDZCEHhER0QBJ6H2QdJAkS3qDpG0lza7VTZG0SNJKZX9rSXfX6s+U9IikFSStIul+SVvX6k+Q9KUBxn6dpO9J+pmkOyV9Q9K6knaT9AdJs8vrR7VjDpV0t6S5ku6S9GVJa5a66ZJ+KUm19ldKenqAGLol3dNH+TvLGIsl9bTVfUTSg5J+Kmnv/t/diIgYDUnofZsC3Fz+zgE2krRGqdsJuA/YrrY/A0DSCsDBwMPArrafAT4EnKvK+sCxwEl9DSppFeAa4DzbW9jeHjgX6CpNbrI9obz+thyzD/DPwN/Z3hLYvsSzbq3r3wM7l/ZrAusN723hHuDtwI1tcb8RmAxsCexTznfFYY4RERHDkITeRtLqwCTgKGCy7cVAL7BjaTIROIcqkVP+3lK2dwPmAudRfRjA9rXAo8DhwBnAKbaf6Gf4dwMzbX+3VWB7uu0lZss1JwPH236ktH/e9gW2f1prM40q4UKVkL89QH/9sn1fW78tBwLTbD9r+yHgQWCH4YwRERHDk4S+pAOBa20/ADwuaSJVwt5J0quAxcB0XprQZ5TtKcClwBXAvq1leapZ+mlAl+1LBhh7K2DWAPVvqS25n1zKtgTuHOScrgN2KbPmycBlg7QfqvWpViVaFpSyJUg6RlKvpN6FCxeOcBgREcuvJPQlTaGa0VL+TqFK2DtRzTrvsD0P2FxSF7C67XmSXgm8DbjS9pPAbcDeALZ/BVxPNXNfGvUl99PaK8v1/NmS5kl6V63qeapLCJOBVW3PX8o4hs32+bZ7bPd0dXUNfkBERHQkvxRXI2ktYA9ga0kGVgQMnAq8ieo69MzSfAFVgmzt7w2sCcwp95+tBiwCri71i8trIHOBXYcY9lyq6+Y32J4DTJB0NrBqW7tpVCsHpwyx/048AmxY29+glEVExBjJDP2lDgEusb2x7W7bGwIPUd0A9zBwJC8m8JlUS+mt6+dTgKPLcd3AJsBeklYbwvhfp1raf+F3FCXtImmrAY75JHC6pA1qZe3JHOCm0vbSIcTTqauAyZJWlrQJsAVw+yiMExER/UhCf6kpVLPYum+V8luAlW23rhXPBDYFZpSkvQ/VHeoA2P4j1TL3/p0ObnsRsB/wT+Vra/cC/wj0e7HZ9veAs4DvS7pX0gyqJfYftLWz7dNtP9ZhOK+XtKD2eqekgyUtAN4MXCPpB6XvucA3gHuBa4HjbD/f6XlHRMTSk+3xjiGWUz09Pe7t7R3vMCI6koez9C8PZxlbkmbZ7mkvzww9IiKiAXJT3DgovxzX/vW1Z23v2Ff7pscRERFLLwl9HLTuRk8cES8fWVaOZV2W3CMiIhogCT0iIqIBktAjIiIaIAk9IiKiAZLQIyIiGiAJPSIiogGS0CMiIhogCT0iIqIBktAjIiIaIAk9IiKiAZLQIyIiGiAJPSIiogGS0CMiIhogCT0iIqIBktAjIiIaIM9Dj4joQPdJ14x3COMqz4Nf9mWGHhER0QBJ6BEREQ2QhB4REdEASegRERENkIQeERHRAKOa0CU93bY/VdLZtf1jJN1fXrdLmlSrmy7pl5JUK7uy1aekbkmLJM2uvQ4fJJ4Jkixpn7J/hKRL29qsI2mhpJUlvULSf0r6WW2Mkzs474PKOG8o+7eVY39Z+m711S3pvZLmSLpb0j2SDhyg34skPSTpLkkPSPqqpA1q9fMlrVO2n297b7ol7SbpD7WyHw0w1imSjm8r21DSDZLulTRX0gdrdWtJ+mF5r34o6S8He58iImLkjNsMXdJ+wPuASbbfABwLfF3SX9Wa/R7YubRfE1ivrZt5tifUXl8dZNgpwM3lL8AVwF6SVqu1OQT4ru1ngU8ArwW2tj0BeAuwUgen95JxbO9Yjv8YcFkrXuA54OTyHmwD/A1w9yB9n2B7W+D1wE+A6yW9so92i9rem/ml/KZa2d92cC51zwH/YvuNJdbjJL2x1J0EXGd7C+C6sh8REWNkPJfcT6RKTo8B2L4TuBg4rtZmGjC5bL8d+PZwBysz/XcCU6mS+Cq2nwR+DOxfazoZuLQk+X8A/sn2MyXGp2yfMsg4qwOTgKNqsffnNcBTwNOl/6dtP9TJ+bhyBvBr4O86OWZp2X60/Dth+yngPmD9Un0g1b8f5e9BffVRVmV6JfUuXLhwlCOOiFh+jHZCX7W+7At8vFa3JTCrrX1vKW+5DthF0opUyfGytvabtS0rv2WAWHYCHrI9D5gOtH4l4dLSN5JeC7wOuB7YHPhlSVxDcSBwre0HgMclTRyg7V3Ab4CHJF0oaf8B2vbnTuANfZTX3/srauVvGcrlg/5I6ga2A24rRevafrRs/xpYt6/jbJ9vu8d2T1dX13CHj4iINqP9S3GLytIyUF1DB3qGcPzzVEvXk4FVbc+vXVKHsuTeYV9TqGb8lL+HA98CrgHOlfRq4O+Bb9l+vm0cJB0JfBBYG9jJ9sMDjPP52jhTWPKDCwBlnH2ANwF7AmdImjjYKkAb9VO+qJ/35ibb+w2h/yUHrFYhvgV8qKxyvIRtS/LSjBEREUMznkvu9wLts9eJwNy2smnAWcA3hjtQmeG/A/iYpPnAF4B9JK1hexFwLXAwZbm9HPYgsJGkNQBsX1gS5B+AFfsZZy1gD+DLZZwTgL9X+6eDmrJ0frvtT5bx3zHE09uOaul7TEhaiSqZf812/RLIbyStV9qsB/x2rGKKiIjxTeifAT4taW2o7kCnur59blu7m4BP8mKiHY49gbttb2i72/bGVEnp4FJ/KfBhqmXimQC2/wR8BThb0iolxhWBvm5AazkEuMT2xmWcDYGHqG6mW4Kk10ravlY0AfhFJyekygeobhS8tpNjllb5YPIV4D7b/9VWfRVwRNk+AvjOWMQUERGVcUvotq8CLgBmSLof+G/g0Np12FY72z69dfNcm/Zr6B/oZ7gpVHe0132LF+92/yHV3eyX2a4vFZ8MPArcI+knVB8uLgZ+Ncxx2q0EnK7qa3uzgXdRLesP5LOS7gIeoFqq3932/w1yzHB9VNKC1ovqGweHAXvU3vO3lbaforrZ8GfA35b9iIgYI3pp/ooYOz09Pe7t7R3vMCI6kqet5WlrywpJs2wvcT9afikuIiKiARr3PHRJtwErtxUfZnvOCI6xNtVX6trtafvxEej/HMoP6tR83vaFS9t3H2OdTPX9/Lpv2j5tpMeKiIjRkyX3GDdZco+IGLosuUdERDRYEnpEREQDJKFHREQ0QBJ6REREAyShR0RENEASekRERAMkoUdERDRAEnpEREQDJKFHREQ0QBJ6REREAyShR0RENEASekRERAMkoUdERDRAEnpEREQDJKFHREQ0wCvGO4CIiJeD7pOuGe8Qxsz8T+073iHEMGSGHhER0QBJ6BEREQ2QhB4REdEASegRERENkIQeERHRAEnoHZL0dNv+VEln1/aPkXR/ed0uaVKtbrqkX0pSrezKVp+SuiUtkjS79jp8gFjmS5pTa/vvte2nJf20bH9V0m6SLOno2vETStnxA4xxkaRD+ii/VtLvJV3dVr6JpNskPSjpMkmv7P/djIiIkZaEPgIk7Qe8D5hk+w3AscDXJf1VrdnvgZ1L+zWB9dq6mWd7Qu311UGG3b3W9tTWNtALvKfstz4U3AP8fe3YKcBdQz9TAD4LHNZH+aeBM2xvDjwBHDXM/iMiYhiS0EfGicAJth8DsH0ncDFwXK3NNGBy2X478O0xjO8XwCqS1i2rBPsA3x9OR7avA56ql5U+9wAuL0UXAwf1dXxZyeiV1Ltw4cLhhBAREX1IQu/cqvUlceDjtbotgVlt7XtLect1wC6SVqRK7Je1td+sbcn9LYPEc0Npd1uH8V8OvBPYCbgTeLbD4zqxNvB728+V/QXA+n01tH2+7R7bPV1dXSMYQkTE8i2/FNe5RWVJG6iuoQM9Qzj+eeBmqmS+qu35tUvqUJbch9Df7q0VgQ59g+pDxBuAS6kSe0RENERm6CPjXmBiW9lEYG5b2TTgLKrkOqZs/xr4M7AX1WrBSHocWFNS6wPiBsAjIzxGREQMIAl9ZHwG+LSktaG6ixyYCpzb1u4m4JNUM+Tx8DHgRNvPj2Sntg3cALTuij8C+M5IjhEREQPLkvsIsH2VpPWBGZJMddPYobYfbWtn4PR+utmsXJtvucD2WSMc54whHvIlSWeW7Ydtv1nSTVTL9qtLWgAcZfsHVDcGTpP0CeAnwFdGKu6IiBicqhwTMfZ6enrc29s73mFEdCRPW4tlhaRZtpe4hytL7hEREQ2QJfdlWPlK2sptxYfZnjOCY5xD+cGbms/bvnCkxohogsxaY1mXhL4Ms73jGIxx3OCtIiJiWZcl94iIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBkhCj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBkhCj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGyPPQIyI60H3SNeMdwpiY/6l9xzuEGKbM0CMiIhogCT0iIqIBktAjIiIaIAk9IiKiAZLQR4mkp9v2p0o6u7Z/jKT7y+t2SZNqddMl/VKSamVXtvqU1C1pkaTZtdfhA8QyX9IcSXdL+l9Jf1UrX6dsP9/W30kD9DddUk9bWXtMX+z83YqIiKWVu9zHgaT9gPcBk2w/Jml74EpJO9j+dWn2e2Bn4GZJawLrtXUzz/aEIQy7exnrP4F/Az7QVr9oiP31ZagxRUTECMkMfXycCJxg+zEA23cCFwPH1dpMAyaX7bcD3x6hsW8ENh+hviIiYhmRhD56Vq0vYQMfr9VtCcxqa99byluuA3aRtCJVYr+srf1mbUvkb+kwrv2AOYPFK+ldHfZXt4mkn0j6cX/xlEsNvZJ6Fy5cOIwhIiKiL1lyHz0vWcKWNBXo6bf1kp4HbqZK5qvanl+7pA5DX96+QdLzwN3ARweLdxgeBTay/bikiVSXELa0/WS9ke3zgfMBenp6vBTjRURETRL6+LgXmAhcXyubCMxtazcNuAI4ZQTG3L21xD8abD8LPFu2Z0maB7yOauUhIiJGWZbcx8dngE9LWhtA0gRgKnBuW7ubgE8Cl45lcMMhqatcHkDSpsAWwM/HN6qIiOVHZujjwPZVktYHZkgy8BRwqO1H29oZOL2fbjYr1+ZbLrB91lKEtWpbf9fa7vera8A1kv5ctmdSrSZ8vJQtBo61/buliCciIoYgCX2U2F69bf8i4KLa/nnAef0cu9tAfdqeD6w6hFi6Byu3veIQ+uszPuBbnfYREREjK0vuERERDZAZeoNIug1Yua34MNt9fU2tk/6uADZpKz7R9g+G019ERIyeJPQGsb3jCPd38Ej2F/FylueEx7IuS+4RERENkIQeERHRAEnoERERDZCEHhER0QBJ6BEREQ2QhB4REdEASegRERENkIQeERHRAB0ldEnrSvqKpO+X/TdKOmp0Q4uIiIhOdTpDvwj4AfDasv8A8KFRiCciIiKGodOEvo7tb1A9FhPbzwHPj1pUERERMSSdJvQ/SlobMICkvwH+MGpRRURExJB0+nCWDwNXAZtJugXoAg4ZtagiIiJiSDpK6LbvlLQr8HpAwE9t/3lUI4uIiIiOdZTQJa0IvA3oLse8VRK2/2sUY4uIiIgOdbrk/l3gGWAO5ca4iIjlSfdJ14x3CGMiz31/+eo0oW9ge5tRjSQiIiKGrdO73L8v6a2jGklEREQMW6cz9FuBKyStAPyZ6sY42371qEUWERERHes0of8X8GZgjm2PYjwRERExDJ0uuT8M3JNkHhERsWzqNKH/HJgu6SOSPtx6jWZg40XSQZIs6Q2StpU0u1Y3RdIiSSuV/a0l3V2rP1PSI5JWkLSKpPslbV2rP0HSl/oYc2tJs8vrd5IeKts/Kn2dJekeSXMk3SFpkwHin1/a3S3pfyX9VSlfXdKXJM2TNEvSdEk71sb9dYm9tf/Kfvp/uo+yqZIW1o49usO3OyIiRkinS+4Pldcry6vJpgA3l7+nAhtJWsP2U8BOwH3AdsDtZX8GQLm/4GCq1Yxdbd8g6UPAuZJ2oXqwzbFAT/uAtucAE0o/FwFX27687E8px25je7GkDYA/DnIOu9t+TNJ/Av8GfAD4MtW/4Raln02AN9pujXsK8LTt04f0br3oMtvvH+axERGxlDr9pbhTRzuQZYGk1YFJwO7Ad23/u6ReYEfgR8BE4ByqRN5K6D8qh+8GzAUuo/owcIPtayW9Fzgc2Bc4xfYTQwxrPeBR260H4ywYwrE3Ah+QtFk5h/fU+ml9SBtTko4BjgHYaKONxnr4iIjG6vR56F2SPivpe5Kub71GO7hxcCBwre0HgMclTQRuAXaS9CqqH9WZTpXIoTZDp0rilwJXAPu2luWpHjN7GtBl+5JhxPQNYP+ylP05SdsN4dj9qH4MaEtgtu3RfELeO8oy/+WSNuyvke3zbffY7unq6hrFcCIili+dXkP/GnA/sAnVMvR84I5Rimk8TQGmle1pZX8GVeLeAbjD9jxgc0ldwOq255XrzW8DrrT9JHAbsDeA7V8B1wPnDSegMiN/PfARqg8U10nac5DDbijX/l8NfHI44w7Rd4Hu8uNDPwQuHoMxIyKiptNr6Gvb/oqkD9r+MfBjSY1K6JLWAvYAtpZkYEWqx8WeCrwJ2BmYWZovACbX9vcG1gTmSAJYDVgEXF3qF7MUP5lr+1ng+1Q/8PMb4CDgugEO2d32Y7VzmwtsK2nF0Zil2368tvtl4DMjPUZERAys0xl668lqj0ratyz7rjVKMY2XQ4BLbG9su9v2hlTXmLejutHtSF5M4DOpltJvKftTgKPLcd1UKxl7SVptaYOStL2k15btFYBtgF8MpY+yqtALnKryiUNSt6QR+dFmSevVdg+gunEwIiLGUKcJ/ROS/gL4F+B4qlnYP49aVONjCtX177pvlfJbgJVtP1zKZwKbAjNK0t4HeOHJDbb/SHWn/P4jENdrgO9Kuge4G3gOOHsY/RwNrAs8WPq6CPjtMPpZTdKC2uvDVDfezZV0F9Ud9VOH0W9ERCwF5bdiYrz09PS4t7d3vMOI6EiethbLCkmzbC/xFehOn4feBfwDLz4PHQDb7x2pACMiImL4Or0p7jvATVTfuR7Nrz41XvnluPavrz1re8ch9nMbsHJb8WHlR2qWiqS16fumuz3bboCLWG5k5hrLuk4T+mq2TxzVSJYT9V+FW8p+hvQBYIh9P84IxBgREWOn05virpb0tlGNJCIiIoat04T+QaqkvkjSk5KekvTkaAYWERERnev0t9zXGKhe0pa2545MSBERETFUnc7QBzOc3yiPiIiIETJSCV0j1E9EREQMw0gl9Pw6TURExDgaqYQeERER42ikEvr/jVA/ERERMQwdJXRVDpX0sbK/kaQdWvW2/2a0AoyIiIjBdTpDPxd4M9WTxwCeAs4ZlYgiIiJiyDr96dcdbW8v6ScAtp+Q9MpRjCsiIiKGoNMZ+p8lrUi5m708fW3xqEUVERERQ9JpQj8LuAJ4jaTTgJuB/xy1qCIiImJIBl1yl7QC8BDwr8CeVD8ic5Dt+0Y5toiIiOjQoAnd9mJJ59jeDrh/DGKKiIiIIer0prjrJL0D+Lbt/CpcRAxL90nXjHcIwzb/U/uOdwgRA+r0Gvr7gG8Cz+bxqREREcueEXl8akRERIyvjhK6pF36Krd948iGExEREcPR6TX0E2rbqwA7ALOAPUY8ooiIiBiyTpfc96/vS9oQOHM0AoqIiIihG+7T1hYAfz2SgYw0SQdJsqQ3SNpW0uxa3RRJiyStVPa3lnR3rf5MSY9IWkHSKpLul7R1rf4ESV/qZ9wrJB1U2/+ppI/W9r8l6e2SdpN0dSmbKmmxpG1q7e6R1D3A+c2XNEfS3ZL+V9JflfLVJX1J0jxJsyRNl7SjpNnl9etybq39Pn/CV9LTfZR9WNK9ZczrJG1cqztC0s/K64j+4o6IiNHR6dPWviDprPI6G7gJuHN0Q1tqU6h+0W4KMAfYSFLr5r6dgPuA7Wr7M+CFH9I5GHgY2NX2M8CHgHPLU+fWB44FTupn3FtKf0haG/gj1YNtWt7cGqvNAuDkIZ7j7ra3AXqBfytlXwZ+B2xheyJwJLCO7Qm2JwBfBM5o7dseyqNvfwL0lDEvBz4DIGkt4N+BHakux/y7pL8c4rlERMRS6HSG3kt1zXwWMBM40fahoxbVUpK0OjAJOAqYbHsx1TnsWJpMpHpa3E5lfyeqRAywGzAXOI/ydDnb1wKPAocDZwCn2H6in+FntPX7XaCrfBjYBFhk+9d9HHc1sKWk1w/5hOFGYHNJm5Vz/Gg5Z2w/ZHtEvvxr+wbbfyq7twIblO29gR/a/l15X34I7NNXH5KOkdQrqXfhwoUjEVZERNB5Ql/T9sXl9TXbt0j64KhGtnQOBK61/QDwuKSJlJmzpFdRPVhmOi9NvK1Z8xTgUqrfrt+3tSxPNUs/DeiyfckAY88CtipL2TtRfQD6KdUlivo47RZTzXj/rZ/6gexHtQqxJTDb9vPD6GOojgK+X7bXp1rRaFlQypZg+3zbPbZ7urq6RjnEiIjlR6cJva9rolNHMI6RNgWYVranlf3WzHkH4A7b86hmtV3A6rbnlST8NuBK208Ct1HNPrH9K+B6qpl7v2w/SzXD3x74m9LHzDJ2fSWgL18H/qbM5DtxQ7k34NXAJzs8ZqlJOhToAT47VmNGRMTABrzLXdIU4N3AJpKuqlWtQXWddplTrufuAWwtyUDrsa+nAm8CdqZKsFDNJCfX9vcG1gTmSAJYDVhEtRwO1Sy6k8fG3gLsAqxRnh1/K/B+qmv2fd5MB2D7OUmfA07s5FyprqE/1tqRNBfYVtKKozVLl/S3VNf6dy0fXgAeobpU0bIB1QpIRESMkcG+tjaD6trxOsDnauVPAXf3ecT4OwS4xPb7WgWSfkyVTB+muklst1I1k3LDW9mfAhxt+9Jy3KuAhyStVrt23IkZVO/X9LJ/N9VsfV3gnkGOvYjqyXZD/nW+ssrQC5wq6f+z7XKn/JYjcR1dUusDyT62f1ur+gHwn7Ub4d4KfGRpx4uIiM4NuORu+xe2p9t+s+0f11532n5urIIcoilU17/rvlXKbwFWtt263jsT2BSYIWk1qhu5Xkh8tv9Idaf8/gzNjNLvzNLPc8Bvgd7WzWr9KXednwW8ZohjthxN9cHhQUn3UH1A+O2AR/RtNUkLaq8PUy2xrw58s3zl7aoS8++A/wDuKK+Pl7KIiBgj6uThaZL+BvgC1Y1dr6Raxv6j7VePbnjRZD09Pe7t7R3vMGIM5WlrEUtP0izbPe3lnd4UdzbVDPdnwKpUs8BzRi68iIiIWBqd/pY7th+s3Wx1oaSfsBxfJy2/HNf+9bVnbe/YV/ulGOc2YOW24sNszxmBvtcGruujak/bjy9t/xHtMsuNGD2dJvQ/la90zZb0Gaob5Yb7s7GNUBLqhDEYZ0Q/ILT1/ThjcA4RETH6Ok3Kh5W276f6KdMNgXeMVlARERExNJ0+be0XklYF1rN96ijHFBEREUPU6cNZ9gdmA9eW/QltPzQTERER46jTJfdTqH4y9fcAtmcDnf48aURERIyyThP6n23/oa1s8C+wR0RExJjo9C73uZLeDawoaQvgA/T/1LCIiIgYYwPO0CW1vmc9j+rRnM9SPVr0SarfQI+IiIhlwGAz9ImSXgu8C9idlz6gZTXgmdEKLCIiIjo3WEL/ItUviW0K1H90W1TX0DcdpbgiIiJiCAZ72tpZtv8auMD2prXXJraTzCMiIpYRHd3lbvv/jXYgERERMXzL9e+xR0RENEUSekRERAMkoUdERDRAx89Dj4gYru6TrhnvEJZanuUey7rM0CMiIhogCT0iIqIBktAjIiIaIAk9IiKiAZLQIyIiGiAJHZD0dNv+VEln1/aPkXR/ed0uaVKtbrqkX0pSrezKVp+SuiUtkjS79jq8nzhuK/W/lLSw1r5b0nslzZF0t6R7JB04wPlcJOmhcuydkt5cqzu+nMdsSXdIOlzSFWX/QUl/qI27Uz/9T5fU01bWfp5f7P8dj4iIkZavrQ1C0n7A+4BJth+TtD1wpaQdbP+6NPs9sDNws6Q1gfXauplne8JgY9nesYw5Feix/f6yvwFwMrC97T9IWh3oGqS7E2xfLumtwJeAbSQdC+wF7GD7SUmvBg62fXAZZzfgeNv7DRZrPzo6z4iIGHmZoQ/uRKrk+BiA7TuBi4Hjam2mAZPL9tuBb49wDK8BngKeLjE8bfuhDo+9Edi8bP8b8P9sP1n6edL2xSMca0REjIMk9Mqq9SVx4OO1ui2BWW3te0t5y3XALpJWpErsl7W136xtyf0tQ4zvLuA3wEOSLpS0/xCO3R+YU2bja9j++RDHHopNJP1E0o/7O8dy+aJXUu/ChQtHMZSIiOVLltwri+pLxa0l7yEc/zxwM1UyX9X2/NoldVjKpWjbz0vaB3gTsCdwhqSJtk8Z4LDPSvoosBA4arhjD8GjwEa2H5c0keqyxJat1YAW2+cD5wP09PR4DOKKiFguZIY+uHuBiW1lE4G5bWXTgLOAb4xGEK7cbvuTVB8c3jHIISfYnmB7L9v3lMT6tKRReY697WdtP162ZwHzgNeNxlgREbGkJPTBfQb4tKS1ASRNAKYC57a1uwn4JHDpSAcg6bXlZryWCcAvhtHVJ4FzyvI7klbv7477oZLUVS45UD40bAGM5vJ+RETUZMl9ELavkrQ+MEOSqW5OO9T2o23tDJzeTzeblWvzLRfYPmsIYawEnC7ptcAzVMvoxw7h+JbzgNWBOyT9Gfgz8Llh9ANwTekDYCbVCsXHS9li4Fjbvxtm3xERMUSq8lDE2Ovp6XFvb+94hxFjIE9bixg5kmbZXuI+ryy5R0RENECW3MeJpNuAlduKD7M9Zwh9nEP1gzZ1n7d94dLGV/q/AtikrfhE2z8Yif4jImLkZMk9xk2W3CMihi5L7hEREQ2WhB4REdEASegRERENkIQeERHRAEnoERERDZCEHhER0QBJ6BEREQ2QhB4REdEASegRERENkIQeERHRAEnoERERDZCEHhER0QBJ6BEREQ2QhB4REdEASegREREN8IrxDiAimqv7pGvGO4QRM/9T+453CBEDygw9IiKiAZLQIyIiGiAJPSIiogGS0CMiIhogCT0iIqIBlumELukgSZb0BknbSppdq5siaZGklcr+1pLurtWfKekRSStIWkXS/ZK2rtWfIOlLA4z9Oknfk/QzSXdK+oakdUvdJEm3lz7vl3RMKT9C0qVt/awjaaGklSVNl/RTSbPL6/LS5pQS62xJ90qaMsj7cpGkh0r7OyW9uVZ3fIlptqQ7JB0u6Yqy/6CkP9TG36mf/qdL6mkr20vSLElzyt89anUTS/mDks6SpIHij4iIkbesf21tCnBz+XsqsJGkNWw/BewE3AdsB9xe9mcASFoBOBh4GNjV9g2SPgScK2kX4LXAsUAPfZC0CnAN8GHb3y1luwFdJVl9HTjI9p2S1gF+IOkR4Argc5JWs/2n0t0hwHdtP1vy3Hts9/Yx7Bm2T5e0BTBL0uW2/zzAe3OC7cslvRX4ErCNpGOBvYAdbD8p6dXAwbYPrp3D8bb3G6Df/jwG7G/7V5K2An4ArF/qzgP+AbgN+B6wD/D9YYwRERHDtMzO0CWtDkwCjgIm214M9AI7liYTgXOoEjnl7y1lezdgLlWimQJg+1rgUeBw4AzgFNtP9DP8u4GZrWRejp9u+x7gOOAi23eW8seAfwVOsv0k8GNg/1pfk4GXzNoHYvtnwJ+Av+zwkBuBzcv2vwH/r8SB7SdtX9zp2IPE9RPbvyq7c4FVy6rDesCrbd9q28BXgYP660fSMZJ6JfUuXLhwJEKLiAiW4YQOHAhca/sB4HFJE6kS9k6SXgUsBqbz0oQ+o2xPoUqiVwD7tpblgQ8BpwFdti8ZYOytgFn91G3ZR11vKaeMOxlA0muB1wHX19p+rbbk/dn2ziVtD/zM9m8HiK9uf2BOmY2vYfvnHR63NN4B3Gn7WapZ+oJa3QJenLkvwfb5tnts93R1dY1ymBERy49lOaFPAaaV7WllfwZV4t4BuMP2PGBzSV3A6rbnSXol8DbgyjJTvQ3YG6DMMK+nmrmPlmuAnUuC/XvgW7afr9W/x/aE8jqhVv7PkuaWeE/rYJzPlnsKjqFaxRgTkrYEPg28b6zGjIiIwS2T19AlrQXsAWwtycCKgKmuo78J2BmYWZovoJoRt/b3BtakmrUCrAYsAq4u9YvLayBzgV37qbuXarn/O7WyieUYbC+SdC3VNfzJwIcHGauldQ39AOArkjaz/cwA7U+wfXm9QNLTkjYdrVm6pA2oVj0OLx+mAB4BNqg126CURUTEGFpWZ+iHAJfY3th2t+0NgYeoboB7GDiSFxP4TKql9Nb18ynA0eW4bmATYC9Jqw1h/K9TLe2/8OPNknYpN4OdA0yVNKGUr001Y/1M7fhLqRL5urU4O2L7Kqol/COGclzxSeCcsjqApNUlHT6MfpYgaU2q1YeTbLfea2w/Cjwp6W/KDYOH89IPOxERMQaW1YQ+hWomWPetUn4LsLLth0v5TGBTYEZJ2vtQJR4AbP+R6k75/emQ7UXAfsA/la+t3Qv8I7CwJLBDgf+WdD/VZYAL6jfQAT+kupP+snKjWF39GvqP+gnh48CHy936Q3EecANwh6R7gJsYfDWiP9dIWlBe3wTeT3Xz3cdq8b+mtP1H4MvAg8A8cod7RMSY05L5JmJs9PT0uLe3r2/wRVPkaWsRI0/SLNtLfO16WZ2hR0RExBAskzfFjRVVvxzX/vW1Z23v2Ff7sSbpHKobAOs+b/vCEer/Cqp7DOpOtP2Dkeg/IrPaiLGzXCd023OACeMdR39sHzfK/R88mv1HRMTYyZJ7REREAyShR0RENEASekRERAMkoUdERDRAEnpEREQDJKFHREQ0QBJ6REREAyShR0RENEASekRERAMkoUdERDRAEnpEREQDJKFHREQ0QBJ6REREAyShR0RENEASekRERAMs189Dj4jR033SNeMdwoia/6l9xzuEiAFlhh4REdEASegRERENkIQeERHRAEnoERERDdCohC7p6bb9qZLOru0fI+n+8rpd0qRa3XRJv5SkWtmVrT4ldUtaJGl27XX4ALHMlzRH0t2S/lfSX5Xyv5D0VUkPSppXtv+i1K0g6SxJ95Rj75C0Sal7b62/eyQdOFLv21CU9+GePspPkfRI7b1523jEFxGxvFpu7nKXtB/wPmCS7cckbQ9cKWkH278uzX4P7AzcLGlNYL22bubZnjCEYXcvY/0n8G/AB4CvAPfYPrzEdSrwZeCdwLuA1wLb2F4saQPgj+XvycD2tv8gaXWga4hvwVg4w/bp4x1ERMTyqFEz9EGcCJxg+zEA23cCFwPH1dpMAyaX7bcD3x6hsW8ENpe0OTAR+I9a3ceBHkmbUX2AeNT24hLjAttPAK8BngKeLuVP236ov8EkTZB0a5nNXyHpL0v5dEmfLzPoeyTtUMpPkXSJpJmSfibpH0bovCMiYow0LaGvWl8Sp0qWLVsCs9ra95byluuAXSStSJXYL2trv1nbkvtbOoxrP2AO8EZgtu3nWxVle3aJ4xvA/qXvz0narjS7C/gN8JCkCyXtP8h4XwVOtL1NGfffa3WrlVWGfwQuqJVvA+wBvBn4mKTXdnhude8vHyIuaH2IaFcue/RK6l24cOEwhoiIiL40LaEvsj2h9QI+NsTjnwdupkrmq9qe31Y/r96/7ZsG6e+G8sHi1cAnBxvc9gLg9cBHgMXAdZL2LEl/H+AQ4AHgDEmn9NVHuR6/pu0fl6KLgV1qTS4tY90IvLpcWgD4ju1FZQXjBmCHweJtcx6wGTABeBT4XD/neL7tHts9XV3L4lWDiIiXp+XmGjpwL9Vy9/W1sonA3LZ204ArgFNGYMzdW0v8AJLuBSZIWqG1rC5pBaokeC+A7WeB7wPfl/Qb4CDgOtsGbgdul/RD4MJhxuh+9vsr76xT+zetbUn/DVw99NAiImK4mjZDH8hngE9LWhuq68zAVODctnY3Uc2mLx3pAGw/CPwE+Git+KPAnbYflLR9a6m7JPptgF9Iem25ia9lAvCLfsb4A/BE7XLAYcCPa03eVfqfBPyhtAc4UNIq5f3ZDbhjKOcmqX4D4cHAEnfCR0TE6FluZui2r5K0PjBDkqluMjvU9qNt7Qz0d6f2ZmUJveUC22cNMZSjgC9Imlf2Z5YyqG5++29JK5f924GzgXWB00uyfwZYCBw7wBhHAF+UtBrwc+DIWt0zkn4CrAS8t1Z+N9VS+zrAf9j+1QD9v17Sgtr+PwMHlA9JBuZTfaMgIiLGiKr8FcsDSdOB4233tpWfAjw91l856+npcW9v7+AN42UpD2eJGB2SZtnuaS9fnpbcIyIiGmu5WXIfLZJuA1ZuKz7M9pwxGPscqh/Cqfu87Qv7am97t37KT+mj762BS9qKn7W949AjjYiI0ZYl9xg3WXKPiBi6LLlHREQ0WBJ6REREAyShR0RENEASekRERAMkoUdERDRAEnpEREQDJKFHREQ0QBJ6REREAyShR0RENEASekRERAMkoUdERDRAEnpEREQDJKFHREQ0QBJ6REREAyShR0RENMArxjuAiHj56j7pmvEOYczM/9S+4x1CxIAyQ4+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBkhCj4iIaICXXUKX9HTb/lRJZ9f2j5F0f3ndLmlSrW66pF9KUq3sylafkrolLZI0u/Y6fIBY5kuaU2u7UynfQtLVkuZJmiXpBkm7lLoDJd1d2vfW4yv1H5L0jKS/WNr3ammU96qnrWyvcj5zyt89anUTS/mDks6qv8cRETH6GvW1NUn7Ae8DJtl+TNL2wJWSdrD969Ls98DOwM2S1gTWa+tmnu0JQxh2d9uP1WJYBbgGON72VaVsK6AHuBG4DrjKtiVtA3wDeEOtvynAHcDbgQuHEMdYeAzY3/avyjn9AFi/1J0H/ANwG/A9YB/g++MSZUTEcuhlN0MfxInACa0Ea/tO4GLguFqbacDksv124NsjHMN7gJmtZF7iuMf2RWX7adsuVa8CWttI2gxYHfgoVWLvl6RVJF1YZsU/kbR7KZ8q6Ttlhv0zSf9eyrvLqsXXJN0n6XJJqw3lxGz/xPavyu5cYFVJK0taD3i17VvLuX0VOKifuI8pKxO9CxcuHMrwERExgJdjQl+1viQOfLxWtyUwq619bylvuQ7YRdKKVIn9srb2m7Utub9lkHhuKO1uq8Vw50AHSDpY0v1UM/n31qomU33guAl4vaR1B+jmOMC2t6ZK/heX1QGAHYB3ANsA76wtnb8eONf2XwNPAv84yLkN5B3AnbafpZqlL6jVLeDFmftL2D7fdo/tnq6urqUYPiIi6l6OCX2R7QmtF/CxIR7/PHAzVfJc1fb8tvp59f5t3zRIf7uXdjv2VSnpCkn3SHphJcD2FbbfQDWL/Y9a8ynANNuLgW8B7xxg3EnA/5T+7gd+Abyu1P3Q9uO2F1GtQLSu0z9s+5ay/T+18iGRtCXwaarLGxERsQx4OSb0gdwLTGwrm0i1PFw3DTiL6vr1SJsLbN/asX0wMBVYq72h7RuBTSWtI2lrYAvgh5LmU33gGHDZfQDuZ7+/8o5J2gC4Ajjc9rxS/AiwQa3ZBqUsIiLGSNMS+meAT0taG0DSBKpkem5bu5uATwKXjkIMXwd2lnRAreyFa9WSNm/dAV5u2lsZeJwqeZ9iu7u8Xgu8VtLG/YxzE9X1eiS9DtgI+Gmp20vSWpJWpVoFaM3KN5L05rL9bqqVio6VmwivAU6qzfSx/SjwpKS/Ked2OPCdofQdERFLp1F3udu+StL6wAxJBp4CDi0Jp97OwOn9dLNZuTbfcoHts4YQw6Jyt/1/SToT+E2J4xOlyTuAwyX9GVgEvKvc8T4ZeFtbd1dQzdQ/3cdQ5wLnSZoDPAdMtf1s+axwO9WS/QbA/9juldRNlfCPk3QB1WrGeYOczjUlToCZwF3A5sDHJLUudbzV9m+prsdfBKxKdXd77nCPiBhDevGG62gCSVOBHtvvbyvvBq62vdV4xNWXnp4e9/b2jncYsRTytLWIsSdplu2e9vKmLblHREQslxq15D5aylfSVm4rPsz2nDEYe2+WXHJ/qNxst4TyffeL+iifDywxO5d0BbBJW/GJtn8wjHAjImKcZMk9xk2W3CMihi5L7hEREQ2WhB4REdEASegRERENkIQeERHRAEnoERERDZCEHhER0QBJ6BEREQ2QhB4REdEASegRERENkIQeERHRAEnoERERDZCEHhER0QBJ6BEREQ2QhB4REdEASegREREN8IrxDiAiln3dJ10z3iGMu/mf2ne8Q4gYUGboERERDZCEHhER0QBJ6BEREQ2QhB4REdEASegREREN0NiELukgSZb0BknbSppdq5siaZGklcr+1pLurtWfKekRSStIWkXS/ZK2rtWfIOlL/YzbXfqeXXsdXurmS5pTK9+plG8h6WpJ8yTNknSDpF0GOLepkhaWPu6V9A+1ur+T1FvKfyLpc5JOro35fG37A/30f4qk4/sov0DSbyXd01a+lqQfSvpZ+fuX/cUeERGjo7EJHZgC3Fz+zgE2krRGqdsJuA/YrrY/A0DSCsDBwMPArrafAT4EnKvK+sCxwEkDjD3P9oTa66u1ut1r5TMkrQJcA5xvezPbE4F/AjYd5Pwusz0B2A34T0nrStoKOBs41PYbgR7gQduntcYEFtXGP2uQMdpdBOzTR/lJwHW2twCuY+D3JiIiRkEjE7qk1YFJwFHAZNuLgV5gx9JkInAOVSKn/L2lbO8GzAXOo/owgO1rgUeBw4EzgFNsPzFC4b4HmGn7qlaB7XtsX9TJwbZ/C8wDNgb+FTjN9v2l7nnb541QnNi+EfhdH1UHAheX7YuBg/rrQ9IxZQWhd+HChSMVWkTEcq+RCZ0qwVxr+wHgcUkTqRL2TpJeBSwGpvPShD6jbE8BLgWuAPZtLctTzdJPA7psXzLI+Ju1Lbm/pVZ3Qym7rexvCdw53BOVtCnVbP5BYCtg1nD7Wgrr2n60bP8aWLe/hrbPt91ju6erq2tsoouIWA409ZfipgCfL9vTyv4PgH8BbgLusD1P0uaSuoDVy/4rgbcBH7b9VEm6ewNX2/6VpOuBqzsYf15Z3u7L7rYf6+9ASVcAWwAP2H77AGO8S9Ik4FngfbZ/J6mD0EaXbUvyeMcREbG8aVxCl7QWsAewdUksKwIGTgXeBOwMzCzNFwCTa/t7A2sCc0pyXA1YxItJfHF5jaS5wAs3wNk+WFIPcPogx11m+/199DURuGtkQxzUbyStZ/tRSesBvx3j8SMilntNXHI/BLjE9sa2u21vCDxEdQPcw8CRvJjAZ1Itpbeun08Bji7HdQObAHtJWm0U4/06sLOkA2plwx3vs8C/SXodVDf4STp2aQPswFXAEWX7COA7YzBmRETUNDGhT6G6/l33rVJ+C7Cy7YdL+Uyq688zStLeh+qOcwBs/5HqTvn9hxhD+zX0Pr8eVsZYBOwHHCvp55JmAh8FPjHEMbF9N9UHlEsl3Qfcw+B3y/fno5IWtF4Aki6les9eX8qPKm0/RfXB52fA35b9iIgYQ7JzuTPGR09Pj3t7e8c7jOhAnraWp63FskPSLNs97eVNnKFHREQsdxp3U9xYKb8c1/71tWdt79hX+2GOcSTwwbbiW2wfN0L9nwy8s634m7ZPG4n+ozkyO41Y9mXJPcZNltwjIoYuS+4RERENloQeERHRAEnoERERDZCEHhER0QBJ6BEREQ2QhB4REdEASegRERENkIQeERHRAEnoERERDZCEHhER0QBJ6BEREQ2QhB4REdEASegRERENkIQeERHRAHkeekSDdJ90zXiH0Fh5Jnws6zJDj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0Pkg6SJIlvUHStpJm1+qmSFokaaWyv7Wku2v1Z0p6RNIKklaRdL+krWv1J0j6Uj/jdpe+Z9deryx1+0i6vfQ3W9JlkjYqdZ8t5XdLukLSmqV8t3IeR9fGmFDKjh/g/C+SdEgf5ddK+r2kq9vKN5F0m6QHS1yvHOw9joiIkZWE3rcpwM3l7xxgI0lrlLqdgPuA7Wr7MwAkrQAcDDwM7Gr7GeBDwLmqrA8cC5w0wNjzbE+ovf5P0lbAF4AjbL/B9gTga0B3OeaHwFa2twEeAD5S6+8e4O/bzu2uobwZNZ8FDuuj/NPAGbY3B54Ajhpm/xERMUxJ6G0krQ5MokpKk20vBnqBHUuTicA5VImc8veWsr0bMBc4jypxYvta4FHgcOAM4BTbTwwxrBOB/7R9X6vA9lW2byzb/2v7uVJ1K7BB7dhfAKtIWleSgH2A7w9x/NaY1wFP1ctKn3sAl5eii4GDhtN/REQMXxL6kg4ErrX9APC4pIlUCXsnSa8CFgPTeWlCn1G2pwCXAlcA+7aW5alm6acBXbYvGWT8zWrL7eeUsi2BOzuM/70smbAvB95ZYr0TeLbDvjqxNvD72geKBcD6/TWWdIykXkm9CxcuHMEwIiKWb0noS5oCTCvb08r+DKpkuANwh+15wOaSuoDVbc8r143fBlxp+0ngNmBvANu/Aq6nmrkPpr7kflx7paS1S7J/oP06uKSTgeeoluPrvkGV0FsfOMaN7fNt99ju6erqGs9QIiIaJT/9WiNpLarl460lGVgRMHAq8CZgZ2Bmab4AmFzb3xtYE5hTrUKzGrAIaN1Atri8hmMusD1wl+3HgQklma9ei30qsB+wp23XD7b9a0l/BvYCPsiLqwsj4XFgTUmvKLP0DYBHRrD/iIjoQGboL3UIcIntjW13294QeIjqBriHgSN5MYHPpFpKb10/nwIcXY7rBjYB9pK02gjE9RngZEl/XSt7oV9J+wD/Chxg+0/99PEx4ETbz49APC8oHx5uoHrvAI4AvjOSY0RExOCS0F9qCtX177pvlfJbgJVtP1zKZwKbAjNK0t4HeOHJGLb/SHWn/P5LG5TtOVQz669K+qmkW4C/Br5empwNrAH8sCzHf7GPPmbYvnIIw35J0oLymgkg6Sbgm8CepXzv0vZE4MOSHqS6pv6VYZxmREQsBbWtzkaMmZ6eHvf29o53GI2Sp62NnjxtLZYVkmbZ7mkvzww9IiKiAXJT3DgovxzX/vW1Z23v2Ff7UYzjHKob/eo+b/vCsYwjIiKWXpbcY9xkyT0iYuiy5B4REdFgSegRERENkIQeERHRAEnoERERDZCEHhER0QBJ6BEREQ2QhB4REdEASegRERENkIQeERHRAEnoERERDZCEHhER0QBJ6BEREQ2QhB4REdEASegRERENkIQeERHRAK8Y7wAimqD7pGvGO4QYZfM/te94hxAxoMzQIyIiGiAJPSIiogGS0CMiIhogCT0iIqIBktAjIiIaYLlL6JIOkmRJb5C0raTZtbopkhZJWqnsby3p7lr9mZIekbSCpFUk3S9p61r9CZK+1M+43aXv2bXX4aVuvqQ5tfKdSvkWkq6WNE/SLEk3SNplgHObKmlh6eNeSf9Qq/s7Sb2l/CeSPifp5NqYz9e2P9BP/6dIOr6P8nr8vQO8/RERMUqWx6+tTQFuLn9PBTaStIbtp4CdgPuA7YDby/4MAEkrAAcDDwO72r5B0oeAc0uSfS1wLNAzwNjzbE/op25324+1diStAlwDHG/7qlK2Ven/xgHGuMz2+yW9Bpgr6SqgCzgb2Nf2/ZJWBI6xfR5wWun76QFi68RL4o+IiLG1XM3QJa0OTAKOAibbXgz0AjuWJhOBc6gSOeXvLWV7N2AucB7VhwFsXws8ChwOnAGcYvuJEQr3PcDMVjIv491j+6JODrb9W2AesDHwr8Bptu8vdc+XZD7mJB1TVgp6Fy5cOB4hREQ00nKV0IEDgWttPwA8LmkiVcLeSdKrgMXAdF6a0GeU7SnApcAVwL6tZXngQ1Sz3C7blwwy/mZtS+5vqdXdUMpuK/tbAncO90QlbQpsCjwIbAXMGm5fHTDwv+WywDEDNrTPt91ju6erq2sUQ4qIWL4sb0vuU4DPl+1pZf8HwL8ANwF32J4naXNJXcDqZf+VwNuAD9t+qiTdvYGrbf9K0vXA1R2M3/GSeztJVwBbAA/YfvsAY7xL0iTgWeB9tn8nqYPQlsok24+UZf4fSrrf9kCXBSIiYoQtNwld0lrAHsDWkgysSDWzPBV4E7AzMLM0XwBMru3vDawJzCnJcTVgES8m8cXlNZLmAi/cAGf7YEk9wOmDHHeZ7ff30ddE4K6RDfGF2B4pf39bPnjswMDX+SMiYoQtT0vuhwCX2N7YdrftDYGHqG6Aexg4khcT+EyqpfTW9fMpwNHluG5gE2AvSauNYrxfB3aWdECtbLjjfRb4N0mvg+oGP0nHLm2Apa9XSVqjtQ28FbhnJPqOiIjOLU8JfQrV9e+6b5XyW4CVbT9cymdSXX+eUZL2PlR3nANg+49Ud8rvP8QY2q+h9/n1sDLGImA/4FhJP5c0E/go8Ikhjontu6k+oFwq6T6qhLvpUPspPippQesFrAvcLOkuqm8GXFNuFoyIiDEk2+MdQyynenp63NvbjK+t52lrzZenrcWyQtIs20t8RXp5mqFHREQ01nJzU9xYKb8c1/71tWdt79hX+2GOcSTwwbbiW2wfN0L9nwy8s634m7ZPG4n+myizt4gYb1lyj3HTpCX3iIixkiX3iIiIBktCj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBkhCj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBkhCj4iIaIAk9IiIiAZ4xXgHEPFy1X3SNeMdQoyh+Z/ad7xDiBhQZugRERENkIQeERHRAEnoERERDZCEHhER0QBJ6BEREQ2QhP4yIukgSZb0BknbSppdq5siaZGklcr+1pLurtWfKekRSStIWkXS/ZK2rtWfIOlL/YzbXcb9RK1sHUl/lnR22T9F0vGjcNoREdGBJPSXlynAzeXvHGAjSWuUup2A+4DtavszACStABwMPAzsavsZ4EPAuaqsDxwLnDTA2A8B9e/tvBOYOwLnFBERIyAJ/WVC0urAJOAoYLLtxUAvsGNpMhE4hyqRU/7eUrZ3o0q+51F9GMD2tcCjwOHAGcAptp8YIIQ/AfdJ6in77wK+MYzzOEZSr6TehQsXDvXwiIjoRxL6y8eBwLW2HwAelzSRKmHvJOlVwGJgOi9N6DPK9hTgUuAKYN/WsjzVLP00oMv2JR3EMA2YLGlD4HngV0M9Cdvn2+6x3dPV1TXUwyMioh9J6C8fU6gSKuXvFKqEvROwA3CH7XnA5pK6gNVtz5P0SuBtwJW2nwRuA/YGsP0r4HqqmXsnrgX2AiYDl43IWUVExIjIT7++DEhaC9gD2FqSgRUBA6cCbwJ2BmaW5guoEm5rf29gTWCOJIDVgEXA1aV+cXkNyvb/SZoF/AvwRuCApTmviIgYOZmhvzwcAlxie2Pb3bY3pLpJbTuqG92O5MUEPpNqKb11/XwKcHQ5rhvYBNhL0mrDjOVzwIm2fzfM4yMiYhQkob88TKG6/l33rVJ+C7Cy7YdL+UxgU2BGSdr7AC88RcT2H6nulN9/OIHYnmv74n6qPyppQes1nP4jImJ4ZHu8Y4jlVE9Pj3t7e8c7jGHL09aWL3naWiwrJM2y3dNenhl6REREA+SmuHhB+eW49q+vPWt7x77aL+8yY4uIZUkSerzA9hxgwnjHERERQ5cl94iIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBkhCj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBkhCj4iIaIAk9IiIiAZIQo+IiGiAPD41Xpa6T7pmvEOI5cz8T+073iFEDCgz9IiIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBkhCHyJJB0mypDdI2lbS7FrdFEmLJK1U9reWdHet/kxJj0haQdIqku6XtHWt/gRJX+pn3O7S9+za65Wlbh9Jt5f+Zku6TNJGpe6zpfxuSVdIWrOU71bO4+jaGBNK2fEDnP9Fkg7po/z5WlxXdf6ORkTESEhCH7opwM3l7xxgI0lrlLqdgPuA7Wr7MwAkrQAcDDwM7Gr7GeBDwLmqrA8cC5w0wNjzbE+ovf5P0lbAF4AjbL/B9gTga0B3OeaHwFa2twEeAD5S6+8e4O/bzu2uobwZNYtqcR0wzD4iImKYktCHQNLqwCTgKGCy7cVAL7BjaTIROIcqkVP+3lK2dwPmAudRJU5sXws8ChwOnAGcYvuJIYZ1IvCftu9rFdi+yvaNZft/bT9Xqm4FNqgd+wtgFUnrShKwD/D9IY4/JJKOkdQrqXfhwoWjOVRExHIlCX1oDgSutf0A8LikiVQJeydJrwIWA9N5aUKfUbanAJcCVwD7tpblqWbppwFdti8ZZPzNasva55SyLYE7O4z/vSyZsC8H3llivRN4tsO+2q1SEvWtkg7qr5Ht82332O7p6uoa5lAREdEuCX1opgDTyva0sj+DKhnuANxhex6wuaQuYHXb88q17rcBV9p+ErgN2BvA9q+A66lm7oOpL7kf114pae2S7B9ovw4u6WTgOarl+LpvUCX01geO4drYdg/wbuBMSZstRV8RETFE+enXDklaC9gD2FqSgRUBA6cCbwJ2BmaW5guAybX9vYE1gTnVyjarAYuAq0v94vIajrnA9sBdth8HJpRkvnot9qnAfsCetl0/2PavJf0Z2Av4IC+uLgyJ7UfK359Lmk51H8G84fQVERFDlxl65w4BLrG9se1u2xsCD1ElroeBI3kxgc+kWkpvXT+fAhxdjusGNgH2krTaCMT1GeBkSX9dK3uhX0n7AP8KHGD7T/308THgRNvPDycASX8paeWyvQ7Vh5t7h9NXREQMTxJ656ZQXf+u+1YpvwVY2fbDpXwmsCkwoyTtfYAXniZi+49Ud8rvv7RB2Z5DNbP+qqSfSroF+Gvg66XJ2cAawA/LcvwX++hjhu0rhzDslyQtKK+ZZbxeSXcBNwCfsp2EHhExhtS2AhsxZnp6etzb2zusY/O0tRhredpaLCskzSr3LL1EZugRERENkJviljHll+Pav772rO0d+2o/inGcQ3UtvO7zti8cyzgiIqIzWXKPcbM0S+4REcurLLlHREQ0WBJ6REREAyShR0RENEASekRERAMkoUdERDRAEnpEREQDJKFHREQ0QL6HHuNG0kLgF+MdR4fWAR4b7yDG2fL+Hizv5w95D5aV89/Ydld7YRJ6RAck9fb1Qw7Lk+X9PVjezx/yHizr558l94iIiAZIQo+IiGiAJPSIzpw/3gEsA5b392B5P3/Ie7BMn3+uoUdERDRAZugRERENkIQeERHRAEnoEX2QtJakH0r6Wfn7lwO0fbWkBZLOHssYR1sn74GkCZJmSpor6W5J7xqPWEeSpH0k/VTSg5JO6qN+ZUmXlfrbJHWPQ5ijpoPz/7Cke8u/93WSNh6POEfTYO9Brd07JFnSMvFVtiT0iL6dBFxnewvgurLfn/8AbhyTqMZWJ+/Bn4DDbW8J7AOcKWnNsQtxZElaETgH+DvgjcAUSW9sa3YU8ITtzYEzgE+PbZSjp8Pz/wnQY3sb4HLgM2Mb5ejq8D1A0hrAB4HbxjbC/iWhR/TtQODisn0xcFBfjSRNBNYF/ndswhpTg74Hth+w/bOy/Svgt8ASv2D1MrID8KDtn9v+P2Aa1ftQV39fLgf2lKQxjHE0DXr+tm+w/aeyeyuwwRjHONo6+d8AVB/kPw08M5bBDSQJPaJv69p+tGz/mippv4SkFYDPAcePZWBjaND3oE7SDsArgXmjHdgoWh94uLa/oJT12cb2c8AfgLXHJLrR18n51x0FfH9UIxp7g74HkrYHNrR9zVgGNphXjHcAEeNF0o+Av+qj6uT6jm1L6uv7nf8IfM/2gpfrBG0E3oNWP+sBlwBH2F48slHGskjSoUAPsOt4xzKWygf5/wKmjnMoS0hCj+WW7b/tr07SbyStZ/vRkqx+20ezNwNvkfSPwOrAKyU9bXug6+3LlBF4D5D0auAa4GTbt45SqGPlEWDD2v4GpayvNgskvQL4C+DxsQlv1HVy/kj6W6oPfbvafnaMYhsrg70HawBbAdPLB/m/Aq6SdIDt3jGLsg9Zco/o21XAEWX7COA77Q1sv8f2Rra7qZbdv/pySuYdGPQ9kPRK4Aqqc798DGMbLXcAW0japJzbZKr3oa7+vhwCXO/m/ELXoOcvaTvgS8ABtvv8kPcyN+B7YPsPttex3V3+v38r1XsxrskcktAj+vMpYC9JPwP+tuwjqUfSl8c1srHTyXvw98AuwFRJs8trwrhEOwLKNfH3Az8A7gO+YXuupI9LOqA0+wqwtqQHgQ8z8DcgXlY6PP/PUq1IfbP8e7d/4HlZ6/A9WCblp18jIiIaIDP0iIiIBkhCj4iIaIAk9IiIiAZIQo+IiGiAJPSIiIgGSEKPiIhogCT0iIiIBvj/AbsLoe+5ZneqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_coefs = view_model_coefs(best_lr.named_steps['logreg'], X_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ceed55cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOME_FG2M_L5</td>\n",
       "      <td>0.456023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>HOME_EFG_PCT_L5</td>\n",
       "      <td>0.400654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>HOME_FG2M_L10</td>\n",
       "      <td>0.287717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>HOME_FG3A_L20</td>\n",
       "      <td>0.231590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>AWAY_UFGM_L5</td>\n",
       "      <td>0.224497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>AWAY_CFGM_L10</td>\n",
       "      <td>0.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>HOME_AVG_ATS_DIFF_L20</td>\n",
       "      <td>0.197018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>HOME_FTM_L10</td>\n",
       "      <td>0.183294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>HOME_PIE_L5</td>\n",
       "      <td>0.179191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>AWAY_TS_PCT_L5</td>\n",
       "      <td>0.179065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>AWAY_SAST_opp_L20</td>\n",
       "      <td>0.178467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>HOME_PIE_L20</td>\n",
       "      <td>0.177551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>AWAY_DFGA_L20</td>\n",
       "      <td>0.156151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>AWAY_FTA_opp_L10</td>\n",
       "      <td>0.143520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HOME_DFGM_L5</td>\n",
       "      <td>0.133406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>AWAY_DRBC_L10</td>\n",
       "      <td>0.131563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>HOME_FG3A_L10</td>\n",
       "      <td>0.128781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>HOME_DFGA_opp_L5</td>\n",
       "      <td>0.128329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>AWAY_FG3M_opp_L20</td>\n",
       "      <td>0.127414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>HOME_DIST_L10</td>\n",
       "      <td>0.118714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>AWAY_FG3A_opp_L5</td>\n",
       "      <td>0.116125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HOME_UFGA_L5</td>\n",
       "      <td>0.109454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>AWAY_PTS_2PT_MR_L20</td>\n",
       "      <td>0.104465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>AWAY_PTS_2PT_MR_opp_L5</td>\n",
       "      <td>0.103467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOME_FTM_L5</td>\n",
       "      <td>0.094215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>AWAY_PTS_OFF_TOV_opp_L5</td>\n",
       "      <td>0.093702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>HOME_AST_opp_L5</td>\n",
       "      <td>0.091363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOME_FG2A_L5</td>\n",
       "      <td>0.089981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>AWAY_COVER_PCT_L10</td>\n",
       "      <td>0.089786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>AWAY_FTA_L10</td>\n",
       "      <td>0.089034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>AWAY_PTS_PAINT_L5</td>\n",
       "      <td>0.088756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>HOME_AST_3PM_L10</td>\n",
       "      <td>0.087879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>HOME_TOV_PCT_opp_L5</td>\n",
       "      <td>0.084645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>AWAY_UFGM_opp_L5</td>\n",
       "      <td>0.083543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>AWAY_PTS_FB_opp_L5</td>\n",
       "      <td>0.082578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>AWAY_UAST_2PM_opp_L5</td>\n",
       "      <td>0.077911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>HOME_PLUS_MINUS_L20</td>\n",
       "      <td>0.077422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>AWAY_PF_opp_L10</td>\n",
       "      <td>0.075515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>AWAY_AST_RATIO_L5</td>\n",
       "      <td>0.074244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HOME_CFGA_L5</td>\n",
       "      <td>0.073538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature_name      coef\n",
       "0               HOME_FG2M_L5  0.456023\n",
       "97           HOME_EFG_PCT_L5  0.400654\n",
       "104            HOME_FG2M_L10  0.287717\n",
       "127            HOME_FG3A_L20  0.231590\n",
       "150             AWAY_UFGM_L5  0.224497\n",
       "209            AWAY_CFGM_L10  0.218000\n",
       "137    HOME_AVG_ATS_DIFF_L20  0.197018\n",
       "108             HOME_FTM_L10  0.183294\n",
       "103              HOME_PIE_L5  0.179191\n",
       "176           AWAY_TS_PCT_L5  0.179065\n",
       "272        AWAY_SAST_opp_L20  0.178467\n",
       "140             HOME_PIE_L20  0.177551\n",
       "259            AWAY_DFGA_L20  0.156151\n",
       "228         AWAY_FTA_opp_L10  0.143520\n",
       "33              HOME_DFGM_L5  0.133406\n",
       "203            AWAY_DRBC_L10  0.131563\n",
       "107            HOME_FG3A_L10  0.128781\n",
       "77          HOME_DFGA_opp_L5  0.128329\n",
       "263        AWAY_FG3M_opp_L20  0.127414\n",
       "116            HOME_DIST_L10  0.118714\n",
       "153         AWAY_FG3A_opp_L5  0.116125\n",
       "32              HOME_UFGA_L5  0.109454\n",
       "260      AWAY_PTS_2PT_MR_L20  0.104465\n",
       "161   AWAY_PTS_2PT_MR_opp_L5  0.103467\n",
       "4                HOME_FTM_L5  0.094215\n",
       "163  AWAY_PTS_OFF_TOV_opp_L5  0.093702\n",
       "52           HOME_AST_opp_L5  0.091363\n",
       "1               HOME_FG2A_L5  0.089981\n",
       "251       AWAY_COVER_PCT_L10  0.089786\n",
       "185             AWAY_FTA_L10  0.089034\n",
       "151        AWAY_PTS_PAINT_L5  0.088756\n",
       "121         HOME_AST_3PM_L10  0.087879\n",
       "102      HOME_TOV_PCT_opp_L5  0.084645\n",
       "158         AWAY_UFGM_opp_L5  0.083543\n",
       "162       AWAY_PTS_FB_opp_L5  0.082578\n",
       "167     AWAY_UAST_2PM_opp_L5  0.077911\n",
       "129      HOME_PLUS_MINUS_L20  0.077422\n",
       "235          AWAY_PF_opp_L10  0.075515\n",
       "178        AWAY_AST_RATIO_L5  0.074244\n",
       "30              HOME_CFGA_L5  0.073538"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_coefs.sort_values('coef', ascending=False).head(40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1374376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 621 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 611 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 601 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 591 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 581 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 571 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 561 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 551 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 541 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 621 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 611 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 601 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 591 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 581 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 571 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 561 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 551 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 541 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 621 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 611 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 601 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 591 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 581 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 571 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 561 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 551 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 541 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 621 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 611 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 601 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 591 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 581 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 571 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 561 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 551 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 541 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 621 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 611 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 601 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 591 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 581 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 571 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 561 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 551 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 541 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 621 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 611 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 601 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 591 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 581 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 571 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 561 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 551 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 541 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 351 features.\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(5)\n",
    "\n",
    "lgbc = lgb.LGBMClassifier(colsample_bytree=0.725714617307935,\n",
    "               learning_rate=0.03366464571120959, max_depth=5,\n",
    "               min_child_weight=0.534047514075973, num_leaves=194,\n",
    "               reg_alpha=4.741561203592908, reg_lambda=5.4130017942167665,\n",
    "               subsample=0.6316705486384242)\n",
    "\n",
    "selector = RFECV(estimator = lgbc, step=5, cv=tscv, scoring='accuracy', verbose=1)\n",
    "\n",
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d9dca8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train.iloc[:, selector.support_].columns, columns=['features']).to_csv('LGBC_RFE_selected_features_no_ML.csv', index=False)\n",
    "\n",
    "lgbc_features = pd.read_csv('LGBC_RFE_selected_features_no_ML.csv')\n",
    "lgbc_features = lgbc_features['features'].tolist()\n",
    "len(lgbc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "323bd98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-08 19:25:42,398]\u001b[0m Using an existing study with name '../models/hyperparameter_tuning/study_lgbc_selected' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:25:50,538]\u001b[0m Trial 400 finished with value: 0.6727272727272727 and parameters: {'min_child_weight': 0.36083198921897236, 'subsample': 0.7570934873921117, 'max_depth': 8, 'reg_lambda': 3.08308667205839, 'reg_alpha': 0.40163963017114057, 'num_leaves': 12, 'colsample_bytree': 0.8577160800881948, 'learning_rate': 0.22371344396773096}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:25:57,131]\u001b[0m Trial 401 finished with value: 0.6651649235720032 and parameters: {'min_child_weight': 0.19408251334049284, 'subsample': 0.6941906168816298, 'max_depth': 5, 'reg_lambda': 5.479762014730576, 'reg_alpha': 0.14656965809126715, 'num_leaves': 23, 'colsample_bytree': 0.8297535268032742, 'learning_rate': 0.3289348803842107}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:25:59,139]\u001b[0m Trial 402 finished with value: 0.6794851166532583 and parameters: {'min_child_weight': 0.38925101844127513, 'subsample': 0.6046726438474616, 'max_depth': 6, 'reg_lambda': 5.134141515135127, 'reg_alpha': 0.2567310792658535, 'num_leaves': 2, 'colsample_bytree': 0.7783843375259818, 'learning_rate': 0.19139815459618786}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:26:14,294]\u001b[0m Trial 403 finished with value: 0.6823813354786806 and parameters: {'min_child_weight': 0.32032019120131083, 'subsample': 0.903264836438837, 'max_depth': 13, 'reg_lambda': 4.75957290867905, 'reg_alpha': 0.002348519649578329, 'num_leaves': 174, 'colsample_bytree': 0.7234276429812282, 'learning_rate': 0.13860926935631146}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:26:25,971]\u001b[0m Trial 404 finished with value: 0.6719227674979887 and parameters: {'min_child_weight': 0.0010340694342997198, 'subsample': 0.6363712077958842, 'max_depth': 9, 'reg_lambda': 5.924541156810077, 'reg_alpha': 0.3431185498219529, 'num_leaves': 47, 'colsample_bytree': 0.8120153100698793, 'learning_rate': 0.26535707633730654}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:26:31,269]\u001b[0m Trial 405 finished with value: 0.6799678197908288 and parameters: {'min_child_weight': 0.32697330409782344, 'subsample': 0.8827494587378305, 'max_depth': 6, 'reg_lambda': 4.91850326750358, 'reg_alpha': 0.1025086186416456, 'num_leaves': 12, 'colsample_bytree': 0.6886574454241635, 'learning_rate': 0.16607921423668026}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:26:48,252]\u001b[0m Trial 406 finished with value: 0.6748189863234111 and parameters: {'min_child_weight': 0.4112261185590518, 'subsample': 0.6687872731684217, 'max_depth': 11, 'reg_lambda': 4.339200232716362, 'reg_alpha': 0.15198746835140367, 'num_leaves': 429, 'colsample_bytree': 0.8470291083934257, 'learning_rate': 0.17004877748588057}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:26:55,196]\u001b[0m Trial 407 finished with value: 0.6732099758648431 and parameters: {'min_child_weight': 0.3554169779938079, 'subsample': 0.6985742029070298, 'max_depth': 8, 'reg_lambda': 6.442569236578913, 'reg_alpha': 0.5554529669921312, 'num_leaves': 19, 'colsample_bytree': 0.7132379863267659, 'learning_rate': 0.22712773137250744}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:27:01,157]\u001b[0m Trial 408 finished with value: 0.6786806114239743 and parameters: {'min_child_weight': 0.11160368453398398, 'subsample': 0.8743547516497736, 'max_depth': 7, 'reg_lambda': 4.689814119238764, 'reg_alpha': 0.24320822393488895, 'num_leaves': 12, 'colsample_bytree': 0.7391558319741869, 'learning_rate': 0.12592983413907657}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:27:11,139]\u001b[0m Trial 409 finished with value: 0.6793242156074014 and parameters: {'min_child_weight': 0.37039599070273027, 'subsample': 0.6469580752436861, 'max_depth': 13, 'reg_lambda': 5.231379223105424, 'reg_alpha': 0.35592635300278697, 'num_leaves': 35, 'colsample_bytree': 0.6986068534727524, 'learning_rate': 0.09610051316887104}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:27:13,093]\u001b[0m Trial 410 finished with value: 0.680450522928399 and parameters: {'min_child_weight': 0.833899581740468, 'subsample': 0.8657113842881381, 'max_depth': 5, 'reg_lambda': 6.194151304479989, 'reg_alpha': 2.3599682053537805, 'num_leaves': 2, 'colsample_bytree': 0.7445309082089803, 'learning_rate': 0.15166740245565383}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:27:15,051]\u001b[0m Trial 411 finished with value: 0.6807723250201128 and parameters: {'min_child_weight': 0.3850555919062795, 'subsample': 0.8948754641655914, 'max_depth': 9, 'reg_lambda': 5.859399887654158, 'reg_alpha': 0.21517963886354172, 'num_leaves': 2, 'colsample_bytree': 0.7612255014968077, 'learning_rate': 0.1925938944057934}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:27:23,555]\u001b[0m Trial 412 finished with value: 0.6772325020112631 and parameters: {'min_child_weight': 0.7589232077392564, 'subsample': 0.6147832965020241, 'max_depth': 10, 'reg_lambda': 6.111545461360531, 'reg_alpha': 0.5054442443147634, 'num_leaves': 24, 'colsample_bytree': 0.7769568420280145, 'learning_rate': 0.23402343725780964}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:27:29,433]\u001b[0m Trial 413 finished with value: 0.686082059533387 and parameters: {'min_child_weight': 0.4308450766100816, 'subsample': 0.8390726413607983, 'max_depth': 7, 'reg_lambda': 6.99458963016381, 'reg_alpha': 1.1839190034544564, 'num_leaves': 12, 'colsample_bytree': 0.7274483627685772, 'learning_rate': 0.123722432667524}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:27:34,274]\u001b[0m Trial 414 finished with value: 0.6572807723250201 and parameters: {'min_child_weight': 0.14848200743735226, 'subsample': 0.7810542955463874, 'max_depth': 6, 'reg_lambda': 5.726353223973995, 'reg_alpha': 0.07303987070114504, 'num_leaves': 11, 'colsample_bytree': 0.6555001748783744, 'learning_rate': 0.43740490660804915}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:27:36,191]\u001b[0m Trial 415 finished with value: 0.678841512469831 and parameters: {'min_child_weight': 0.789346839069353, 'subsample': 0.6011966759785058, 'max_depth': 11, 'reg_lambda': 5.547816629574373, 'reg_alpha': 0.6454093427485237, 'num_leaves': 2, 'colsample_bytree': 0.7195108764960921, 'learning_rate': 0.18454798233044453}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:27:44,082]\u001b[0m Trial 416 finished with value: 0.66532582461786 and parameters: {'min_child_weight': 0.8188170961061776, 'subsample': 0.6211636289761169, 'max_depth': 8, 'reg_lambda': 3.3179789133898265, 'reg_alpha': 0.44291625396000045, 'num_leaves': 21, 'colsample_bytree': 0.7940173391790074, 'learning_rate': 0.33349979437010646}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:27:49,449]\u001b[0m Trial 417 finished with value: 0.6814159292035399 and parameters: {'min_child_weight': 0.3042667630054425, 'subsample': 0.8910142598602964, 'max_depth': 9, 'reg_lambda': 3.931738255757322, 'reg_alpha': 0.8757699326050337, 'num_leaves': 11, 'colsample_bytree': 0.7577836518290562, 'learning_rate': 0.1537577133910688}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:27:58,543]\u001b[0m Trial 418 finished with value: 0.6691874497184231 and parameters: {'min_child_weight': 0.3443158592181529, 'subsample': 0.7716918760181137, 'max_depth': 12, 'reg_lambda': 7.337854739315675, 'reg_alpha': 0.7417650275029277, 'num_leaves': 28, 'colsample_bytree': 0.7680613748179577, 'learning_rate': 0.2827851928724359}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:28:06,151]\u001b[0m Trial 419 finished with value: 0.6770716009654063 and parameters: {'min_child_weight': 0.8671344154104283, 'subsample': 0.6049800419446794, 'max_depth': 10, 'reg_lambda': 6.019263555986408, 'reg_alpha': 0.5641409130001861, 'num_leaves': 17, 'colsample_bytree': 0.8462030500890845, 'learning_rate': 0.2125902276886422}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:28:11,272]\u001b[0m Trial 420 finished with value: 0.6762670957361223 and parameters: {'min_child_weight': 0.47299563079430024, 'subsample': 0.7865259288048597, 'max_depth': 11, 'reg_lambda': 6.676031948733552, 'reg_alpha': 1.8156276017835435, 'num_leaves': 11, 'colsample_bytree': 0.7036226232077593, 'learning_rate': 0.22030495620622656}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:28:13,270]\u001b[0m Trial 421 finished with value: 0.6111021721641191 and parameters: {'min_child_weight': 0.8024957946959063, 'subsample': 0.608536648413611, 'max_depth': 10, 'reg_lambda': 6.280366807332173, 'reg_alpha': 0.43543726403748795, 'num_leaves': 2, 'colsample_bytree': 0.808042759868883, 'learning_rate': 0.007739259479640103}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:28:24,959]\u001b[0m Trial 422 finished with value: 0.6703137570394208 and parameters: {'min_child_weight': 0.4461118052951759, 'subsample': 0.6835351709454746, 'max_depth': 12, 'reg_lambda': 7.662438129980048, 'reg_alpha': 0.30606941575364865, 'num_leaves': 36, 'colsample_bytree': 0.8665316017854028, 'learning_rate': 0.25191829837466573}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:28:27,016]\u001b[0m Trial 423 finished with value: 0.6810941271118263 and parameters: {'min_child_weight': 0.13569129605485777, 'subsample': 0.6177390193617566, 'max_depth': 9, 'reg_lambda': 5.009268276826241, 'reg_alpha': 0.18043353230260628, 'num_leaves': 2, 'colsample_bytree': 0.7444482314084441, 'learning_rate': 0.18842867096086588}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:28:33,239]\u001b[0m Trial 424 finished with value: 0.6662912308930008 and parameters: {'min_child_weight': 0.8432591198780025, 'subsample': 0.6000256324249621, 'max_depth': 9, 'reg_lambda': 5.855098948155879, 'reg_alpha': 2.8985495522060534, 'num_leaves': 19, 'colsample_bytree': 0.8344418644150363, 'learning_rate': 0.35383790506028034}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:28:42,158]\u001b[0m Trial 425 finished with value: 0.6727272727272727 and parameters: {'min_child_weight': 0.20639996791117782, 'subsample': 0.6313996244171912, 'max_depth': 11, 'reg_lambda': 6.339655099563361, 'reg_alpha': 0.6441696405372455, 'num_leaves': 25, 'colsample_bytree': 0.8265288710497665, 'learning_rate': 0.3021599732566455}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:28:47,845]\u001b[0m Trial 426 finished with value: 0.6632341110217216 and parameters: {'min_child_weight': 0.7650536623731979, 'subsample': 0.7649805275329691, 'max_depth': 8, 'reg_lambda': 7.2372541217546535, 'reg_alpha': 0.30491280560207223, 'num_leaves': 11, 'colsample_bytree': 0.77807820250068, 'learning_rate': 0.4730066499592367}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:28:49,730]\u001b[0m Trial 427 finished with value: 0.685277554304103 and parameters: {'min_child_weight': 0.11500511818996832, 'subsample': 0.8219351239470286, 'max_depth': 29, 'reg_lambda': 4.1898675963518635, 'reg_alpha': 0.11013363947151532, 'num_leaves': 2, 'colsample_bytree': 0.7430553199742982, 'learning_rate': 0.27156393134500173}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:28:57,179]\u001b[0m Trial 428 finished with value: 0.6711182622687047 and parameters: {'min_child_weight': 0.09002203005269858, 'subsample': 0.6082277893282748, 'max_depth': 7, 'reg_lambda': 4.630555218071471, 'reg_alpha': 0.24062043247339054, 'num_leaves': 18, 'colsample_bytree': 0.7964777646267899, 'learning_rate': 0.1964861002060316}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:29:01,966]\u001b[0m Trial 429 finished with value: 0.6432823813354787 and parameters: {'min_child_weight': 0.8731970401269816, 'subsample': 0.788385835858977, 'max_depth': 5, 'reg_lambda': 5.298677072330116, 'reg_alpha': 0.09938531514497517, 'num_leaves': 11, 'colsample_bytree': 0.7299260145812386, 'learning_rate': 0.7173037968601157}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:29:09,474]\u001b[0m Trial 430 finished with value: 0.6870474658085278 and parameters: {'min_child_weight': 0.8199709426868406, 'subsample': 0.7222200113765177, 'max_depth': 13, 'reg_lambda': 9.19178794221197, 'reg_alpha': 3.6333512911853436, 'num_leaves': 31, 'colsample_bytree': 0.6783281536554608, 'learning_rate': 0.12405390999927002}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:29:11,426]\u001b[0m Trial 431 finished with value: 0.678841512469831 and parameters: {'min_child_weight': 0.1705668587917207, 'subsample': 0.881035548477025, 'max_depth': 14, 'reg_lambda': 6.5873843118374165, 'reg_alpha': 0.384566957329292, 'num_leaves': 2, 'colsample_bytree': 0.7145727897200772, 'learning_rate': 0.14928884912160917}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:29:17,988]\u001b[0m Trial 432 finished with value: 0.6738535800482703 and parameters: {'min_child_weight': 0.3311837366313713, 'subsample': 0.8573431599684189, 'max_depth': 6, 'reg_lambda': 5.338823840172496, 'reg_alpha': 0.5261669043288735, 'num_leaves': 19, 'colsample_bytree': 0.7288742828439784, 'learning_rate': 0.16799126603089623}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:29:23,683]\u001b[0m Trial 433 finished with value: 0.6772325020112631 and parameters: {'min_child_weight': 0.7463579710861912, 'subsample': 0.6594341468223031, 'max_depth': 10, 'reg_lambda': 5.672317696148671, 'reg_alpha': 0.40240582865102226, 'num_leaves': 12, 'colsample_bytree': 0.7649170519758265, 'learning_rate': 0.23879419691648512}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:29:25,575]\u001b[0m Trial 434 finished with value: 0.6785197103781175 and parameters: {'min_child_weight': 0.38820378958197227, 'subsample': 0.8728289977915791, 'max_depth': 7, 'reg_lambda': 6.787484233899274, 'reg_alpha': 0.0014265541417976257, 'num_leaves': 2, 'colsample_bytree': 0.6944229735509315, 'learning_rate': 0.10784934393703378}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:29:34,196]\u001b[0m Trial 435 finished with value: 0.6748189863234111 and parameters: {'min_child_weight': 0.7838451291821269, 'subsample': 0.8649732353740535, 'max_depth': 11, 'reg_lambda': 6.456761736921028, 'reg_alpha': 0.699672778701801, 'num_leaves': 27, 'colsample_bytree': 0.7082993453565346, 'learning_rate': 0.1364704139524042}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:29:40,115]\u001b[0m Trial 436 finished with value: 0.6606596942880129 and parameters: {'min_child_weight': 0.8463296148577746, 'subsample': 0.6116455672469454, 'max_depth': 10, 'reg_lambda': 3.5304312867092316, 'reg_alpha': 0.5573642717174582, 'num_leaves': 12, 'colsample_bytree': 0.8484254996285732, 'learning_rate': 0.37515263697497947}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:29:50,528]\u001b[0m Trial 437 finished with value: 0.6727272727272726 and parameters: {'min_child_weight': 0.03180954789738523, 'subsample': 0.8516395559310638, 'max_depth': 8, 'reg_lambda': 6.177896579190796, 'reg_alpha': 0.22344001421784582, 'num_leaves': 45, 'colsample_bytree': 0.7481246560853106, 'learning_rate': 0.17609732293805522}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:29:58,122]\u001b[0m Trial 438 finished with value: 0.670957361222848 and parameters: {'min_child_weight': 0.49555900221820753, 'subsample': 0.6268150283225127, 'max_depth': 9, 'reg_lambda': 8.160155902641657, 'reg_alpha': 0.33513423480892174, 'num_leaves': 19, 'colsample_bytree': 0.8067337422539373, 'learning_rate': 0.29620067335473044}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:30:12,847]\u001b[0m Trial 439 finished with value: 0.6798069187449719 and parameters: {'min_child_weight': 0.41284190372794016, 'subsample': 0.8882214485825921, 'max_depth': 11, 'reg_lambda': 5.5188509137617725, 'reg_alpha': 0.18361113941153576, 'num_leaves': 509, 'colsample_bytree': 0.7363231081242606, 'learning_rate': 0.16345239774501477}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:30:19,504]\u001b[0m Trial 440 finished with value: 0.6806114239742558 and parameters: {'min_child_weight': 0.2987665660497981, 'subsample': 0.6172538563571242, 'max_depth': 12, 'reg_lambda': 5.920637813792792, 'reg_alpha': 0.8320873334406186, 'num_leaves': 13, 'colsample_bytree': 0.8647668809991271, 'learning_rate': 0.21609211790457464}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:30:21,419]\u001b[0m Trial 441 finished with value: 0.6814159292035399 and parameters: {'min_child_weight': 0.7987163068378573, 'subsample': 0.608274230989415, 'max_depth': 5, 'reg_lambda': 3.7762693615057, 'reg_alpha': 0.4587488974764167, 'num_leaves': 2, 'colsample_bytree': 0.7887944815738763, 'learning_rate': 0.24064726085024862}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:30:24,623]\u001b[0m Trial 442 finished with value: 0.6830249396621078 and parameters: {'min_child_weight': 0.12224700351423914, 'subsample': 0.8113367272514193, 'max_depth': 8, 'reg_lambda': 4.382824652313235, 'reg_alpha': 0.11891544309486081, 'num_leaves': 28, 'colsample_bytree': 0.18132036949386227, 'learning_rate': 0.1423887793356348}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:30:30,176]\u001b[0m Trial 443 finished with value: 0.6666130329847144 and parameters: {'min_child_weight': 0.8227601346077767, 'subsample': 0.6224939475963777, 'max_depth': 10, 'reg_lambda': 7.969518084829982, 'reg_alpha': 0.3001970622645841, 'num_leaves': 11, 'colsample_bytree': 0.7918648017556918, 'learning_rate': 0.32916026197294235}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:30:32,057]\u001b[0m Trial 444 finished with value: 0.6790024135156878 and parameters: {'min_child_weight': 0.5430344312469089, 'subsample': 0.865442139827879, 'max_depth': 12, 'reg_lambda': 7.188539526865194, 'reg_alpha': 0.08487897551371182, 'num_leaves': 2, 'colsample_bytree': 0.7223861989150937, 'learning_rate': 0.18553855043869394}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:30:39,699]\u001b[0m Trial 445 finished with value: 0.6704746580852776 and parameters: {'min_child_weight': 0.3558707148036947, 'subsample': 0.7494510388142167, 'max_depth': 11, 'reg_lambda': 6.1004214779457655, 'reg_alpha': 0.503286335703683, 'num_leaves': 20, 'colsample_bytree': 0.7698099717276886, 'learning_rate': 0.2281085002261025}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:30:49,644]\u001b[0m Trial 446 finished with value: 0.6693483507642799 and parameters: {'min_child_weight': 0.08880232374488697, 'subsample': 0.832589325701014, 'max_depth': 13, 'reg_lambda': 6.928144476601319, 'reg_alpha': 0.20442590885782128, 'num_leaves': 37, 'colsample_bytree': 0.6848073615101887, 'learning_rate': 0.12176581621697406}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:30:53,921]\u001b[0m Trial 447 finished with value: 0.6740144810941271 and parameters: {'min_child_weight': 0.7352292585329594, 'subsample': 0.6143300410503759, 'max_depth': 10, 'reg_lambda': 8.319712790696606, 'reg_alpha': 0.635364773418591, 'num_leaves': 11, 'colsample_bytree': 0.500288020024594, 'learning_rate': 0.20183671273905482}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:30:55,828]\u001b[0m Trial 448 finished with value: 0.6806114239742558 and parameters: {'min_child_weight': 0.8488216703755412, 'subsample': 0.7988532964647371, 'max_depth': 4, 'reg_lambda': 7.439163711231111, 'reg_alpha': 0.22059345338504366, 'num_leaves': 2, 'colsample_bytree': 0.7509871990141629, 'learning_rate': 0.28527453363217786}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:31:03,970]\u001b[0m Trial 449 finished with value: 0.678841512469831 and parameters: {'min_child_weight': 0.7642251976860168, 'subsample': 0.6564363094268464, 'max_depth': 7, 'reg_lambda': 4.960551594881006, 'reg_alpha': 0.33223695521724006, 'num_leaves': 22, 'colsample_bytree': 0.8185623215928453, 'learning_rate': 0.1983292659865434}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:31:09,641]\u001b[0m Trial 450 finished with value: 0.6633950120675784 and parameters: {'min_child_weight': 0.7759039855067487, 'subsample': 0.633441880930183, 'max_depth': 9, 'reg_lambda': 5.694524062151549, 'reg_alpha': 0.4062557601188511, 'num_leaves': 11, 'colsample_bytree': 0.8282077831468448, 'learning_rate': 0.38619863748197714}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:31:14,781]\u001b[0m Trial 451 finished with value: 0.6799678197908288 and parameters: {'min_child_weight': 0.2633292567064997, 'subsample': 0.8839422985257281, 'max_depth': 11, 'reg_lambda': 4.566481977183086, 'reg_alpha': 0.5709932988432742, 'num_leaves': 11, 'colsample_bytree': 0.7032031865414016, 'learning_rate': 0.15831942589436646}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:31:21,095]\u001b[0m Trial 452 finished with value: 0.6662912308930008 and parameters: {'min_child_weight': 0.8772420388380714, 'subsample': 0.6736607906511147, 'max_depth': 6, 'reg_lambda': 7.777270932184928, 'reg_alpha': 0.3056332155098498, 'num_leaves': 28, 'colsample_bytree': 0.6655101741371218, 'learning_rate': 0.2580739867250717}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:31:23,141]\u001b[0m Trial 453 finished with value: 0.6738535800482703 and parameters: {'min_child_weight': 0.38394301822263094, 'subsample': 0.9055379773335787, 'max_depth': 14, 'reg_lambda': 6.520922985524238, 'reg_alpha': 0.00015973705530152038, 'num_leaves': 2, 'colsample_bytree': 0.878467757161155, 'learning_rate': 0.08615239149138147}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:31:30,662]\u001b[0m Trial 454 finished with value: 0.6778761061946902 and parameters: {'min_child_weight': 0.3689997458560247, 'subsample': 0.8909520249799487, 'max_depth': 14, 'reg_lambda': 6.013166036425537, 'reg_alpha': 0.7439800488641913, 'num_leaves': 20, 'colsample_bytree': 0.7227275172229227, 'learning_rate': 0.14182298259154946}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:31:36,506]\u001b[0m Trial 455 finished with value: 0.6785197103781175 and parameters: {'min_child_weight': 0.46497509897413825, 'subsample': 0.7804150887204807, 'max_depth': 8, 'reg_lambda': 8.483229004794161, 'reg_alpha': 0.1592224114208132, 'num_leaves': 11, 'colsample_bytree': 0.8507411035628683, 'learning_rate': 0.22351408010705526}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:31:38,410]\u001b[0m Trial 456 finished with value: 0.6790024135156878 and parameters: {'min_child_weight': 0.3348419216279817, 'subsample': 0.8726794449569831, 'max_depth': 13, 'reg_lambda': 7.042344745319831, 'reg_alpha': 0.1078442959443349, 'num_leaves': 2, 'colsample_bytree': 0.577953824002013, 'learning_rate': 0.17776103483342606}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:31:46,804]\u001b[0m Trial 457 finished with value: 0.6727272727272726 and parameters: {'min_child_weight': 0.8902414067427779, 'subsample': 0.737935965918085, 'max_depth': 27, 'reg_lambda': 6.343932002983524, 'reg_alpha': 0.3934571845578652, 'num_leaves': 23, 'colsample_bytree': 0.7610824454949019, 'learning_rate': 0.2928243564906972}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:31:56,952]\u001b[0m Trial 458 finished with value: 0.6728881737731295 and parameters: {'min_child_weight': 0.14857888096985122, 'subsample': 0.7954338856217191, 'max_depth': 7, 'reg_lambda': 5.372798940770555, 'reg_alpha': 0.23649916737868787, 'num_leaves': 137, 'colsample_bytree': 0.7411937865995644, 'learning_rate': 0.2345405004208051}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:32:03,865]\u001b[0m Trial 459 finished with value: 0.671761866452132 and parameters: {'min_child_weight': 0.8632403070929369, 'subsample': 0.8764735150336856, 'max_depth': 12, 'reg_lambda': 5.100544605307628, 'reg_alpha': 0.0009532697730804483, 'num_leaves': 17, 'colsample_bytree': 0.711245086679476, 'learning_rate': 0.16492014707818337}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:32:09,163]\u001b[0m Trial 460 finished with value: 0.6846339501206758 and parameters: {'min_child_weight': 0.42971874902489615, 'subsample': 0.6486916160195677, 'max_depth': 10, 'reg_lambda': 8.006325421307638, 'reg_alpha': 0.49325807406897215, 'num_leaves': 10, 'colsample_bytree': 0.7364298944508589, 'learning_rate': 0.11425195993531292}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:32:19,978]\u001b[0m Trial 461 finished with value: 0.674979887369268 and parameters: {'min_child_weight': 0.7475517274346193, 'subsample': 0.7115371134806393, 'max_depth': 9, 'reg_lambda': 6.794993806903289, 'reg_alpha': 0.2978390645904381, 'num_leaves': 37, 'colsample_bytree': 0.8177733427506745, 'learning_rate': 0.20536929640786916}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:32:22,015]\u001b[0m Trial 462 finished with value: 0.6810941271118263 and parameters: {'min_child_weight': 0.4071366073642021, 'subsample': 0.666690102111501, 'max_depth': 13, 'reg_lambda': 6.57409283965405, 'reg_alpha': 0.3941709184639619, 'num_leaves': 2, 'colsample_bytree': 0.6841369317061109, 'learning_rate': 0.2479240916651567}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:32:29,103]\u001b[0m Trial 463 finished with value: 0.6716009654062751 and parameters: {'min_child_weight': 0.8173017403474331, 'subsample': 0.691163651455847, 'max_depth': 11, 'reg_lambda': 5.811527864003, 'reg_alpha': 0.6590605904235517, 'num_leaves': 18, 'colsample_bytree': 0.7727379831799035, 'learning_rate': 0.321124727438018}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:32:37,903]\u001b[0m Trial 464 finished with value: 0.6666130329847144 and parameters: {'min_child_weight': 0.8352150164702948, 'subsample': 0.789315491951448, 'max_depth': 8, 'reg_lambda': 6.713423578086621, 'reg_alpha': 0.09549748967225986, 'num_leaves': 29, 'colsample_bytree': 0.7604023025692354, 'learning_rate': 0.4106550622228475}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:32:43,104]\u001b[0m Trial 465 finished with value: 0.6831858407079647 and parameters: {'min_child_weight': 0.7965854914747518, 'subsample': 0.9912926518096894, 'max_depth': 9, 'reg_lambda': 8.169505423959297, 'reg_alpha': 3.7786966180573414, 'num_leaves': 11, 'colsample_bytree': 0.7998797792943715, 'learning_rate': 0.19271830611867002}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:32:48,177]\u001b[0m Trial 466 finished with value: 0.6802896218825423 and parameters: {'min_child_weight': 0.7802583952439337, 'subsample': 0.6008740385650251, 'max_depth': 9, 'reg_lambda': 5.519103913870537, 'reg_alpha': 3.0833794181677225, 'num_leaves': 11, 'colsample_bytree': 0.7852910466141153, 'learning_rate': 0.2867882513937005}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:32:56,939]\u001b[0m Trial 467 finished with value: 0.6596942880128721 and parameters: {'min_child_weight': 0.3187656842658343, 'subsample': 0.8139120297574588, 'max_depth': 12, 'reg_lambda': 6.850942970555066, 'reg_alpha': 0.5522057995713474, 'num_leaves': 97, 'colsample_bytree': 0.6378813067825275, 'learning_rate': 0.5588215804094763}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:32:58,913]\u001b[0m Trial 468 finished with value: 0.6778761061946902 and parameters: {'min_child_weight': 0.047782722596872135, 'subsample': 0.864226748017824, 'max_depth': 6, 'reg_lambda': 6.13864843458732, 'reg_alpha': 0.19965658798998817, 'num_leaves': 2, 'colsample_bytree': 0.7314600211304056, 'learning_rate': 0.13977025092186843}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:33:05,963]\u001b[0m Trial 469 finished with value: 0.682059533386967 and parameters: {'min_child_weight': 0.245391587837317, 'subsample': 0.7023645987376598, 'max_depth': 11, 'reg_lambda': 4.291974963212066, 'reg_alpha': 0.9540485380057544, 'num_leaves': 19, 'colsample_bytree': 0.6968594990062945, 'learning_rate': 0.09890360812034502}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:33:11,510]\u001b[0m Trial 470 finished with value: 0.6764279967819791 and parameters: {'min_child_weight': 0.8036482440109726, 'subsample': 0.6270624001339594, 'max_depth': 10, 'reg_lambda': 4.105512466685779, 'reg_alpha': 0.4306772309384738, 'num_leaves': 10, 'colsample_bytree': 0.8443023684445884, 'learning_rate': 0.18828753095863235}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:33:20,451]\u001b[0m Trial 471 finished with value: 0.6738535800482703 and parameters: {'min_child_weight': 0.716419850651326, 'subsample': 0.6072416712909373, 'max_depth': 10, 'reg_lambda': 6.4009766302601, 'reg_alpha': 0.6180450651354998, 'num_leaves': 29, 'colsample_bytree': 0.7172655636832724, 'learning_rate': 0.25834560860571076}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:33:22,423]\u001b[0m Trial 472 finished with value: 0.6775543041029767 and parameters: {'min_child_weight': 0.3488164874562405, 'subsample': 0.9729574286177761, 'max_depth': 12, 'reg_lambda': 7.512083552049717, 'reg_alpha': 1.412491798464066, 'num_leaves': 2, 'colsample_bytree': 0.7561575061854542, 'learning_rate': 0.15864972278707415}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:33:32,258]\u001b[0m Trial 473 finished with value: 0.6786806114239743 and parameters: {'min_child_weight': 0.08626953092325429, 'subsample': 0.8418586885260669, 'max_depth': 7, 'reg_lambda': 5.940443942052746, 'reg_alpha': 0.7732673011946504, 'num_leaves': 367, 'colsample_bytree': 0.7247865322646972, 'learning_rate': 0.13542454150835853}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:33:38,072]\u001b[0m Trial 474 finished with value: 0.6775543041029767 and parameters: {'min_child_weight': 0.1148516541240195, 'subsample': 0.9805017715013553, 'max_depth': 6, 'reg_lambda': 4.88755443455635, 'reg_alpha': 0.1613914372228451, 'num_leaves': 254, 'colsample_bytree': 0.4678125536018781, 'learning_rate': 0.20729028676054587}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:33:49,647]\u001b[0m Trial 475 finished with value: 0.6756234915526951 and parameters: {'min_child_weight': 0.08185341734797404, 'subsample': 0.6443908407152878, 'max_depth': 8, 'reg_lambda': 7.855236546965471, 'reg_alpha': 0.2738383202921917, 'num_leaves': 57, 'colsample_bytree': 0.8114160385040996, 'learning_rate': 0.2322085852796588}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:33:55,665]\u001b[0m Trial 476 finished with value: 0.6748189863234111 and parameters: {'min_child_weight': 0.44542864035817803, 'subsample': 0.8502565894216997, 'max_depth': 5, 'reg_lambda': 7.139227949456296, 'reg_alpha': 0.11566735782270246, 'num_leaves': 19, 'colsample_bytree': 0.745746831643015, 'learning_rate': 0.17473401529862007}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:33:57,696]\u001b[0m Trial 477 finished with value: 0.6825422365245374 and parameters: {'min_child_weight': 0.8531402281369599, 'subsample': 0.8988267109417926, 'max_depth': 7, 'reg_lambda': 5.23694797669081, 'reg_alpha': 0.3044233146298029, 'num_leaves': 2, 'colsample_bytree': 0.76110031505806, 'learning_rate': 0.4547788535790867}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:34:03,529]\u001b[0m Trial 478 finished with value: 0.6703137570394209 and parameters: {'min_child_weight': 0.36811331353279736, 'subsample': 0.6163755776016415, 'max_depth': 10, 'reg_lambda': 5.765690415357114, 'reg_alpha': 0.47792149455020655, 'num_leaves': 12, 'colsample_bytree': 0.7804613960686027, 'learning_rate': 0.246457881896481}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:34:14,962]\u001b[0m Trial 479 finished with value: 0.6667739340305712 and parameters: {'min_child_weight': 0.8299561957551383, 'subsample': 0.6359310236139234, 'max_depth': 30, 'reg_lambda': 6.216087673443774, 'reg_alpha': 0.5595420051824076, 'num_leaves': 40, 'colsample_bytree': 0.8612031407166859, 'learning_rate': 0.29867920075805005}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:34:22,845]\u001b[0m Trial 480 finished with value: 0.6765888978278358 and parameters: {'min_child_weight': 0.29230613181543164, 'subsample': 0.6001533149956724, 'max_depth': 9, 'reg_lambda': 8.344010081354952, 'reg_alpha': 0.3857162339829122, 'num_leaves': 20, 'colsample_bytree': 0.7082401176735517, 'learning_rate': 0.2065985210531186}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:34:25,995]\u001b[0m Trial 481 finished with value: 0.6688656476267096 and parameters: {'min_child_weight': 0.7604993706746817, 'subsample': 0.8791411191581063, 'max_depth': 12, 'reg_lambda': 4.765356798253762, 'reg_alpha': 0.26029544944986827, 'num_leaves': 12, 'colsample_bytree': 0.2641314282986788, 'learning_rate': 0.011796436100661847}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:34:35,651]\u001b[0m Trial 482 finished with value: 0.6682220434432824 and parameters: {'min_child_weight': 0.5726975158538012, 'subsample': 0.6132720494358372, 'max_depth': 11, 'reg_lambda': 8.57697367889956, 'reg_alpha': 0.703322449065116, 'num_leaves': 28, 'colsample_bytree': 0.8322626543464386, 'learning_rate': 0.3418222853357811}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:34:37,595]\u001b[0m Trial 483 finished with value: 0.6765888978278358 and parameters: {'min_child_weight': 0.1028045354024489, 'subsample': 0.8583505837717479, 'max_depth': 4, 'reg_lambda': 5.580022126124663, 'reg_alpha': 0.07747307492223804, 'num_leaves': 2, 'colsample_bytree': 0.7374041989603974, 'learning_rate': 0.11754927223174873}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:34:44,015]\u001b[0m Trial 484 finished with value: 0.6761061946902656 and parameters: {'min_child_weight': 0.78263714830812, 'subsample': 0.6086961534192241, 'max_depth': 31, 'reg_lambda': 5.350836179139707, 'reg_alpha': 0.38093016837494076, 'num_leaves': 11, 'colsample_bytree': 0.8818866036289882, 'learning_rate': 0.18028802178362707}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:34:52,004]\u001b[0m Trial 485 finished with value: 0.6865647626709575 and parameters: {'min_child_weight': 0.5164268646489232, 'subsample': 0.6210263307829437, 'max_depth': 10, 'reg_lambda': 8.217730208106623, 'reg_alpha': 0.4866010577982192, 'num_leaves': 20, 'colsample_bytree': 0.6941993622444634, 'learning_rate': 0.15059935763407378}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:34:54,065]\u001b[0m Trial 486 finished with value: 0.6786806114239743 and parameters: {'min_child_weight': 0.02856124866250019, 'subsample': 0.8724953963864612, 'max_depth': 13, 'reg_lambda': 6.8830980609216255, 'reg_alpha': 0.19571012089543038, 'num_leaves': 2, 'colsample_bytree': 0.7226838702245351, 'learning_rate': 0.15413287609524645}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:34:59,597]\u001b[0m Trial 487 finished with value: 0.6619469026548673 and parameters: {'min_child_weight': 0.8146198853645551, 'subsample': 0.6069898755645454, 'max_depth': 11, 'reg_lambda': 5.9731544082521415, 'reg_alpha': 0.628504009455174, 'num_leaves': 12, 'colsample_bytree': 0.6633734457144508, 'learning_rate': 0.37094530045188656}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:35:07,918]\u001b[0m Trial 488 finished with value: 0.6799678197908287 and parameters: {'min_child_weight': 0.39301625150432984, 'subsample': 0.8824367866982897, 'max_depth': 12, 'reg_lambda': 6.602988877845083, 'reg_alpha': 0.3073506856154259, 'num_leaves': 28, 'colsample_bytree': 0.6999156124229986, 'learning_rate': 0.13073629761363204}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:35:13,032]\u001b[0m Trial 489 finished with value: 0.6725663716814159 and parameters: {'min_child_weight': 0.1312541540225266, 'subsample': 0.8655292210678895, 'max_depth': 14, 'reg_lambda': 9.508456479404343, 'reg_alpha': 0.07496950944208548, 'num_leaves': 11, 'colsample_bytree': 0.7459420781487978, 'learning_rate': 0.1697110163177217}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:35:20,064]\u001b[0m Trial 490 finished with value: 0.6279967819790828 and parameters: {'min_child_weight': 0.7297247619925794, 'subsample': 0.7927111023915877, 'max_depth': 8, 'reg_lambda': 5.690434840567161, 'reg_alpha': 0.2159856910713519, 'num_leaves': 20, 'colsample_bytree': 0.7485130298765195, 'learning_rate': 0.00371843644681469}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:35:21,849]\u001b[0m Trial 491 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.06615046257086209, 'subsample': 0.7668254950220229, 'max_depth': 9, 'reg_lambda': 8.024169383068685, 'reg_alpha': 0.16144580608112333, 'num_leaves': 2, 'colsample_bytree': 0.722160361670709, 'learning_rate': 0.00011017102285322712}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:35:26,967]\u001b[0m Trial 492 finished with value: 0.6740144810941271 and parameters: {'min_child_weight': 0.33949312797553927, 'subsample': 0.9870234278400236, 'max_depth': 8, 'reg_lambda': 6.525689911524427, 'reg_alpha': 0.8201587813547153, 'num_leaves': 12, 'colsample_bytree': 0.7051352655102254, 'learning_rate': 0.22426704046909107}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:35:28,723]\u001b[0m Trial 493 finished with value: 0.6851166532582462 and parameters: {'min_child_weight': 0.41837099272636347, 'subsample': 0.7263798441614491, 'max_depth': 10, 'reg_lambda': 6.2193917553557565, 'reg_alpha': 1.686055275450435, 'num_leaves': 2, 'colsample_bytree': 0.6174791906989249, 'learning_rate': 0.27091883126991234}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:35:36,594]\u001b[0m Trial 494 finished with value: 0.6793242156074014 and parameters: {'min_child_weight': 0.17066065768010383, 'subsample': 0.798452407945877, 'max_depth': 6, 'reg_lambda': 5.094620038566668, 'reg_alpha': 2.5948241916347556, 'num_leaves': 308, 'colsample_bytree': 0.8532652573593837, 'learning_rate': 0.20180969353697387}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:35:46,184]\u001b[0m Trial 495 finished with value: 0.6659694288012872 and parameters: {'min_child_weight': 0.8669846559208458, 'subsample': 0.6224075974704617, 'max_depth': 11, 'reg_lambda': 6.404302866869231, 'reg_alpha': 0.503352710757474, 'num_leaves': 35, 'colsample_bytree': 0.7992761327271134, 'learning_rate': 0.3231694173429134}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:35:53,688]\u001b[0m Trial 496 finished with value: 0.6711182622687047 and parameters: {'min_child_weight': 0.8945205602643759, 'subsample': 0.6139397902816524, 'max_depth': 11, 'reg_lambda': 5.842718221221892, 'reg_alpha': 0.4671539567411939, 'num_leaves': 20, 'colsample_bytree': 0.8263053459216488, 'learning_rate': 0.2659375749354595}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:35:58,621]\u001b[0m Trial 497 finished with value: 0.6754625905068383 and parameters: {'min_child_weight': 0.8461752263352733, 'subsample': 0.7764545002601898, 'max_depth': 5, 'reg_lambda': 4.476029618175982, 'reg_alpha': 0.07296078944756504, 'num_leaves': 12, 'colsample_bytree': 0.7775634708412356, 'learning_rate': 0.19405108379370692}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:36:05,359]\u001b[0m Trial 498 finished with value: 0.6849557522123895 and parameters: {'min_child_weight': 0.7605080173356364, 'subsample': 0.8777563877949577, 'max_depth': 10, 'reg_lambda': 3.8594609559082116, 'reg_alpha': 3.3079188015664016, 'num_leaves': 25, 'colsample_bytree': 0.6771586435980349, 'learning_rate': 0.10943885716351294}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:36:16,185]\u001b[0m Trial 499 finished with value: 0.6773934030571199 and parameters: {'min_child_weight': 0.05309409913720829, 'subsample': 0.9685797360096446, 'max_depth': 20, 'reg_lambda': 7.037325150147764, 'reg_alpha': 0.005038008352519729, 'num_leaves': 48, 'colsample_bytree': 0.7323609420334426, 'learning_rate': 0.22628187952793105}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:36:18,020]\u001b[0m Trial 500 finished with value: 0.6772325020112631 and parameters: {'min_child_weight': 0.10768787910710348, 'subsample': 0.8073670909987699, 'max_depth': 13, 'reg_lambda': 5.46360140504352, 'reg_alpha': 0.19815695655584337, 'num_leaves': 2, 'colsample_bytree': 0.7332209510556823, 'learning_rate': 0.1540869126833036}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:36:23,026]\u001b[0m Trial 501 finished with value: 0.6838294448913917 and parameters: {'min_child_weight': 0.315323301674446, 'subsample': 0.9126686814917175, 'max_depth': 12, 'reg_lambda': 8.833574918710637, 'reg_alpha': 0.33970092398387886, 'num_leaves': 11, 'colsample_bytree': 0.7086888569871677, 'learning_rate': 0.12810170098136003}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:36:30,034]\u001b[0m Trial 502 finished with value: 0.6749798873692678 and parameters: {'min_child_weight': 0.3550945863832845, 'subsample': 0.6309525576709089, 'max_depth': 9, 'reg_lambda': 6.069030652703208, 'reg_alpha': 0.4194900841344332, 'num_leaves': 19, 'colsample_bytree': 0.7828415827532136, 'learning_rate': 0.24563996810356714}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:36:38,085]\u001b[0m Trial 503 finished with value: 0.6809332260659694 and parameters: {'min_child_weight': 0.4568292188769518, 'subsample': 0.9814384166111364, 'max_depth': 8, 'reg_lambda': 6.977485973901944, 'reg_alpha': 0.5785372699557313, 'num_leaves': 32, 'colsample_bytree': 0.6881316487264773, 'learning_rate': 0.17505842307512212}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:36:39,998]\u001b[0m Trial 504 finished with value: 0.6790024135156878 and parameters: {'min_child_weight': 0.3918243586765051, 'subsample': 0.8908194310595643, 'max_depth': 11, 'reg_lambda': 6.271026421885118, 'reg_alpha': 0.34316269392167065, 'num_leaves': 2, 'colsample_bytree': 0.749380985965379, 'learning_rate': 0.17298940854077832}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:36:45,027]\u001b[0m Trial 505 finished with value: 0.6838294448913917 and parameters: {'min_child_weight': 0.1355616931799573, 'subsample': 0.8286014346624979, 'max_depth': 7, 'reg_lambda': 6.683286456190094, 'reg_alpha': 0.18983485562067745, 'num_leaves': 11, 'colsample_bytree': 0.7187162685180299, 'learning_rate': 0.14182867085637157}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:36:51,898]\u001b[0m Trial 506 finished with value: 0.6679002413515688 and parameters: {'min_child_weight': 0.833998036422145, 'subsample': 0.6613018891675647, 'max_depth': 13, 'reg_lambda': 7.292727239341362, 'reg_alpha': 0.7267589271682264, 'num_leaves': 20, 'colsample_bytree': 0.7571941308411801, 'learning_rate': 0.3339779833680858}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:36:53,726]\u001b[0m Trial 507 finished with value: 0.6733708769106999 and parameters: {'min_child_weight': 0.3703930551331885, 'subsample': 0.8533300175434683, 'max_depth': 6, 'reg_lambda': 5.632603089078153, 'reg_alpha': 0.2852899239727698, 'num_leaves': 2, 'colsample_bytree': 0.7704680996526067, 'learning_rate': 0.07631665278321074}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:36:57,608]\u001b[0m Trial 508 finished with value: 0.6720836685438456 and parameters: {'min_child_weight': 0.08245912972251657, 'subsample': 0.8671263819067405, 'max_depth': 9, 'reg_lambda': 7.703424839436593, 'reg_alpha': 0.249529364626061, 'num_leaves': 13, 'colsample_bytree': 0.41239884182753017, 'learning_rate': 0.19747529513913759}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:37:05,616]\u001b[0m Trial 509 finished with value: 0.6806114239742558 and parameters: {'min_child_weight': 0.006484777822552613, 'subsample': 0.8588978923160644, 'max_depth': 7, 'reg_lambda': 5.427718268633394, 'reg_alpha': 0.10405589855083691, 'num_leaves': 27, 'colsample_bytree': 0.75705389382001, 'learning_rate': 0.1760860368015799}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:37:10,744]\u001b[0m Trial 510 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.8152262137335522, 'subsample': 0.9426782061089848, 'max_depth': 14, 'reg_lambda': 6.745913560386514, 'reg_alpha': 0.38880010788807084, 'num_leaves': 11, 'colsample_bytree': 0.7996861589769348, 'learning_rate': 0.0017046437788598733}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:37:12,562]\u001b[0m Trial 511 finished with value: 0.678037007240547 and parameters: {'min_child_weight': 0.48467031191710197, 'subsample': 0.6066493622454384, 'max_depth': 3, 'reg_lambda': 8.432895445003206, 'reg_alpha': 0.5031896265380643, 'num_leaves': 2, 'colsample_bytree': 0.7332981709482318, 'learning_rate': 0.1503457457176974}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:37:20,216]\u001b[0m Trial 512 finished with value: 0.6775543041029767 and parameters: {'min_child_weight': 0.7452157200137275, 'subsample': 0.9536390691089786, 'max_depth': 7, 'reg_lambda': 5.000204769871933, 'reg_alpha': 0.11063177893472306, 'num_leaves': 19, 'colsample_bytree': 0.8662963191202223, 'learning_rate': 0.226521789804743}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:37:30,021]\u001b[0m Trial 513 finished with value: 0.6778761061946902 and parameters: {'min_child_weight': 0.20872632560599874, 'subsample': 0.6012861628573085, 'max_depth': 10, 'reg_lambda': 5.919785677689488, 'reg_alpha': 0.6124403089242836, 'num_leaves': 37, 'colsample_bytree': 0.7901913813906276, 'learning_rate': 0.2654809354177704}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:37:32,983]\u001b[0m Trial 514 finished with value: 0.6857602574416732 and parameters: {'min_child_weight': 0.0411098797457352, 'subsample': 0.6762279830454023, 'max_depth': 12, 'reg_lambda': 6.485657770551834, 'reg_alpha': 0.25874568220749006, 'num_leaves': 10, 'colsample_bytree': 0.32696847623043335, 'learning_rate': 0.11127768684523635}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:37:34,848]\u001b[0m Trial 515 finished with value: 0.6815768302493966 and parameters: {'min_child_weight': 0.4411175334456023, 'subsample': 0.7585151796982381, 'max_depth': 9, 'reg_lambda': 8.101062575831964, 'reg_alpha': 0.3777032068980398, 'num_leaves': 2, 'colsample_bytree': 0.8027223423106854, 'learning_rate': 0.21922485623930707}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:37:41,718]\u001b[0m Trial 516 finished with value: 0.6640386162510057 and parameters: {'min_child_weight': 0.8598965674474742, 'subsample': 0.7836964800644055, 'max_depth': 8, 'reg_lambda': 5.314912012812946, 'reg_alpha': 0.16546253082865703, 'num_leaves': 20, 'colsample_bytree': 0.7725601451932838, 'learning_rate': 0.4155725005444546}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:37:47,348]\u001b[0m Trial 517 finished with value: 0.6670957361222849 and parameters: {'min_child_weight': 0.7814758014033368, 'subsample': 0.6185491807013785, 'max_depth': 11, 'reg_lambda': 6.111036130481992, 'reg_alpha': 0.8922902282324596, 'num_leaves': 12, 'colsample_bytree': 0.8377698501268959, 'learning_rate': 0.2876592920536099}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:37:55,887]\u001b[0m Trial 518 finished with value: 0.6672566371681417 and parameters: {'min_child_weight': 0.7931267867456081, 'subsample': 0.6099365727067699, 'max_depth': 10, 'reg_lambda': 8.253487949759668, 'reg_alpha': 0.5732849054982618, 'num_leaves': 29, 'colsample_bytree': 0.8356345130288241, 'learning_rate': 0.5067005331399442}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:38:01,162]\u001b[0m Trial 519 finished with value: 0.6714400643604183 and parameters: {'min_child_weight': 0.3297765950935631, 'subsample': 0.9021903455230459, 'max_depth': 10, 'reg_lambda': 7.891565237523839, 'reg_alpha': 0.4464444068876497, 'num_leaves': 12, 'colsample_bytree': 0.7156664730283291, 'learning_rate': 0.21000473248008203}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:38:08,261]\u001b[0m Trial 520 finished with value: 0.6748189863234111 and parameters: {'min_child_weight': 0.3963868535994719, 'subsample': 0.8866637113732825, 'max_depth': 11, 'reg_lambda': 5.7674185898208385, 'reg_alpha': 0.6425418919767286, 'num_leaves': 21, 'colsample_bytree': 0.6918022317198809, 'learning_rate': 0.09736432569687685}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:38:10,249]\u001b[0m Trial 521 finished with value: 0.6846339501206757 and parameters: {'min_child_weight': 0.7667676871529013, 'subsample': 0.9753942281543663, 'max_depth': 12, 'reg_lambda': 6.288452760758879, 'reg_alpha': 0.6957452136012876, 'num_leaves': 2, 'colsample_bytree': 0.9058184537618164, 'learning_rate': 0.3239980086183465}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:38:15,458]\u001b[0m Trial 522 finished with value: 0.6807723250201126 and parameters: {'min_child_weight': 0.11168866233114966, 'subsample': 0.8703988286421985, 'max_depth': 13, 'reg_lambda': 4.217693394610703, 'reg_alpha': 0.07444176846521418, 'num_leaves': 11, 'colsample_bytree': 0.7375470005130527, 'learning_rate': 0.1329131050272419}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:38:21,653]\u001b[0m Trial 523 finished with value: 0.6759452936444087 and parameters: {'min_child_weight': 0.1541238453602613, 'subsample': 0.812977893679074, 'max_depth': 5, 'reg_lambda': 4.60526740092988, 'reg_alpha': 2.1450064192603406, 'num_leaves': 239, 'colsample_bytree': 0.8810858136239328, 'learning_rate': 0.2570577423925872}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:38:30,241]\u001b[0m Trial 524 finished with value: 0.6709573612228479 and parameters: {'min_child_weight': 0.19161246468455362, 'subsample': 0.6249493267033561, 'max_depth': 10, 'reg_lambda': 8.522239234324072, 'reg_alpha': 0.47186387895259724, 'num_leaves': 26, 'colsample_bytree': 0.8123564858729536, 'learning_rate': 0.3070891690000466}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:38:35,549]\u001b[0m Trial 525 finished with value: 0.6791633145615446 and parameters: {'min_child_weight': 0.7357260843834276, 'subsample': 0.8781455921641931, 'max_depth': 10, 'reg_lambda': 6.027519076729906, 'reg_alpha': 0.0023956111953997716, 'num_leaves': 12, 'colsample_bytree': 0.7162486445021043, 'learning_rate': 0.17260633427745808}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:38:37,451]\u001b[0m Trial 526 finished with value: 0.6807723250201126 and parameters: {'min_child_weight': 0.07442711428158329, 'subsample': 0.8230499606685594, 'max_depth': 32, 'reg_lambda': 4.075705661868219, 'reg_alpha': 0.31113810338517844, 'num_leaves': 2, 'colsample_bytree': 0.6755602276722468, 'learning_rate': 0.1553567914462014}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:38:48,286]\u001b[0m Trial 527 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.7085924780922584, 'subsample': 0.8034380773107449, 'max_depth': 8, 'reg_lambda': 5.185135289715275, 'reg_alpha': 0.1835610475252119, 'num_leaves': 284, 'colsample_bytree': 0.7400102893615219, 'learning_rate': 0.00027375636853416494}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:38:55,641]\u001b[0m Trial 528 finished with value: 0.6727272727272726 and parameters: {'min_child_weight': 0.8315454832333642, 'subsample': 0.965352595147757, 'max_depth': 6, 'reg_lambda': 7.6262286844164375, 'reg_alpha': 0.28148843021164643, 'num_leaves': 44, 'colsample_bytree': 0.7616620584303737, 'learning_rate': 0.36203764762485074}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:38:57,498]\u001b[0m Trial 529 finished with value: 0.6783588093322608 and parameters: {'min_child_weight': 0.8696021311683272, 'subsample': 0.7840638155266427, 'max_depth': 9, 'reg_lambda': 4.82036590545945, 'reg_alpha': 3.4061281259190856, 'num_leaves': 2, 'colsample_bytree': 0.771730251979654, 'learning_rate': 0.1976605645988107}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:39:05,202]\u001b[0m Trial 530 finished with value: 0.6704746580852776 and parameters: {'min_child_weight': 0.4178623667307762, 'subsample': 0.6529483623297733, 'max_depth': 14, 'reg_lambda': 5.595367447578719, 'reg_alpha': 0.400243436736779, 'num_leaves': 19, 'colsample_bytree': 0.8553831635760438, 'learning_rate': 0.2365160154863164}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:39:10,917]\u001b[0m Trial 531 finished with value: 0.6754625905068383 and parameters: {'min_child_weight': 0.09419543115095634, 'subsample': 0.8435806980475388, 'max_depth': 7, 'reg_lambda': 7.1422097445054025, 'reg_alpha': 0.24153774389499613, 'num_leaves': 12, 'colsample_bytree': 0.8118842644999168, 'learning_rate': 0.19614427979791643}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:39:20,037]\u001b[0m Trial 532 finished with value: 0.6748189863234111 and parameters: {'min_child_weight': 0.7965949738729328, 'subsample': 0.7703273734206365, 'max_depth': 8, 'reg_lambda': 8.061460261687634, 'reg_alpha': 0.0024850979631525494, 'num_leaves': 33, 'colsample_bytree': 0.8143579642796511, 'learning_rate': 0.2413144534269712}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:39:26,644]\u001b[0m Trial 533 finished with value: 0.6818986323411101 and parameters: {'min_child_weight': 0.2819162343470665, 'subsample': 0.8737862211243733, 'max_depth': 19, 'reg_lambda': 9.26883854069343, 'reg_alpha': 0.15102981694627965, 'num_leaves': 20, 'colsample_bytree': 0.6524648009759706, 'learning_rate': 0.12537410401048846}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:39:30,525]\u001b[0m Trial 534 finished with value: 0.6756234915526951 and parameters: {'min_child_weight': 0.0420402263577328, 'subsample': 0.9242096037940216, 'max_depth': 6, 'reg_lambda': 7.457376312291519, 'reg_alpha': 0.29312008051866395, 'num_leaves': 10, 'colsample_bytree': 0.5561928892644605, 'learning_rate': 0.18341028573807255}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:39:31,963]\u001b[0m Trial 535 finished with value: 0.6790024135156878 and parameters: {'min_child_weight': 0.849870381383966, 'subsample': 0.7956411735359312, 'max_depth': 8, 'reg_lambda': 9.058746712721941, 'reg_alpha': 0.15115673117698397, 'num_leaves': 2, 'colsample_bytree': 0.13253747665582466, 'learning_rate': 0.27732696676992824}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:39:40,294]\u001b[0m Trial 536 finished with value: 0.6086886564762671 and parameters: {'min_child_weight': 0.6569003622699762, 'subsample': 0.6009478522736827, 'max_depth': 11, 'reg_lambda': 6.513751952499519, 'reg_alpha': 0.5549569609888063, 'num_leaves': 25, 'colsample_bytree': 0.8397818051766093, 'learning_rate': 0.0029152869488858766}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:39:42,125]\u001b[0m Trial 537 finished with value: 0.5967819790828641 and parameters: {'min_child_weight': 0.3769998662336213, 'subsample': 0.8620212497707666, 'max_depth': 9, 'reg_lambda': 6.3531300799247505, 'reg_alpha': 0.3442691723670798, 'num_leaves': 2, 'colsample_bytree': 0.7566230382042948, 'learning_rate': 0.005818224811882103}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:39:48,148]\u001b[0m Trial 538 finished with value: 0.6680611423974256 and parameters: {'min_child_weight': 0.07147495484819998, 'subsample': 0.9900807700539743, 'max_depth': 13, 'reg_lambda': 7.866884977874465, 'reg_alpha': 0.09438163297670593, 'num_leaves': 16, 'colsample_bytree': 0.6998329467822464, 'learning_rate': 0.21489115735128153}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:39:53,089]\u001b[0m Trial 539 finished with value: 0.6857602574416733 and parameters: {'min_child_weight': 0.35322841275010103, 'subsample': 0.8865094394454113, 'max_depth': 21, 'reg_lambda': 8.63603295453461, 'reg_alpha': 0.21957615030652863, 'num_leaves': 11, 'colsample_bytree': 0.7223455777465776, 'learning_rate': 0.15031088535622394}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:39:54,982]\u001b[0m Trial 540 finished with value: 0.6767497988736927 and parameters: {'min_child_weight': 0.5059357740720707, 'subsample': 0.7144209828660627, 'max_depth': 12, 'reg_lambda': 6.664349856120431, 'reg_alpha': 0.09982670497491272, 'num_leaves': 2, 'colsample_bytree': 0.7336834462809178, 'learning_rate': 0.15098975622601787}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:40:02,983]\u001b[0m Trial 541 finished with value: 0.6783588093322607 and parameters: {'min_child_weight': 0.12523498716171072, 'subsample': 0.6450004092326899, 'max_depth': 11, 'reg_lambda': 5.174183599498973, 'reg_alpha': 0.37780866524272855, 'num_leaves': 26, 'colsample_bytree': 0.699277145980165, 'learning_rate': 0.17653092732641207}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:40:13,026]\u001b[0m Trial 542 finished with value: 0.6722445695897024 and parameters: {'min_child_weight': 0.8083977373978353, 'subsample': 0.6855053521647733, 'max_depth': 12, 'reg_lambda': 5.503323315133079, 'reg_alpha': 2.8025151191987545, 'num_leaves': 88, 'colsample_bytree': 0.7149820618652607, 'learning_rate': 0.12649385093339446}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:40:19,467]\u001b[0m Trial 543 finished with value: 0.6746580852775542 and parameters: {'min_child_weight': 0.7500192162185083, 'subsample': 0.6379567360129192, 'max_depth': 13, 'reg_lambda': 4.42514764040809, 'reg_alpha': 0.4516806737233291, 'num_leaves': 18, 'colsample_bytree': 0.6731475048632587, 'learning_rate': 0.09404504556243304}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:40:24,593]\u001b[0m Trial 544 finished with value: 0.6809332260659695 and parameters: {'min_child_weight': 0.824726324097414, 'subsample': 0.6983713623075324, 'max_depth': 11, 'reg_lambda': 5.926756425092567, 'reg_alpha': 0.7831751532312183, 'num_leaves': 11, 'colsample_bytree': 0.7433122644595026, 'learning_rate': 0.17005675294547873}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:40:33,250]\u001b[0m Trial 545 finished with value: 0.6704746580852776 and parameters: {'min_child_weight': 0.9062759922618281, 'subsample': 0.7315937946243676, 'max_depth': 9, 'reg_lambda': 6.901309072879806, 'reg_alpha': 0.5372731838475753, 'num_leaves': 33, 'colsample_bytree': 0.7885162961840271, 'learning_rate': 0.4134678818237527}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:40:38,368]\u001b[0m Trial 546 finished with value: 0.6675784392598552 and parameters: {'min_child_weight': 0.7772893601820368, 'subsample': 0.611172668224714, 'max_depth': 9, 'reg_lambda': 8.332941792232514, 'reg_alpha': 0.45719371574122136, 'num_leaves': 10, 'colsample_bytree': 0.8286135677669739, 'learning_rate': 0.29053252015556746}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:40:49,612]\u001b[0m Trial 547 finished with value: 0.6714400643604184 and parameters: {'min_child_weight': 0.8753248657848877, 'subsample': 0.8961525384745951, 'max_depth': 12, 'reg_lambda': 6.73312519208075, 'reg_alpha': 1.0941184114718743, 'num_leaves': 330, 'colsample_bytree': 0.7733062847787532, 'learning_rate': 0.2648554249049758}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:40:56,064]\u001b[0m Trial 548 finished with value: 0.678841512469831 and parameters: {'min_child_weight': 0.3120271387040863, 'subsample': 0.8688606005232863, 'max_depth': 5, 'reg_lambda': 6.170101721055885, 'reg_alpha': 0.6918882034347813, 'num_leaves': 17, 'colsample_bytree': 0.8902850022718518, 'learning_rate': 0.11260424542068696}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:40:57,886]\u001b[0m Trial 549 finished with value: 0.6794851166532582 and parameters: {'min_child_weight': 0.4354409262251445, 'subsample': 0.8802609996022417, 'max_depth': 7, 'reg_lambda': 7.145556627472685, 'reg_alpha': 1.3060632330264985, 'num_leaves': 2, 'colsample_bytree': 0.7267299753676383, 'learning_rate': 0.14364681473057642}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:41:02,000]\u001b[0m Trial 550 finished with value: 0.6757843925985518 and parameters: {'min_child_weight': 0.33938719621987173, 'subsample': 0.854661447107575, 'max_depth': 4, 'reg_lambda': 5.76602608681841, 'reg_alpha': 0.6214313028232729, 'num_leaves': 23, 'colsample_bytree': 0.7069222721299713, 'learning_rate': 0.1920024005905408}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:41:06,838]\u001b[0m Trial 551 finished with value: 0.6683829444891392 and parameters: {'min_child_weight': 0.022587648407683337, 'subsample': 0.6175768062325975, 'max_depth': 10, 'reg_lambda': 4.979202349598159, 'reg_alpha': 2.343433658988411, 'num_leaves': 10, 'colsample_bytree': 0.7823856971112841, 'learning_rate': 0.22829099106321232}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:41:17,648]\u001b[0m Trial 552 finished with value: 0.6773934030571198 and parameters: {'min_child_weight': 0.41089646449203704, 'subsample': 0.6102272641739841, 'max_depth': 10, 'reg_lambda': 8.18429472166233, 'reg_alpha': 1.9960137188642761, 'num_leaves': 194, 'colsample_bytree': 0.7425127830537228, 'learning_rate': 0.1643300068617526}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:41:19,541]\u001b[0m Trial 553 finished with value: 0.6807723250201125 and parameters: {'min_child_weight': 0.8052556907855335, 'subsample': 0.9483484144737608, 'max_depth': 11, 'reg_lambda': 6.385504710464144, 'reg_alpha': 0.542999682803137, 'num_leaves': 2, 'colsample_bytree': 0.8221844749029756, 'learning_rate': 0.3240244968037692}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:41:27,730]\u001b[0m Trial 554 finished with value: 0.6617860016090105 and parameters: {'min_child_weight': 0.8478647154015797, 'subsample': 0.6239059649157895, 'max_depth': 10, 'reg_lambda': 6.16085528864972, 'reg_alpha': 0.7493635487046466, 'num_leaves': 34, 'colsample_bytree': 0.8476448181468756, 'learning_rate': 0.6017807099064805}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:41:34,731]\u001b[0m Trial 555 finished with value: 0.6754625905068383 and parameters: {'min_child_weight': 0.689605713565289, 'subsample': 0.997371197988467, 'max_depth': 6, 'reg_lambda': 4.6192044309196545, 'reg_alpha': 0.2620991935864483, 'num_leaves': 19, 'colsample_bytree': 0.8684094607363777, 'learning_rate': 0.21794515066724915}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:41:39,900]\u001b[0m Trial 556 finished with value: 0.6637168141592921 and parameters: {'min_child_weight': 0.4702051654573032, 'subsample': 0.8058524232501877, 'max_depth': 14, 'reg_lambda': 5.383221457913459, 'reg_alpha': 0.1970877557457711, 'num_leaves': 12, 'colsample_bytree': 0.7512994462801124, 'learning_rate': 0.35780603611176276}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:41:46,685]\u001b[0m Trial 557 finished with value: 0.6666130329847144 and parameters: {'min_child_weight': 0.828849660979233, 'subsample': 0.9748750472823869, 'max_depth': 10, 'reg_lambda': 5.809002789690297, 'reg_alpha': 0.8899548803924039, 'num_leaves': 27, 'colsample_bytree': 0.6884109330952248, 'learning_rate': 0.46550731920228305}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:41:48,566]\u001b[0m Trial 558 finished with value: 0.6807723250201126 and parameters: {'min_child_weight': 0.5922519721603474, 'subsample': 0.6323355857587475, 'max_depth': 10, 'reg_lambda': 5.647128705863244, 'reg_alpha': 0.3552874659301595, 'num_leaves': 2, 'colsample_bytree': 0.7909212463489521, 'learning_rate': 0.25686707739891557}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:41:53,599]\u001b[0m Trial 559 finished with value: 0.6781979082864039 and parameters: {'min_child_weight': 0.3685445570197442, 'subsample': 0.785685634251962, 'max_depth': 28, 'reg_lambda': 6.6750779181915165, 'reg_alpha': 1.554363024678481, 'num_leaves': 12, 'colsample_bytree': 0.7181770991791951, 'learning_rate': 0.20443301892997373}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:41:55,522]\u001b[0m Trial 560 finished with value: 0.6785197103781175 and parameters: {'min_child_weight': 0.1495594141526752, 'subsample': 0.8714392281976848, 'max_depth': 7, 'reg_lambda': 3.9421662746340185, 'reg_alpha': 0.46135490119323863, 'num_leaves': 2, 'colsample_bytree': 0.7368775892483502, 'learning_rate': 0.13059949766765988}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:42:02,460]\u001b[0m Trial 561 finished with value: 0.6727272727272726 and parameters: {'min_child_weight': 0.09853667726544552, 'subsample': 0.8608797836492414, 'max_depth': 8, 'reg_lambda': 6.01894434261695, 'reg_alpha': 0.27408450855312116, 'num_leaves': 18, 'colsample_bytree': 0.7667385757560115, 'learning_rate': 0.015709212753529222}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:42:12,193]\u001b[0m Trial 562 finished with value: 0.6754625905068382 and parameters: {'min_child_weight': 0.29830700251500597, 'subsample': 0.8896621032830829, 'max_depth': 12, 'reg_lambda': 6.502160670981808, 'reg_alpha': 0.07045208063390301, 'num_leaves': 39, 'colsample_bytree': 0.708056218968723, 'learning_rate': 0.1662904201122712}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:42:17,170]\u001b[0m Trial 563 finished with value: 0.6672566371681417 and parameters: {'min_child_weight': 0.855295055663398, 'subsample': 0.7438059518452431, 'max_depth': 9, 'reg_lambda': 6.953661042464069, 'reg_alpha': 0.34520199873533586, 'num_leaves': 11, 'colsample_bytree': 0.7576737440722984, 'learning_rate': 0.29494706570684576}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:42:25,148]\u001b[0m Trial 564 finished with value: 0.6744971842316976 and parameters: {'min_child_weight': 0.39248802792548937, 'subsample': 0.9328609016490753, 'max_depth': 11, 'reg_lambda': 7.394695277604519, 'reg_alpha': 0.0008171263029850794, 'num_leaves': 24, 'colsample_bytree': 0.7540775321859688, 'learning_rate': 0.2382659382736074}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:42:27,012]\u001b[0m Trial 565 finished with value: 0.6798069187449718 and parameters: {'min_child_weight': 0.1308948983759606, 'subsample': 0.844909796692216, 'max_depth': 13, 'reg_lambda': 6.349582633600494, 'reg_alpha': 0.15736604400345153, 'num_leaves': 2, 'colsample_bytree': 0.7344906254264538, 'learning_rate': 0.14773674053956476}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:42:32,331]\u001b[0m Trial 566 finished with value: 0.6759452936444088 and parameters: {'min_child_weight': 0.7666579381018512, 'subsample': 0.6075257658639979, 'max_depth': 9, 'reg_lambda': 8.035966481960331, 'reg_alpha': 0.2908777124694447, 'num_leaves': 11, 'colsample_bytree': 0.7962520100544058, 'learning_rate': 0.20214677771143208}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:42:38,698]\u001b[0m Trial 567 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.7876047588930749, 'subsample': 0.8824552345348972, 'max_depth': 11, 'reg_lambda': 4.814648034653284, 'reg_alpha': 0.37659476358766514, 'num_leaves': 20, 'colsample_bytree': 0.687850373760236, 'learning_rate': 0.000764173577448099}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:42:40,657]\u001b[0m Trial 568 finished with value: 0.6817377312952535 and parameters: {'min_child_weight': 0.7220385789831707, 'subsample': 0.6182509366812132, 'max_depth': 11, 'reg_lambda': 8.79463658147802, 'reg_alpha': 0.5102342019485235, 'num_leaves': 2, 'colsample_bytree': 0.7182560713473278, 'learning_rate': 0.17696722099133852}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:42:49,451]\u001b[0m Trial 569 finished with value: 0.6738535800482703 and parameters: {'min_child_weight': 0.8923720475509398, 'subsample': 0.7771388241284499, 'max_depth': 7, 'reg_lambda': 4.255153363365156, 'reg_alpha': 0.15331420701221718, 'num_leaves': 51, 'colsample_bytree': 0.7745571914448167, 'learning_rate': 0.37177671994902456}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:42:58,150]\u001b[0m Trial 570 finished with value: 0.6519710378117458 and parameters: {'min_child_weight': 0.07461318548257076, 'subsample': 0.9836515384193794, 'max_depth': 8, 'reg_lambda': 5.255724506756417, 'reg_alpha': 0.1938644634688605, 'num_leaves': 70, 'colsample_bytree': 0.7639310658193955, 'learning_rate': 0.957812568055582}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:43:03,922]\u001b[0m Trial 571 finished with value: 0.6712791633145615 and parameters: {'min_child_weight': 0.8145996152295422, 'subsample': 0.6003766885363182, 'max_depth': 12, 'reg_lambda': 5.958675110771862, 'reg_alpha': 0.6375721328902346, 'num_leaves': 12, 'colsample_bytree': 0.8593160479697334, 'learning_rate': 0.2853969505005474}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:43:13,867]\u001b[0m Trial 572 finished with value: 0.6738535800482703 and parameters: {'min_child_weight': 0.05142303885971805, 'subsample': 0.8161135024739542, 'max_depth': 15, 'reg_lambda': 5.481848403753355, 'reg_alpha': 0.428201159517959, 'num_leaves': 28, 'colsample_bytree': 0.8932239425516849, 'learning_rate': 0.2321496663902051}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:43:18,955]\u001b[0m Trial 573 finished with value: 0.6714400643604184 and parameters: {'min_child_weight': 0.7606397338492754, 'subsample': 0.796515797253941, 'max_depth': 6, 'reg_lambda': 5.578172396938301, 'reg_alpha': 0.08734815612265251, 'num_leaves': 11, 'colsample_bytree': 0.7470864700111896, 'learning_rate': 0.19654978070343404}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:43:20,760]\u001b[0m Trial 574 finished with value: 0.6746580852775543 and parameters: {'min_child_weight': 0.35448468347452433, 'subsample': 0.6146129944598389, 'max_depth': 10, 'reg_lambda': 8.417680550645068, 'reg_alpha': 0.5561813922067995, 'num_leaves': 2, 'colsample_bytree': 0.7203251436290693, 'learning_rate': 0.11239705929872744}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:43:27,579]\u001b[0m Trial 575 finished with value: 0.6691874497184231 and parameters: {'min_child_weight': 0.09845811446670198, 'subsample': 0.6668578021163, 'max_depth': 14, 'reg_lambda': 7.238135509662785, 'reg_alpha': 0.3146753047708404, 'num_leaves': 20, 'colsample_bytree': 0.6995768632305909, 'learning_rate': 0.009904333648057609}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:43:32,418]\u001b[0m Trial 576 finished with value: 0.6764279967819791 and parameters: {'min_child_weight': 0.16764557813857417, 'subsample': 0.9102728267881826, 'max_depth': 7, 'reg_lambda': 6.826168104391724, 'reg_alpha': 0.1865376981409956, 'num_leaves': 11, 'colsample_bytree': 0.6715816126671545, 'learning_rate': 0.1540017639241263}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:43:42,018]\u001b[0m Trial 577 finished with value: 0.6756234915526951 and parameters: {'min_child_weight': 0.32884524122695524, 'subsample': 0.6274915287970319, 'max_depth': 9, 'reg_lambda': 6.124637632345999, 'reg_alpha': 0.7950065382165608, 'num_leaves': 37, 'colsample_bytree': 0.8033567122063894, 'learning_rate': 0.24647468953066914}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:43:49,360]\u001b[0m Trial 578 finished with value: 0.6661303298471439 and parameters: {'min_child_weight': 0.8827165151612434, 'subsample': 0.9572765989346976, 'max_depth': 25, 'reg_lambda': 8.630577848216854, 'reg_alpha': 0.6557294265556001, 'num_leaves': 19, 'colsample_bytree': 0.8309904123916083, 'learning_rate': 0.32230926140710714}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:44:02,308]\u001b[0m Trial 579 finished with value: 0.6744971842316975 and parameters: {'min_child_weight': 0.5459244079758434, 'subsample': 0.9699210637737308, 'max_depth': 13, 'reg_lambda': 6.5801259399606415, 'reg_alpha': 0.002307441741096261, 'num_leaves': 109, 'colsample_bytree': 0.7775067012360644, 'learning_rate': 0.27115211896216584}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:44:07,652]\u001b[0m Trial 580 finished with value: 0.6785197103781175 and parameters: {'min_child_weight': 0.2315621367655164, 'subsample': 0.920731418101083, 'max_depth': 8, 'reg_lambda': 7.709102496479986, 'reg_alpha': 0.3946693183497659, 'num_leaves': 10, 'colsample_bytree': 0.8411496712717631, 'learning_rate': 0.19806803817388793}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:44:09,532]\u001b[0m Trial 581 finished with value: 0.6798069187449719 and parameters: {'min_child_weight': 0.4571936012844488, 'subsample': 0.6552056080541336, 'max_depth': 12, 'reg_lambda': 6.854390174510781, 'reg_alpha': 0.23722533373786658, 'num_leaves': 2, 'colsample_bytree': 0.8177151164955329, 'learning_rate': 0.2186105333512017}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:44:17,852]\u001b[0m Trial 582 finished with value: 0.6765888978278358 and parameters: {'min_child_weight': 0.7756247278375829, 'subsample': 0.8740141058986739, 'max_depth': 10, 'reg_lambda': 5.796040600293153, 'reg_alpha': 0.4813340630790256, 'num_leaves': 28, 'colsample_bytree': 0.7284377778934166, 'learning_rate': 0.13781845264453732}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:44:23,326]\u001b[0m Trial 583 finished with value: 0.6822204344328238 and parameters: {'min_child_weight': 0.4082611247800013, 'subsample': 0.8317052804860112, 'max_depth': 6, 'reg_lambda': 7.062858912516584, 'reg_alpha': 3.9354479992012084, 'num_leaves': 18, 'colsample_bytree': 0.7342449039253197, 'learning_rate': 0.16786636924312323}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:44:25,131]\u001b[0m Trial 584 finished with value: 0.6802896218825423 and parameters: {'min_child_weight': 0.00016165403840425613, 'subsample': 0.8977929093558062, 'max_depth': 5, 'reg_lambda': 8.297797344346051, 'reg_alpha': 0.11072295306240262, 'num_leaves': 2, 'colsample_bytree': 0.6927548134053153, 'learning_rate': 0.12714900603340404}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:44:32,268]\u001b[0m Trial 585 finished with value: 0.6592115848753017 and parameters: {'min_child_weight': 0.8400427584181099, 'subsample': 0.6048770898119825, 'max_depth': 11, 'reg_lambda': 3.356639247467324, 'reg_alpha': 0.5798093255918799, 'num_leaves': 18, 'colsample_bytree': 0.8727155041373619, 'learning_rate': 0.3528990777469433}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:44:44,043]\u001b[0m Trial 586 finished with value: 0.6733708769107 and parameters: {'min_child_weight': 0.3790161282263601, 'subsample': 0.8529104128926257, 'max_depth': 14, 'reg_lambda': 6.56467703672347, 'reg_alpha': 0.2607187824282288, 'num_leaves': 482, 'colsample_bytree': 0.5970317603647415, 'learning_rate': 0.1748026485519759}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:44:49,347]\u001b[0m Trial 587 finished with value: 0.682059533386967 and parameters: {'min_child_weight': 0.430231409436869, 'subsample': 0.7912149562940427, 'max_depth': 13, 'reg_lambda': 6.257964300541325, 'reg_alpha': 0.0871297189021116, 'num_leaves': 11, 'colsample_bytree': 0.7476071013120605, 'learning_rate': 0.14798877572459668}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:44:57,065]\u001b[0m Trial 588 finished with value: 0.6790024135156879 and parameters: {'min_child_weight': 0.11666915832071859, 'subsample': 0.8687125782027022, 'max_depth': 8, 'reg_lambda': 5.048126197699962, 'reg_alpha': 0.9614210268875787, 'num_leaves': 26, 'colsample_bytree': 0.7090439399394108, 'learning_rate': 0.0814902015621927}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:44:58,929]\u001b[0m Trial 589 finished with value: 0.6801287208366855 and parameters: {'min_child_weight': 0.736534620124953, 'subsample': 0.805262124101709, 'max_depth': 9, 'reg_lambda': 5.329408935452098, 'reg_alpha': 0.4076161123916827, 'num_leaves': 2, 'colsample_bytree': 0.7220726855765299, 'learning_rate': 0.19008957430317514}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:45:04,109]\u001b[0m Trial 590 finished with value: 0.6793242156074014 and parameters: {'min_child_weight': 0.05822767568162528, 'subsample': 0.8612083143881801, 'max_depth': 7, 'reg_lambda': 6.777212179649638, 'reg_alpha': 0.23307205695475547, 'num_leaves': 11, 'colsample_bytree': 0.7456535149257937, 'learning_rate': 0.11918139955292924}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:45:05,900]\u001b[0m Trial 591 finished with value: 0.6790024135156878 and parameters: {'min_child_weight': 0.04018375169872102, 'subsample': 0.8865396408954794, 'max_depth': 9, 'reg_lambda': 3.7051802492385186, 'reg_alpha': 0.253751257844877, 'num_leaves': 2, 'colsample_bytree': 0.6973901464742464, 'learning_rate': 0.1782042545923749}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:45:19,639]\u001b[0m Trial 592 finished with value: 0.6802896218825423 and parameters: {'min_child_weight': 0.26456623663225304, 'subsample': 0.6840145102727931, 'max_depth': 12, 'reg_lambda': 7.020531298230993, 'reg_alpha': 0.13825800103577005, 'num_leaves': 180, 'colsample_bytree': 0.7281389515216254, 'learning_rate': 0.10002727504200458}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:45:25,896]\u001b[0m Trial 593 finished with value: 0.6757843925985518 and parameters: {'min_child_weight': 0.800102812290803, 'subsample': 0.8795474461626475, 'max_depth': 11, 'reg_lambda': 8.03632281012203, 'reg_alpha': 0.0012510880375285471, 'num_leaves': 19, 'colsample_bytree': 0.6429244114548812, 'learning_rate': 0.14906335868615142}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:45:39,963]\u001b[0m Trial 594 finished with value: 0.6712791633145616 and parameters: {'min_child_weight': 0.7553662822760104, 'subsample': 0.7086047884878204, 'max_depth': 15, 'reg_lambda': 5.670021345394082, 'reg_alpha': 0.362819315997144, 'num_leaves': 424, 'colsample_bytree': 0.8602332534877128, 'learning_rate': 0.2411437098963356}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:45:49,173]\u001b[0m Trial 595 finished with value: 0.6690265486725664 and parameters: {'min_child_weight': 0.8265689337607474, 'subsample': 0.6128370637456365, 'max_depth': 10, 'reg_lambda': 5.890725808197005, 'reg_alpha': 0.688222510791397, 'num_leaves': 41, 'colsample_bytree': 0.8049306275269114, 'learning_rate': 0.4176615000513462}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:45:58,844]\u001b[0m Trial 596 finished with value: 0.674979887369268 and parameters: {'min_child_weight': 0.7877642818426889, 'subsample': 0.6393948143156895, 'max_depth': 8, 'reg_lambda': 4.561163624502802, 'reg_alpha': 0.4791992627764884, 'num_leaves': 28, 'colsample_bytree': 0.9668107758482871, 'learning_rate': 0.28749274601731334}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:46:04,171]\u001b[0m Trial 597 finished with value: 0.6736926790024136 and parameters: {'min_child_weight': 0.06614420097970833, 'subsample': 0.6226457048239905, 'max_depth': 9, 'reg_lambda': 7.818384112661694, 'reg_alpha': 0.29550637901461313, 'num_leaves': 11, 'colsample_bytree': 0.78951741125571, 'learning_rate': 0.23114731744591666}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:46:09,080]\u001b[0m Trial 598 finished with value: 0.6707964601769911 and parameters: {'min_child_weight': 0.14222848795744306, 'subsample': 0.7521410839606348, 'max_depth': 5, 'reg_lambda': 8.160361423042984, 'reg_alpha': 0.15603907856737156, 'num_leaves': 11, 'colsample_bytree': 0.8131853968365872, 'learning_rate': 0.21489853128645559}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:46:11,121]\u001b[0m Trial 599 finished with value: 0.6827031375703942 and parameters: {'min_child_weight': 0.863979700345162, 'subsample': 0.6062361827064783, 'max_depth': 11, 'reg_lambda': 6.429319119548747, 'reg_alpha': 0.5212678879918322, 'num_leaves': 2, 'colsample_bytree': 0.8454260806603847, 'learning_rate': 0.3120916945289557}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:46:17,312]\u001b[0m Trial 600 finished with value: 0.6698310539018505 and parameters: {'min_child_weight': 0.3611202014413905, 'subsample': 0.9614626798718513, 'max_depth': 12, 'reg_lambda': 6.281350207246363, 'reg_alpha': 0.7865350193366445, 'num_leaves': 19, 'colsample_bytree': 0.6591769641190678, 'learning_rate': 0.2453250545404303}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:46:19,082]\u001b[0m Trial 601 finished with value: 0.6817377312952534 and parameters: {'min_child_weight': 0.48433471157154556, 'subsample': 0.8763907764993993, 'max_depth': 6, 'reg_lambda': 4.06934230440794, 'reg_alpha': 0.6131838347128296, 'num_leaves': 2, 'colsample_bytree': 0.7107651254293837, 'learning_rate': 0.18330055909606222}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:46:27,696]\u001b[0m Trial 602 finished with value: 0.6595333869670152 and parameters: {'min_child_weight': 0.8069070065107491, 'subsample': 0.9895005800886556, 'max_depth': 10, 'reg_lambda': 4.880969065521456, 'reg_alpha': 0.4032606103558957, 'num_leaves': 31, 'colsample_bytree': 0.8252677788693108, 'learning_rate': 0.5120751000207059}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:46:33,100]\u001b[0m Trial 603 finished with value: 0.6719227674979888 and parameters: {'min_child_weight': 0.8540034668588866, 'subsample': 0.9807666304721171, 'max_depth': 7, 'reg_lambda': 7.310753987783701, 'reg_alpha': 0.17793386577250517, 'num_leaves': 12, 'colsample_bytree': 0.764014985723143, 'learning_rate': 0.2649783509155686}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:46:45,744]\u001b[0m Trial 604 finished with value: 0.6810941271118263 and parameters: {'min_child_weight': 0.3379057640874162, 'subsample': 0.8929026304675755, 'max_depth': 11, 'reg_lambda': 8.481240953034703, 'reg_alpha': 0.3340549965121028, 'num_leaves': 214, 'colsample_bytree': 0.7022448312187585, 'learning_rate': 0.15806775334790227}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:46:53,457]\u001b[0m Trial 605 finished with value: 0.6814159292035399 and parameters: {'min_child_weight': 0.020665337751527214, 'subsample': 0.7753559509919705, 'max_depth': 8, 'reg_lambda': 7.608450421866736, 'reg_alpha': 1.7830901362981173, 'num_leaves': 20, 'colsample_bytree': 0.9128148958020768, 'learning_rate': 0.20533876270152945}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:46:58,595]\u001b[0m Trial 606 finished with value: 0.6635559131134353 and parameters: {'min_child_weight': 0.8464639591463665, 'subsample': 0.6009083688783687, 'max_depth': 9, 'reg_lambda': 6.038332311446943, 'reg_alpha': 0.4144910709790417, 'num_leaves': 11, 'colsample_bytree': 0.7956136250539007, 'learning_rate': 0.3747949347220897}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:47:07,996]\u001b[0m Trial 607 finished with value: 0.6772325020112631 and parameters: {'min_child_weight': 0.8253470681287541, 'subsample': 0.6145889704077238, 'max_depth': 10, 'reg_lambda': 5.166097772046072, 'reg_alpha': 0.28929342742753794, 'num_leaves': 27, 'colsample_bytree': 0.8845716632464367, 'learning_rate': 0.29796568094084824}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:47:09,994]\u001b[0m Trial 608 finished with value: 0.681255028157683 and parameters: {'min_child_weight': 0.09941597051015312, 'subsample': 0.8000584284715967, 'max_depth': 23, 'reg_lambda': 5.466043604983501, 'reg_alpha': 0.1048404275026283, 'num_leaves': 2, 'colsample_bytree': 0.7813568629575024, 'learning_rate': 0.20790491566779234}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:47:22,913]\u001b[0m Trial 609 finished with value: 0.6781979082864039 and parameters: {'min_child_weight': 0.6157996332219485, 'subsample': 0.6296608878365504, 'max_depth': 10, 'reg_lambda': 5.741036619925174, 'reg_alpha': 0.5262202840497359, 'num_leaves': 156, 'colsample_bytree': 0.7466699268988369, 'learning_rate': 0.12995084614277008}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:47:35,986]\u001b[0m Trial 610 finished with value: 0.6714400643604184 and parameters: {'min_child_weight': 0.30481161231483106, 'subsample': 0.6725596411816436, 'max_depth': 11, 'reg_lambda': 6.015867655835548, 'reg_alpha': 0.47089233186457236, 'num_leaves': 402, 'colsample_bytree': 0.7682191767868793, 'learning_rate': 0.24557855955144384}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:47:40,966]\u001b[0m Trial 611 finished with value: 0.6762670957361222 and parameters: {'min_child_weight': 0.3955110025090242, 'subsample': 0.6484758855410203, 'max_depth': 10, 'reg_lambda': 8.329242898067095, 'reg_alpha': 0.7033237723364875, 'num_leaves': 12, 'colsample_bytree': 0.6769417500977156, 'learning_rate': 0.1668842820551588}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:47:48,150]\u001b[0m Trial 612 finished with value: 0.6807723250201126 and parameters: {'min_child_weight': 0.7207112649215783, 'subsample': 0.6184744461047078, 'max_depth': 11, 'reg_lambda': 4.385194716148615, 'reg_alpha': 0.5921370112081519, 'num_leaves': 20, 'colsample_bytree': 0.727332884010257, 'learning_rate': 0.13324082238269655}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:47:50,119]\u001b[0m Trial 613 finished with value: 0.6809332260659694 and parameters: {'min_child_weight': 0.4486732796372111, 'subsample': 0.6088521337659004, 'max_depth': 11, 'reg_lambda': 6.147571705208989, 'reg_alpha': 0.3682246623087655, 'num_leaves': 2, 'colsample_bytree': 0.7405822215022942, 'learning_rate': 0.18362881682094961}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:47:54,539]\u001b[0m Trial 614 finished with value: 0.6675784392598552 and parameters: {'min_child_weight': 0.8825696207142196, 'subsample': 0.821176560752061, 'max_depth': 4, 'reg_lambda': 5.045710351880485, 'reg_alpha': 0.19767437361198414, 'num_leaves': 40, 'colsample_bytree': 0.7651440060737195, 'learning_rate': 0.31323089647845215}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:48:00,163]\u001b[0m Trial 615 finished with value: 0.6783588093322607 and parameters: {'min_child_weight': 0.07976215154161576, 'subsample': 0.7893180279041441, 'max_depth': 13, 'reg_lambda': 6.617869441673592, 'reg_alpha': 0.09724384985731604, 'num_leaves': 13, 'colsample_bytree': 0.727023309456038, 'learning_rate': 0.10148759192438828}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:48:01,983]\u001b[0m Trial 616 finished with value: 0.6807723250201125 and parameters: {'min_child_weight': 0.3802496390739415, 'subsample': 0.8669993685484051, 'max_depth': 13, 'reg_lambda': 6.44503464942594, 'reg_alpha': 0.0644531948512283, 'num_leaves': 2, 'colsample_bytree': 0.7499844143801053, 'learning_rate': 0.15755157243146972}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:48:08,977]\u001b[0m Trial 617 finished with value: 0.6855993563958165 and parameters: {'min_child_weight': 0.4227996287893244, 'subsample': 0.9692256354720544, 'max_depth': 12, 'reg_lambda': 6.2980736450702315, 'reg_alpha': 0.7427304885151527, 'num_leaves': 20, 'colsample_bytree': 0.7123000672395977, 'learning_rate': 0.11764065208142604}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:48:15,060]\u001b[0m Trial 618 finished with value: 0.6761061946902654 and parameters: {'min_child_weight': 0.741423244054498, 'subsample': 0.7365868145114252, 'max_depth': 7, 'reg_lambda': 4.736714610114284, 'reg_alpha': 0.2545779094579536, 'num_leaves': 13, 'colsample_bytree': 0.8389913472519361, 'learning_rate': 0.2185820688432308}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:48:23,826]\u001b[0m Trial 619 finished with value: 0.6669348350764279 and parameters: {'min_child_weight': 0.7731976255907236, 'subsample': 0.7649652235813421, 'max_depth': 9, 'reg_lambda': 7.946004705561745, 'reg_alpha': 0.30506526883739504, 'num_leaves': 29, 'colsample_bytree': 0.7791113409845158, 'learning_rate': 0.28025348274349926}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:48:28,905]\u001b[0m Trial 620 finished with value: 0.680450522928399 and parameters: {'min_child_weight': 0.34771297764652614, 'subsample': 0.8549643546655638, 'max_depth': 14, 'reg_lambda': 7.19567630109981, 'reg_alpha': 0.197788455900951, 'num_leaves': 12, 'colsample_bytree': 0.6853152536317086, 'learning_rate': 0.17897415214271986}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:48:40,137]\u001b[0m Trial 621 finished with value: 0.6756234915526951 and parameters: {'min_child_weight': 0.11574501295041059, 'subsample': 0.8442062394472888, 'max_depth': 8, 'reg_lambda': 5.340777373281449, 'reg_alpha': 0.22728670862152095, 'num_leaves': 125, 'colsample_bytree': 0.7538146991787237, 'learning_rate': 0.19840837635570988}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:48:42,129]\u001b[0m Trial 622 finished with value: 0.6818986323411103 and parameters: {'min_child_weight': 0.7951697154242968, 'subsample': 0.6021794935266183, 'max_depth': 6, 'reg_lambda': 5.625283922348425, 'reg_alpha': 0.44202612399655133, 'num_leaves': 2, 'colsample_bytree': 0.816244691443619, 'learning_rate': 0.4352283817561109}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:48:49,294]\u001b[0m Trial 623 finished with value: 0.6733708769106999 and parameters: {'min_child_weight': 0.31676535163786834, 'subsample': 0.8811452969476177, 'max_depth': 10, 'reg_lambda': 8.148004220811668, 'reg_alpha': 0.5651946750115382, 'num_leaves': 21, 'colsample_bytree': 0.7313222629628421, 'learning_rate': 0.14572773794129112}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:48:54,740]\u001b[0m Trial 624 finished with value: 0.6785197103781174 and parameters: {'min_child_weight': 0.7549249414460675, 'subsample': 0.640303955135983, 'max_depth': 9, 'reg_lambda': 5.858129509298803, 'reg_alpha': 0.8947784847115205, 'num_leaves': 12, 'colsample_bytree': 0.785477604433791, 'learning_rate': 0.24753770481777515}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:48:56,728]\u001b[0m Trial 625 finished with value: 0.6791633145615446 and parameters: {'min_child_weight': 0.09182330607396252, 'subsample': 0.8603936841756868, 'max_depth': 8, 'reg_lambda': 6.111218418262485, 'reg_alpha': 0.34153350730218895, 'num_leaves': 2, 'colsample_bytree': 0.7037553731647812, 'learning_rate': 0.16878666518455637}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:49:05,544]\u001b[0m Trial 626 finished with value: 0.6711182622687047 and parameters: {'min_child_weight': 0.7047128495850128, 'subsample': 0.6003311832208916, 'max_depth': 10, 'reg_lambda': 8.754096100072047, 'reg_alpha': 0.491321108484455, 'num_leaves': 29, 'colsample_bytree': 0.7648375013454357, 'learning_rate': 0.24569440569230971}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:49:10,524]\u001b[0m Trial 627 finished with value: 0.6717618664521321 and parameters: {'min_child_weight': 0.16694422414712823, 'subsample': 0.8711196594668957, 'max_depth': 7, 'reg_lambda': 5.4775784836115, 'reg_alpha': 0.6491665046405415, 'num_leaves': 11, 'colsample_bytree': 0.7353625094138991, 'learning_rate': 0.1966371613625449}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:49:16,030]\u001b[0m Trial 628 finished with value: 0.6815768302493966 and parameters: {'min_child_weight': 0.3651840455882645, 'subsample': 0.9500167451121642, 'max_depth': 5, 'reg_lambda': 6.80852960506159, 'reg_alpha': 0.029660526538325932, 'num_leaves': 19, 'colsample_bytree': 0.7155220175377429, 'learning_rate': 0.13336836293593443}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:49:17,850]\u001b[0m Trial 629 finished with value: 0.6790024135156879 and parameters: {'min_child_weight': 0.40211746360831646, 'subsample': 0.6142767081882936, 'max_depth': 11, 'reg_lambda': 4.200235276801939, 'reg_alpha': 0.46325185982780015, 'num_leaves': 2, 'colsample_bytree': 0.6890540670588894, 'learning_rate': 0.15864339978670614}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:49:27,155]\u001b[0m Trial 630 finished with value: 0.6725663716814159 and parameters: {'min_child_weight': 0.9067737627793739, 'subsample': 0.6956857848866734, 'max_depth': 12, 'reg_lambda': 9.903532089727138, 'reg_alpha': 0.3242484478290385, 'num_leaves': 36, 'colsample_bytree': 0.7978070465387717, 'learning_rate': 0.36971895234295604}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:49:32,735]\u001b[0m Trial 631 finished with value: 0.6659694288012872 and parameters: {'min_child_weight': 0.8130771003061917, 'subsample': 0.980067269596436, 'max_depth': 10, 'reg_lambda': 6.433686566587106, 'reg_alpha': 0.670134531583112, 'num_leaves': 12, 'colsample_bytree': 0.8155409698229094, 'learning_rate': 0.2993686920475965}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:49:40,389]\u001b[0m Trial 632 finished with value: 0.6738535800482703 and parameters: {'min_child_weight': 0.04346569099780468, 'subsample': 0.8346898288512633, 'max_depth': 9, 'reg_lambda': 1.3194641049362206, 'reg_alpha': 0.1607668807671102, 'num_leaves': 23, 'colsample_bytree': 0.7609468239188527, 'learning_rate': 0.22926205304904648}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:49:42,305]\u001b[0m Trial 633 finished with value: 0.6801287208366854 and parameters: {'min_child_weight': 0.2869657410447903, 'subsample': 0.722658406183655, 'max_depth': 29, 'reg_lambda': 8.975137069277398, 'reg_alpha': 0.004994861203465012, 'num_leaves': 2, 'colsample_bytree': 0.7501014799509148, 'learning_rate': 0.19955962760951024}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:49:44,759]\u001b[0m Trial 634 finished with value: 0.6831858407079646 and parameters: {'min_child_weight': 0.32892788165939707, 'subsample': 0.79530756607289, 'max_depth': 6, 'reg_lambda': 7.904178159710866, 'reg_alpha': 0.22782135435636486, 'num_leaves': 11, 'colsample_bytree': 0.2203698391774001, 'learning_rate': 0.17999666973884412}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:49:52,123]\u001b[0m Trial 635 finished with value: 0.6761061946902654 and parameters: {'min_child_weight': 0.7805515264913127, 'subsample': 0.6099751771337278, 'max_depth': 12, 'reg_lambda': 5.939576595223467, 'reg_alpha': 1.0215777311172831, 'num_leaves': 19, 'colsample_bytree': 0.8553289796272052, 'learning_rate': 0.2742065123290949}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:50:03,600]\u001b[0m Trial 636 finished with value: 0.6621078037007241 and parameters: {'min_child_weight': 0.1392710297632723, 'subsample': 0.9079158502553091, 'max_depth': 8, 'reg_lambda': 5.237620074235866, 'reg_alpha': 0.09324208866643016, 'num_leaves': 459, 'colsample_bytree': 0.8698263002296301, 'learning_rate': 0.6334230175285932}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:50:08,613]\u001b[0m Trial 637 finished with value: 0.6759452936444087 and parameters: {'min_child_weight': 0.5303751639112334, 'subsample': 0.8111548677104166, 'max_depth': 18, 'reg_lambda': 8.557563969469593, 'reg_alpha': 0.3017282961742089, 'num_leaves': 11, 'colsample_bytree': 0.7249224584249487, 'learning_rate': 0.13255751447141767}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:50:18,190]\u001b[0m Trial 638 finished with value: 0.6706355591311344 and parameters: {'min_child_weight': 0.829574509509386, 'subsample': 0.6300177261103561, 'max_depth': 14, 'reg_lambda': 5.649896950357725, 'reg_alpha': 0.41966532802576756, 'num_leaves': 31, 'colsample_bytree': 0.8300689206051296, 'learning_rate': 0.3179983020081583}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:50:27,224]\u001b[0m Trial 639 finished with value: 0.680450522928399 and parameters: {'min_child_weight': 0.12038089661002757, 'subsample': 0.8923982647385355, 'max_depth': 7, 'reg_lambda': 6.710323720952987, 'reg_alpha': 0.16797671138504894, 'num_leaves': 366, 'colsample_bytree': 0.7095024226967924, 'learning_rate': 0.10396485754033485}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:50:29,164]\u001b[0m Trial 640 finished with value: 0.670152855993564 and parameters: {'min_child_weight': 0.8407724758773989, 'subsample': 0.9981489353210379, 'max_depth': 11, 'reg_lambda': 3.473981130548271, 'reg_alpha': 0.5645495338249198, 'num_leaves': 2, 'colsample_bytree': 0.8435707057745775, 'learning_rate': 0.06731683909902227}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:50:34,526]\u001b[0m Trial 641 finished with value: 0.6711182622687047 and parameters: {'min_child_weight': 0.19185435144498858, 'subsample': 0.6606810548603823, 'max_depth': 10, 'reg_lambda': 2.9679262003048437, 'reg_alpha': 0.8560734423933233, 'num_leaves': 20, 'colsample_bytree': 0.5237004374807469, 'learning_rate': 0.2306877696450239}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:50:41,295]\u001b[0m Trial 642 finished with value: 0.6661303298471439 and parameters: {'min_child_weight': 0.8712829249870587, 'subsample': 0.7818073408663646, 'max_depth': 24, 'reg_lambda': 5.76121723071822, 'reg_alpha': 3.2102729071380303, 'num_leaves': 441, 'colsample_bytree': 0.7837381767633399, 'learning_rate': 0.4007336515482338}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:50:47,143]\u001b[0m Trial 643 finished with value: 0.6727272727272727 and parameters: {'min_child_weight': 0.7427848943130951, 'subsample': 0.9438616790899026, 'max_depth': 12, 'reg_lambda': 6.670254117692404, 'reg_alpha': 0.5592375412526023, 'num_leaves': 11, 'colsample_bytree': 0.9228701637848981, 'learning_rate': 0.21189600258651137}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:50:48,995]\u001b[0m Trial 644 finished with value: 0.6818986323411103 and parameters: {'min_child_weight': 0.06378845246300587, 'subsample': 0.6178047545924946, 'max_depth': 9, 'reg_lambda': 8.29712829305263, 'reg_alpha': 0.3535941111850344, 'num_leaves': 2, 'colsample_bytree': 0.7687646012306896, 'learning_rate': 0.2480672950188465}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:50:59,267]\u001b[0m Trial 645 finished with value: 0.6698310539018504 and parameters: {'min_child_weight': 0.08416151360531943, 'subsample': 0.6092726725650657, 'max_depth': 9, 'reg_lambda': 3.969705905353548, 'reg_alpha': 0.24964457717041896, 'num_leaves': 45, 'colsample_bytree': 0.7444102543295523, 'learning_rate': 0.20263329537011118}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:51:07,611]\u001b[0m Trial 646 finished with value: 0.6719227674979887 and parameters: {'min_child_weight': 0.5027565292979352, 'subsample': 0.803699048990298, 'max_depth': 8, 'reg_lambda': 4.47163818986824, 'reg_alpha': 0.35793930293720694, 'num_leaves': 26, 'colsample_bytree': 0.7984403695704855, 'learning_rate': 0.2508049760249853}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:51:12,204]\u001b[0m Trial 647 finished with value: 0.6786806114239743 and parameters: {'min_child_weight': 0.4177091148572174, 'subsample': 0.9003971775418811, 'max_depth': 10, 'reg_lambda': 6.214371000355443, 'reg_alpha': 2.6957569349580384, 'num_leaves': 11, 'colsample_bytree': 0.6752262260939534, 'learning_rate': 0.16053895245832261}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:51:14,106]\u001b[0m Trial 648 finished with value: 0.6807723250201125 and parameters: {'min_child_weight': 0.03080169760814936, 'subsample': 0.6253737435821245, 'max_depth': 6, 'reg_lambda': 7.780963171637175, 'reg_alpha': 0.19731595700820176, 'num_leaves': 2, 'colsample_bytree': 0.7560964415978009, 'learning_rate': 0.2072192425994127}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:51:20,722]\u001b[0m Trial 649 finished with value: 0.6781979082864039 and parameters: {'min_child_weight': 0.43846375941153576, 'subsample': 0.8867513746493142, 'max_depth': 13, 'reg_lambda': 4.659631141676696, 'reg_alpha': 0.0710908368510269, 'num_leaves': 18, 'colsample_bytree': 0.6896521859876671, 'learning_rate': 0.11627204672015942}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:51:26,185]\u001b[0m Trial 650 finished with value: 0.6746580852775543 and parameters: {'min_child_weight': 0.3819294156442298, 'subsample': 0.6001754510471593, 'max_depth': 11, 'reg_lambda': 6.347719666502764, 'reg_alpha': 0.4665424054087668, 'num_leaves': 12, 'colsample_bytree': 0.7843177590856666, 'learning_rate': 0.2685084238992793}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:51:33,404]\u001b[0m Trial 651 finished with value: 0.6818986323411103 and parameters: {'min_child_weight': 0.7863846887179032, 'subsample': 0.8640083250788723, 'max_depth': 13, 'reg_lambda': 8.080578919383099, 'reg_alpha': 3.525936082961074, 'num_leaves': 32, 'colsample_bytree': 0.7048723903554808, 'learning_rate': 0.14135411819956514}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:51:41,603]\u001b[0m Trial 652 finished with value: 0.6773934030571199 and parameters: {'min_child_weight': 0.8610882698262639, 'subsample': 0.9745750031870684, 'max_depth': 11, 'reg_lambda': 6.557582581550863, 'reg_alpha': 0.6939994464111628, 'num_leaves': 21, 'colsample_bytree': 0.8939194061683342, 'learning_rate': 0.33375794175700907}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:51:43,516]\u001b[0m Trial 653 finished with value: 0.6818986323411103 and parameters: {'min_child_weight': 0.8056108349809431, 'subsample': 0.7894674680528824, 'max_depth': 7, 'reg_lambda': 5.464797854116019, 'reg_alpha': 0.11514076270045748, 'num_leaves': 2, 'colsample_bytree': 0.8746688827048342, 'learning_rate': 0.17559212731566706}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:51:47,721]\u001b[0m Trial 654 finished with value: 0.6794851166532583 and parameters: {'min_child_weight': 0.46976782168927794, 'subsample': 0.8766658509882203, 'max_depth': 5, 'reg_lambda': 8.369074326048585, 'reg_alpha': 0.3762798928848095, 'num_leaves': 10, 'colsample_bytree': 0.6627674412282822, 'learning_rate': 0.15692093147912992}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:51:55,225]\u001b[0m Trial 655 finished with value: 0.6698310539018504 and parameters: {'min_child_weight': 0.8565063146390117, 'subsample': 0.6790401296462041, 'max_depth': 12, 'reg_lambda': 5.856038013672293, 'reg_alpha': 0.8128169265915064, 'num_leaves': 21, 'colsample_bytree': 0.8299733084487472, 'learning_rate': 0.32754220917457066}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:52:00,192]\u001b[0m Trial 656 finished with value: 0.6680611423974255 and parameters: {'min_child_weight': 0.8370287490900366, 'subsample': 0.9565050468311088, 'max_depth': 8, 'reg_lambda': 7.03436544551634, 'reg_alpha': 0.1618326542134582, 'num_leaves': 11, 'colsample_bytree': 0.7425748773184111, 'learning_rate': 0.2697942629877188}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:52:02,042]\u001b[0m Trial 657 finished with value: 0.6783588093322607 and parameters: {'min_child_weight': 0.7704611208092661, 'subsample': 0.6210104029760904, 'max_depth': 10, 'reg_lambda': 4.920336467115398, 'reg_alpha': 0.5637532156585595, 'num_leaves': 2, 'colsample_bytree': 0.7191349507979666, 'learning_rate': 0.1830452496449408}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:52:09,311]\u001b[0m Trial 658 finished with value: 0.6674175382139984 and parameters: {'min_child_weight': 0.24594677373780705, 'subsample': 0.7036456092269319, 'max_depth': 12, 'reg_lambda': 7.579464362881147, 'reg_alpha': 1.2346694654209096, 'num_leaves': 26, 'colsample_bytree': 0.7331907360773271, 'learning_rate': 0.35674085818249024}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:52:15,080]\u001b[0m Trial 659 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.8125078952574754, 'subsample': 0.9888394924776991, 'max_depth': 11, 'reg_lambda': 6.023033403549311, 'reg_alpha': 0.6276866009961731, 'num_leaves': 13, 'colsample_bytree': 0.8105919411965713, 'learning_rate': 0.000509540800234962}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:52:26,520]\u001b[0m Trial 660 finished with value: 0.6867256637168141 and parameters: {'min_child_weight': 0.33861492338257, 'subsample': 0.8702231787398603, 'max_depth': 15, 'reg_lambda': 8.174351294751329, 'reg_alpha': 0.2836142127474517, 'num_leaves': 39, 'colsample_bytree': 0.8596869239748357, 'learning_rate': 0.08890549117177943}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:52:31,492]\u001b[0m Trial 661 finished with value: 0.637489943684634 and parameters: {'min_child_weight': 0.36201657719703323, 'subsample': 0.8794173592739918, 'max_depth': 14, 'reg_lambda': 6.76210638606318, 'reg_alpha': 0.006740267220523274, 'num_leaves': 11, 'colsample_bytree': 0.7259355154093016, 'learning_rate': 0.004619897639697314}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:52:33,321]\u001b[0m Trial 662 finished with value: 0.6798069187449718 and parameters: {'min_child_weight': 0.072709841399144, 'subsample': 0.8491250659997577, 'max_depth': 19, 'reg_lambda': 7.062202362019145, 'reg_alpha': 0.16790872646930452, 'num_leaves': 2, 'colsample_bytree': 0.7073095647284355, 'learning_rate': 0.1408469981583857}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:52:40,425]\u001b[0m Trial 663 finished with value: 0.679646017699115 and parameters: {'min_child_weight': 0.8730581766423443, 'subsample': 0.9294487903121639, 'max_depth': 22, 'reg_lambda': 5.115918422144928, 'reg_alpha': 0.2970357300465779, 'num_leaves': 19, 'colsample_bytree': 0.7376085713377847, 'learning_rate': 0.11451877407134005}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:52:49,014]\u001b[0m Trial 664 finished with value: 0.6769106999195496 and parameters: {'min_child_weight': 0.8912463287532635, 'subsample': 0.6079868394644923, 'max_depth': 9, 'reg_lambda': 6.941982385928363, 'reg_alpha': 0.40397830006126006, 'num_leaves': 27, 'colsample_bytree': 0.8037301037124063, 'learning_rate': 0.28591694074533747}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:52:54,606]\u001b[0m Trial 665 finished with value: 0.6770716009654063 and parameters: {'min_child_weight': 0.7948926974856847, 'subsample': 0.6147226528918297, 'max_depth': 10, 'reg_lambda': 6.261070915606742, 'reg_alpha': 0.5162770477343015, 'num_leaves': 10, 'colsample_bytree': 0.9467239444508089, 'learning_rate': 0.20788218641262754}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:52:56,395]\u001b[0m Trial 666 finished with value: 0.6777152051488334 and parameters: {'min_child_weight': 0.09907623479643957, 'subsample': 0.8598430561157328, 'max_depth': 13, 'reg_lambda': 6.52693154485403, 'reg_alpha': 0.08810406934733123, 'num_leaves': 2, 'colsample_bytree': 0.6853498027932647, 'learning_rate': 0.17274207288675733}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:53:03,301]\u001b[0m Trial 667 finished with value: 0.6791633145615447 and parameters: {'min_child_weight': 0.8324274475197188, 'subsample': 0.9650674478868541, 'max_depth': 12, 'reg_lambda': 5.583584067165976, 'reg_alpha': 0.003919109530976239, 'num_leaves': 18, 'colsample_bytree': 0.752263285819411, 'learning_rate': 0.13478763024618043}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:53:08,495]\u001b[0m Trial 668 finished with value: 0.6738535800482703 and parameters: {'min_child_weight': 0.7524228012088978, 'subsample': 0.8714490294018814, 'max_depth': 11, 'reg_lambda': 5.29141337011189, 'reg_alpha': 0.4337987941454169, 'num_leaves': 12, 'colsample_bytree': 0.7182750700462135, 'learning_rate': 0.1907574271095088}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:53:10,360]\u001b[0m Trial 669 finished with value: 0.681255028157683 and parameters: {'min_child_weight': 0.3101159317237847, 'subsample': 0.6897360796901545, 'max_depth': 9, 'reg_lambda': 7.416633837775707, 'reg_alpha': 0.27278114838323203, 'num_leaves': 2, 'colsample_bytree': 0.7710055551887178, 'learning_rate': 0.234962953374781}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:53:21,479]\u001b[0m Trial 670 finished with value: 0.6728881737731295 and parameters: {'min_child_weight': 0.39952218373666354, 'subsample': 0.6000659829805985, 'max_depth': 9, 'reg_lambda': 6.082558183793466, 'reg_alpha': 0.7374188345817337, 'num_leaves': 59, 'colsample_bytree': 0.7856439189492648, 'learning_rate': 0.21373344679084472}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:53:29,969]\u001b[0m Trial 671 finished with value: 0.6693483507642799 and parameters: {'min_child_weight': 0.05050048032551553, 'subsample': 0.7701615214394262, 'max_depth': 7, 'reg_lambda': 5.765737523087472, 'reg_alpha': 0.22381120416661862, 'num_leaves': 35, 'colsample_bytree': 0.7653840742761876, 'learning_rate': 0.2832235150724374}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:53:36,195]\u001b[0m Trial 672 finished with value: 0.6550281576830248 and parameters: {'min_child_weight': 0.01626607404648854, 'subsample': 0.7568352773970842, 'max_depth': 6, 'reg_lambda': 3.7717891444282237, 'reg_alpha': 0.12302160301522841, 'num_leaves': 19, 'colsample_bytree': 0.750612820486245, 'learning_rate': 0.46341265225417355}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:53:41,490]\u001b[0m Trial 673 finished with value: 0.6603378921962993 and parameters: {'min_child_weight': 0.814737310095639, 'subsample': 0.6212844653852184, 'max_depth': 8, 'reg_lambda': 7.94003951547934, 'reg_alpha': 0.3931941371562337, 'num_leaves': 11, 'colsample_bytree': 0.8226177665417017, 'learning_rate': 0.3966774125491562}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:53:43,370]\u001b[0m Trial 674 finished with value: 0.678841512469831 and parameters: {'min_child_weight': 0.15091162091881516, 'subsample': 0.8841245694771803, 'max_depth': 4, 'reg_lambda': 6.343495096601488, 'reg_alpha': 0.25901685251533574, 'num_leaves': 2, 'colsample_bytree': 0.7350681260569463, 'learning_rate': 0.165815251087662}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:53:51,871]\u001b[0m Trial 675 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.11702888124416065, 'subsample': 0.8091566517522848, 'max_depth': 28, 'reg_lambda': 4.312958485726145, 'reg_alpha': 0.4825973720198349, 'num_leaves': 25, 'colsample_bytree': 0.8494009166046649, 'learning_rate': 0.0012380633448429666}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:53:55,771]\u001b[0m Trial 676 finished with value: 0.6822204344328238 and parameters: {'min_child_weight': 0.7204469736930206, 'subsample': 0.7972097480198876, 'max_depth': 7, 'reg_lambda': 6.890935232758286, 'reg_alpha': 0.11612895761735587, 'num_leaves': 13, 'colsample_bytree': 0.43901251507086114, 'learning_rate': 0.15079506996404218}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:53:57,760]\u001b[0m Trial 677 finished with value: 0.680450522928399 and parameters: {'min_child_weight': 0.4531954397904282, 'subsample': 0.8264192049103347, 'max_depth': 27, 'reg_lambda': 7.23081728868165, 'reg_alpha': 0.18853538292409452, 'num_leaves': 2, 'colsample_bytree': 0.9768460380408491, 'learning_rate': 0.18522708993205114}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:54:02,674]\u001b[0m Trial 678 finished with value: 0.6801287208366855 and parameters: {'min_child_weight': 0.38695446133274436, 'subsample': 0.6396239169314878, 'max_depth': 13, 'reg_lambda': 8.562137214304377, 'reg_alpha': 0.33592895434266923, 'num_leaves': 27, 'colsample_bytree': 0.35940890083795723, 'learning_rate': 0.12011969327431384}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:54:09,349]\u001b[0m Trial 679 finished with value: 0.6743362831858407 and parameters: {'min_child_weight': 0.8457046099724425, 'subsample': 0.6082293884881292, 'max_depth': 10, 'reg_lambda': 5.112502717486417, 'reg_alpha': 2.561695409160902, 'num_leaves': 18, 'colsample_bytree': 0.9061875071856811, 'learning_rate': 0.24661243589714685}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:54:14,452]\u001b[0m Trial 680 finished with value: 0.6767497988736926 and parameters: {'min_child_weight': 0.8240380195405158, 'subsample': 0.8191593608245139, 'max_depth': 16, 'reg_lambda': 5.601135290686527, 'reg_alpha': 0.23602360414863888, 'num_leaves': 11, 'colsample_bytree': 0.772936562421009, 'learning_rate': 0.21843653910731634}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:54:16,359]\u001b[0m Trial 681 finished with value: 0.6817377312952535 and parameters: {'min_child_weight': 0.7675386298439021, 'subsample': 0.7860569739320458, 'max_depth': 9, 'reg_lambda': 5.423655228693858, 'reg_alpha': 0.36975962428478787, 'num_leaves': 2, 'colsample_bytree': 0.795392519744677, 'learning_rate': 0.23084236286399346}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:54:23,571]\u001b[0m Trial 682 finished with value: 0.6741753821399838 and parameters: {'min_child_weight': 0.6863335696960567, 'subsample': 0.8358290271347618, 'max_depth': 6, 'reg_lambda': 6.705241724079939, 'reg_alpha': 0.004977769964553055, 'num_leaves': 225, 'colsample_bytree': 0.6920663562596271, 'learning_rate': 0.15043287781282688}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:54:32,779]\u001b[0m Trial 683 finished with value: 0.681255028157683 and parameters: {'min_child_weight': 0.9151118334750996, 'subsample': 0.8657616578199395, 'max_depth': 14, 'reg_lambda': 5.941890467737707, 'reg_alpha': 0.6055812583125282, 'num_leaves': 34, 'colsample_bytree': 0.712830914938375, 'learning_rate': 0.17233857587803245}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:54:39,847]\u001b[0m Trial 684 finished with value: 0.6777152051488335 and parameters: {'min_child_weight': 0.35766505115164837, 'subsample': 0.8905524082467596, 'max_depth': 12, 'reg_lambda': 6.865826670950694, 'reg_alpha': 0.10245231639997752, 'num_leaves': 18, 'colsample_bytree': 0.7297206323259781, 'learning_rate': 0.13109479621201994}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:54:44,624]\u001b[0m Trial 685 finished with value: 0.6759452936444087 and parameters: {'min_child_weight': 0.420897979718484, 'subsample': 0.7169516851906685, 'max_depth': 11, 'reg_lambda': 6.16097139320504, 'reg_alpha': 2.9514707768036774, 'num_leaves': 11, 'colsample_bytree': 0.7574781604577783, 'learning_rate': 0.2677975636159037}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:54:55,373]\u001b[0m Trial 686 finished with value: 0.6699919549477071 and parameters: {'min_child_weight': 0.7889943530981653, 'subsample': 0.7445462303234311, 'max_depth': 8, 'reg_lambda': 6.553172246900829, 'reg_alpha': 0.5286843225988873, 'num_leaves': 50, 'colsample_bytree': 0.8827872970072889, 'learning_rate': 0.3257609753737707}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:55:03,545]\u001b[0m Trial 687 finished with value: 0.66934835076428 and parameters: {'min_child_weight': 0.8605790584856944, 'subsample': 0.6552514990469496, 'max_depth': 9, 'reg_lambda': 8.72607884045085, 'reg_alpha': 0.43751680268601495, 'num_leaves': 24, 'colsample_bytree': 0.8343093453837518, 'learning_rate': 0.35984478081594673}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:55:05,459]\u001b[0m Trial 688 finished with value: 0.6831858407079647 and parameters: {'min_child_weight': 0.7277322156439868, 'subsample': 0.6357798821639065, 'max_depth': 26, 'reg_lambda': 8.19270215711913, 'reg_alpha': 0.6594688194624587, 'num_leaves': 2, 'colsample_bytree': 0.8143564579204873, 'learning_rate': 0.29292761775391424}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:55:11,254]\u001b[0m Trial 689 finished with value: 0.682059533386967 and parameters: {'min_child_weight': 0.1003401046671868, 'subsample': 0.6673610266210287, 'max_depth': 8, 'reg_lambda': 4.190797874272467, 'reg_alpha': 0.2776988996938034, 'num_leaves': 12, 'colsample_bytree': 0.8403374255679572, 'learning_rate': 0.20302792218504145}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:55:19,259]\u001b[0m Trial 690 finished with value: 0.6810941271118263 and parameters: {'min_child_weight': 0.05968068944443117, 'subsample': 0.6492804073661481, 'max_depth': 10, 'reg_lambda': 4.758329153458375, 'reg_alpha': 3.7063729946286, 'num_leaves': 141, 'colsample_bytree': 0.7815904164931847, 'learning_rate': 0.23578700275599704}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:55:21,133]\u001b[0m Trial 691 finished with value: 0.6802896218825423 and parameters: {'min_child_weight': 0.32567367255563756, 'subsample': 0.6292018472412448, 'max_depth': 10, 'reg_lambda': 5.806808346523503, 'reg_alpha': 0.5185226856224783, 'num_leaves': 2, 'colsample_bytree': 0.6966073593989305, 'learning_rate': 0.22022122897778318}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:55:28,079]\u001b[0m Trial 692 finished with value: 0.6799678197908287 and parameters: {'min_child_weight': 0.8383986854117058, 'subsample': 0.9007496354585868, 'max_depth': 12, 'reg_lambda': 6.405752969212311, 'reg_alpha': 0.7970333392797899, 'num_leaves': 19, 'colsample_bytree': 0.7264907956757177, 'learning_rate': 0.11064791102429075}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:55:33,429]\u001b[0m Trial 693 finished with value: 0.679646017699115 and parameters: {'min_child_weight': 0.07886180763568273, 'subsample': 0.8499869497915831, 'max_depth': 7, 'reg_lambda': 5.244751003935222, 'reg_alpha': 0.4376080982535087, 'num_leaves': 12, 'colsample_bytree': 0.7408249658506866, 'learning_rate': 0.16747382409653563}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:55:40,762]\u001b[0m Trial 694 finished with value: 0.6542236524537409 and parameters: {'min_child_weight': 0.8030103406993818, 'subsample': 0.9752890325125575, 'max_depth': 9, 'reg_lambda': 8.376046811261354, 'reg_alpha': 0.3408429357738316, 'num_leaves': 30, 'colsample_bytree': 0.7956773096624139, 'learning_rate': 0.820255539059035}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:55:45,915]\u001b[0m Trial 695 finished with value: 0.6622687047465808 and parameters: {'min_child_weight': 0.8893057237327685, 'subsample': 0.6133594874398411, 'max_depth': 5, 'reg_lambda': 7.945273956687174, 'reg_alpha': 0.35071569986802265, 'num_leaves': 11, 'colsample_bytree': 0.8562219467106921, 'learning_rate': 0.31520758213589617}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:55:59,165]\u001b[0m Trial 696 finished with value: 0.6711182622687047 and parameters: {'min_child_weight': 0.3747119482148056, 'subsample': 0.7791990029150264, 'max_depth': 13, 'reg_lambda': 6.9261856683508185, 'reg_alpha': 0.1702379624677045, 'num_leaves': 305, 'colsample_bytree': 0.699630520702842, 'learning_rate': 0.14426881479672576}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:56:01,116]\u001b[0m Trial 697 finished with value: 0.6799678197908287 and parameters: {'min_child_weight': 0.1339350902520015, 'subsample': 0.8775829275238687, 'max_depth': 6, 'reg_lambda': 4.968618709581276, 'reg_alpha': 0.22593481901195567, 'num_leaves': 2, 'colsample_bytree': 0.7126375366131528, 'learning_rate': 0.1885804151346237}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:56:14,891]\u001b[0m Trial 698 finished with value: 0.6791633145615446 and parameters: {'min_child_weight': 0.3401771703046742, 'subsample': 0.8589184738575378, 'max_depth': 15, 'reg_lambda': 6.20056546862938, 'reg_alpha': 0.0002281739567444041, 'num_leaves': 265, 'colsample_bytree': 0.6758846378556289, 'learning_rate': 0.09899513028556563}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 19:56:21,813]\u001b[0m Trial 699 finished with value: 0.6683829444891392 and parameters: {'min_child_weight': 0.4728527073090928, 'subsample': 0.7963184592968595, 'max_depth': 30, 'reg_lambda': 8.479131797506197, 'reg_alpha': 1.5280439769488947, 'num_leaves': 20, 'colsample_bytree': 0.7624293731883549, 'learning_rate': 0.2519705210249117}. Best is trial 304 with value: 0.7036202735317779.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "selected_cols = lgbc_features\n",
    "\n",
    "def objective(trial):    \n",
    "    min_child_weight = trial.suggest_float('min_child_weight', 1e-4, 1.0)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 32)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 1, 10)\n",
    "    reg_alpha = trial.suggest_float('reg_alpha', 0, 5),\n",
    "    num_leaves = trial.suggest_int('num_leaves', 2, 512)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.1, 1.0)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1.0, log=True)\n",
    "    \n",
    "    classifier_obj = Pipeline(steps=[(\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", selected_cols)], remainder=\"drop\")),\n",
    "        ('lgbc', lgb.LGBMClassifier(colsample_bytree=colsample_bytree,\n",
    "               learning_rate=learning_rate, max_depth=max_depth,\n",
    "               min_child_weight=min_child_weight, num_leaves=num_leaves,\n",
    "               random_state=23, reg_alpha=reg_alpha,\n",
    "               reg_lambda=reg_lambda, subsample=subsample))])\n",
    "    \n",
    "    score = cross_val_score(classifier_obj, X_train, y_train, n_jobs=-1,\n",
    "                           cv=tscv, scoring='accuracy')\n",
    "    \n",
    "    \n",
    "    score_avg = score.mean()\n",
    "    \n",
    "    return score_avg\n",
    "\n",
    "study_name = '../models/hyperparameter_tuning/study_lgbc_selected'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_lgbc = optuna.create_study(study_name = study_name, direction='maximize', \n",
    "                               storage = storage_name, load_if_exists=True)\n",
    "\n",
    "study_lgbc.optimize(objective, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9f15d24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 0.7064896755162242\n",
      "val_acc: 0.6522315510384445\n",
      "test_acc: 0.6620745542949756\n",
      "LGBoost or XGBoost\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>AWAY_OREB_L5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>AWAY_TS_PCT_opp_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>AWAY_COVER_PCT_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>AWAY_AVG_ATS_DIFF_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>AWAY_NET_RATING_opp_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>AWAY_PF_opp_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>AWAY_UAST_2PM_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>AWAY_DFGA_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>AWAY_FG3A_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>AWAY_FG3M_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>AWAY_EFG_PCT_L10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>AWAY_UAST_3PM_L10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>AWAY_PTS_PAINT_L5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>HOME_TOV_PCT_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>HOME_EFG_PCT_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>AWAY_REST</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>HOME_REB_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>HOME_PTS_FB_opp_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>HOME_EFG_PCT_L10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>HOME_NET_RATING_opp_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>HOME_FG3A_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>HOME_AVG_ATS_DIFF_L5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>HOME_DEF_RATING_L10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>HOME_NET_RATING_L20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>AWAY_PTS_opp_L20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>HOME_AVG_ATS_DIFF_L10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>HOME_WIN_PCT_L20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>AWAY_AVG_ATS_DIFF_L10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>AWAY_AVG_ATS_DIFF_L5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>HOME_UFGA_opp_L5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>AWAY_SAST_opp_L20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>HOME_PLUS_MINUS_opp_L20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>AWAY_PIE_L20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>HOME_PIE_L20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>AWAY_PLUS_MINUS_opp_L20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>AWAY_WIN_PCT_L20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>HOME_AVG_ATS_DIFF_L20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>HOME_PLUS_MINUS_L20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOME_FG2M_L5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>AWAY_FG2M_L5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>HOME_EFG_PCT_L5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>AWAY_EFG_PCT_L5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature_name  coef\n",
       "178             AWAY_OREB_L5     1\n",
       "337      AWAY_TS_PCT_opp_L20     1\n",
       "334       AWAY_COVER_PCT_L20     1\n",
       "332    AWAY_AVG_ATS_DIFF_L20     1\n",
       "320  AWAY_NET_RATING_opp_L20     1\n",
       "317          AWAY_PF_opp_L20     1\n",
       "308        AWAY_UAST_2PM_L20     1\n",
       "304            AWAY_DFGA_L20     1\n",
       "284            AWAY_FG3A_L20     1\n",
       "283            AWAY_FG3M_L20     1\n",
       "278         AWAY_EFG_PCT_L10     1\n",
       "259        AWAY_UAST_3PM_L10     1\n",
       "196        AWAY_PTS_PAINT_L5     1\n",
       "171         HOME_TOV_PCT_L20     1\n",
       "168         HOME_EFG_PCT_L20     1\n",
       "345                AWAY_REST     1\n",
       "119             HOME_REB_L20     1\n",
       "157      HOME_PTS_FB_opp_L20     1\n",
       "107         HOME_EFG_PCT_L10     1\n",
       "148  HOME_NET_RATING_opp_L20     1\n",
       "115            HOME_FG3A_L20     1\n",
       "50      HOME_AVG_ATS_DIFF_L5     1\n",
       "73       HOME_DEF_RATING_L10     1\n",
       "126      HOME_NET_RATING_L20     1\n",
       "318         AWAY_PTS_opp_L20     2\n",
       "103    HOME_AVG_ATS_DIFF_L10     2\n",
       "163         HOME_WIN_PCT_L20     2\n",
       "275    AWAY_AVG_ATS_DIFF_L10     2\n",
       "221     AWAY_AVG_ATS_DIFF_L5     2\n",
       "44          HOME_UFGA_opp_L5     2\n",
       "324        AWAY_SAST_opp_L20     2\n",
       "147  HOME_PLUS_MINUS_opp_L20     3\n",
       "344             AWAY_PIE_L20     3\n",
       "173             HOME_PIE_L20     3\n",
       "319  AWAY_PLUS_MINUS_opp_L20     3\n",
       "333         AWAY_WIN_PCT_L20     3\n",
       "162    HOME_AVG_ATS_DIFF_L20     5\n",
       "123      HOME_PLUS_MINUS_L20     6\n",
       "0               HOME_FG2M_L5     7\n",
       "174             AWAY_FG2M_L5     8\n",
       "57           HOME_EFG_PCT_L5     9\n",
       "226          AWAY_EFG_PCT_L5    12"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = study_lgbc.best_params\n",
    "\n",
    "best_lgbc = Pipeline(steps=[(\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", selected_cols)], remainder=\"drop\")),\n",
    "        ('lgbc', lgb.LGBMClassifier(**params))])\n",
    "\n",
    "best_lgbc.fit(X_train, y_train)\n",
    "\n",
    "print(\"train_acc:\", best_lgbc.score(X_train, y_train))\n",
    "print(\"val_acc:\", best_lgbc.score(X_val, y_val))\n",
    "print(\"test_acc:\", best_lgbc.score(X_test, y_test))\n",
    "\n",
    "\n",
    "view_model_coefs(best_lgbc.named_steps['lgbc'], X_train[selected_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ea8015f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.725714617307935,\n",
       "               learning_rate=0.03366464571120959, max_depth=5,\n",
       "               min_child_weight=0.534047514075973, num_leaves=194,\n",
       "               reg_alpha=4.741561203592908, reg_lambda=5.4130017942167665,\n",
       "               subsample=0.6316705486384242)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.725714617307935,\n",
       "               learning_rate=0.03366464571120959, max_depth=5,\n",
       "               min_child_weight=0.534047514075973, num_leaves=194,\n",
       "               reg_alpha=4.741561203592908, reg_lambda=5.4130017942167665,\n",
       "               subsample=0.6316705486384242)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.725714617307935,\n",
       "               learning_rate=0.03366464571120959, max_depth=5,\n",
       "               min_child_weight=0.534047514075973, num_leaves=194,\n",
       "               reg_alpha=4.741561203592908, reg_lambda=5.4130017942167665,\n",
       "               subsample=0.6316705486384242)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lgbc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f53c07",
   "metadata": {},
   "source": [
    "## LGBClassifier No Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed5b7e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-08 11:28:42,850]\u001b[0m A new study created in RDB with name: ../models/hyperparameter_tuning/study_lgbc\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:29:11,404]\u001b[0m Trial 0 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.7945820844069986, 'subsample': 0.867006029374243, 'max_depth': 31, 'reg_lambda': 1.002477454176816, 'reg_alpha': 3.754182600915853, 'num_leaves': 251, 'colsample_bytree': 0.8443812917531429, 'learning_rate': 0.00019335906781807813}. Best is trial 0 with value: 0.588897827835881.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:29:20,649]\u001b[0m Trial 1 finished with value: 0.5990345937248593 and parameters: {'min_child_weight': 0.7004950986100416, 'subsample': 0.7368655428306523, 'max_depth': 14, 'reg_lambda': 6.617448837534741, 'reg_alpha': 0.386326348857049, 'num_leaves': 238, 'colsample_bytree': 0.22604027835477142, 'learning_rate': 0.0028727704948619506}. Best is trial 1 with value: 0.5990345937248593.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:29:33,979]\u001b[0m Trial 2 finished with value: 0.6212389380530974 and parameters: {'min_child_weight': 0.02889576389011448, 'subsample': 0.9239594858502072, 'max_depth': 9, 'reg_lambda': 4.765624311997151, 'reg_alpha': 4.31760499099369, 'num_leaves': 235, 'colsample_bytree': 0.6667800708638365, 'learning_rate': 0.0032207639313644515}. Best is trial 2 with value: 0.6212389380530974.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:29:46,443]\u001b[0m Trial 3 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.8569730383722376, 'subsample': 0.9999628144503765, 'max_depth': 7, 'reg_lambda': 1.784188055022926, 'reg_alpha': 3.86559537869867, 'num_leaves': 88, 'colsample_bytree': 0.7562939748774627, 'learning_rate': 0.00023040609785313928}. Best is trial 2 with value: 0.6212389380530974.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:30:06,600]\u001b[0m Trial 4 finished with value: 0.6817377312952534 and parameters: {'min_child_weight': 0.7398060114570643, 'subsample': 0.8448290250609544, 'max_depth': 19, 'reg_lambda': 1.371132507502534, 'reg_alpha': 0.07649111725091029, 'num_leaves': 122, 'colsample_bytree': 0.37812600671039154, 'learning_rate': 0.05501374245402038}. Best is trial 4 with value: 0.6817377312952534.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:30:20,471]\u001b[0m Trial 5 finished with value: 0.6923572003218021 and parameters: {'min_child_weight': 0.33761790953649995, 'subsample': 0.6627199458879519, 'max_depth': 12, 'reg_lambda': 3.213830353747781, 'reg_alpha': 4.691800778115701, 'num_leaves': 402, 'colsample_bytree': 0.6668845526102115, 'learning_rate': 0.18166941584634766}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:30:33,174]\u001b[0m Trial 6 finished with value: 0.682059533386967 and parameters: {'min_child_weight': 0.7518743377144198, 'subsample': 0.9518665496148658, 'max_depth': 31, 'reg_lambda': 2.533081397192391, 'reg_alpha': 1.6993460883682765, 'num_leaves': 104, 'colsample_bytree': 0.3597569369133833, 'learning_rate': 0.02240128036469595}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:30:43,480]\u001b[0m Trial 7 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.9392179343910412, 'subsample': 0.9021566166585291, 'max_depth': 25, 'reg_lambda': 8.488933948632933, 'reg_alpha': 3.385778594865659, 'num_leaves': 415, 'colsample_bytree': 0.3999174468934341, 'learning_rate': 0.00025000610840295376}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:30:49,709]\u001b[0m Trial 8 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.2563682284002036, 'subsample': 0.8003231584692969, 'max_depth': 19, 'reg_lambda': 6.913729303513615, 'reg_alpha': 4.396861898783926, 'num_leaves': 368, 'colsample_bytree': 0.14660889900076712, 'learning_rate': 0.0003454597433699767}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:30:58,316]\u001b[0m Trial 9 finished with value: 0.6757843925985518 and parameters: {'min_child_weight': 0.09924606459929625, 'subsample': 0.6266188107834351, 'max_depth': 30, 'reg_lambda': 2.85897832706079, 'reg_alpha': 2.0762909957856426, 'num_leaves': 213, 'colsample_bytree': 0.18720200021037275, 'learning_rate': 0.023185102309470337}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:31:07,796]\u001b[0m Trial 10 finished with value: 0.6453740949316169 and parameters: {'min_child_weight': 0.41379889204217046, 'subsample': 0.6054558917784386, 'max_depth': 13, 'reg_lambda': 4.231968648425298, 'reg_alpha': 2.8343553851268246, 'num_leaves': 510, 'colsample_bytree': 0.9564828202292461, 'learning_rate': 0.9847579325349624}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:31:22,379]\u001b[0m Trial 11 finished with value: 0.6818986323411103 and parameters: {'min_child_weight': 0.5315162572761213, 'subsample': 0.7084722909670524, 'max_depth': 24, 'reg_lambda': 3.3559005447742964, 'reg_alpha': 1.4865686577382298, 'num_leaves': 350, 'colsample_bytree': 0.5426178262021836, 'learning_rate': 0.2538512481426631}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:31:36,384]\u001b[0m Trial 12 finished with value: 0.6910699919549478 and parameters: {'min_child_weight': 0.534356374705099, 'subsample': 0.7030819891684641, 'max_depth': 13, 'reg_lambda': 3.3276601006282744, 'reg_alpha': 1.6373368485248843, 'num_leaves': 44, 'colsample_bytree': 0.5225501322105001, 'learning_rate': 0.11785508491682}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:31:41,583]\u001b[0m Trial 13 finished with value: 0.6912308930008045 and parameters: {'min_child_weight': 0.4833692488501514, 'subsample': 0.6914185908018626, 'max_depth': 3, 'reg_lambda': 5.468154658433802, 'reg_alpha': 4.987900511405929, 'num_leaves': 443, 'colsample_bytree': 0.5788740916118957, 'learning_rate': 0.1467837020520633}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:31:46,619]\u001b[0m Trial 14 finished with value: 0.6670957361222848 and parameters: {'min_child_weight': 0.36012275407839095, 'subsample': 0.6635672088146364, 'max_depth': 3, 'reg_lambda': 5.77788090917287, 'reg_alpha': 4.725632744807732, 'num_leaves': 512, 'colsample_bytree': 0.6921175673462379, 'learning_rate': 0.6537479431334465}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:31:53,428]\u001b[0m Trial 15 finished with value: 0.6854384553499597 and parameters: {'min_child_weight': 0.20040807173735745, 'subsample': 0.7640981438369195, 'max_depth': 4, 'reg_lambda': 9.199986036599281, 'reg_alpha': 4.967719589665797, 'num_leaves': 436, 'colsample_bytree': 0.6140444597492924, 'learning_rate': 0.19171259455915235}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:32:10,466]\u001b[0m Trial 16 finished with value: 0.6601769911504424 and parameters: {'min_child_weight': 0.6101642671904134, 'subsample': 0.6636735703415216, 'max_depth': 9, 'reg_lambda': 4.752699726221607, 'reg_alpha': 2.9749670816508655, 'num_leaves': 325, 'colsample_bytree': 0.8235920143927844, 'learning_rate': 0.006053224483410436}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:32:23,417]\u001b[0m Trial 17 finished with value: 0.6920353982300884 and parameters: {'min_child_weight': 0.38499137719499715, 'subsample': 0.8011868278641481, 'max_depth': 8, 'reg_lambda': 7.5316172039342, 'reg_alpha': 4.101504790909269, 'num_leaves': 447, 'colsample_bytree': 0.4655777547801929, 'learning_rate': 0.05625292136264313}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:32:36,496]\u001b[0m Trial 18 finished with value: 0.6883346741753822 and parameters: {'min_child_weight': 0.30416483623842105, 'subsample': 0.7998270190961699, 'max_depth': 16, 'reg_lambda': 7.70332449489204, 'reg_alpha': 3.9295388015424475, 'num_leaves': 312, 'colsample_bytree': 0.43665241490804585, 'learning_rate': 0.0344653227175206}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:32:46,065]\u001b[0m Trial 19 finished with value: 0.6714400643604183 and parameters: {'min_child_weight': 0.16717066491899263, 'subsample': 0.7913485971127514, 'max_depth': 10, 'reg_lambda': 9.671708890266512, 'reg_alpha': 3.327915395746765, 'num_leaves': 405, 'colsample_bytree': 0.2918583880841759, 'learning_rate': 0.010281189810715}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:32:55,222]\u001b[0m Trial 20 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.4072985499217123, 'subsample': 0.8366213716200177, 'max_depth': 7, 'reg_lambda': 7.737157681815252, 'reg_alpha': 4.297276318203058, 'num_leaves': 173, 'colsample_bytree': 0.4831965973539861, 'learning_rate': 0.0009834525640903676}. Best is trial 5 with value: 0.6923572003218021.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:33:04,141]\u001b[0m Trial 21 finished with value: 0.6925181013676589 and parameters: {'min_child_weight': 0.4903270598378111, 'subsample': 0.6653315702719856, 'max_depth': 5, 'reg_lambda': 5.85036074999235, 'reg_alpha': 4.8827178583012945, 'num_leaves': 459, 'colsample_bytree': 0.6058547729958857, 'learning_rate': 0.0852772826100897}. Best is trial 21 with value: 0.6925181013676589.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:33:16,119]\u001b[0m Trial 22 finished with value: 0.6915526950925182 and parameters: {'min_child_weight': 0.6229847017827502, 'subsample': 0.7512414640875876, 'max_depth': 6, 'reg_lambda': 6.247111263058886, 'reg_alpha': 4.441625323731917, 'num_leaves': 453, 'colsample_bytree': 0.6562187802858781, 'learning_rate': 0.0589231117770892}. Best is trial 21 with value: 0.6925181013676589.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:33:27,358]\u001b[0m Trial 23 finished with value: 0.6769106999195494 and parameters: {'min_child_weight': 0.3197901773546141, 'subsample': 0.6563888539986225, 'max_depth': 11, 'reg_lambda': 7.589540089714101, 'reg_alpha': 4.655336626148305, 'num_leaves': 484, 'colsample_bytree': 0.7738164165744201, 'learning_rate': 0.3976655363491033}. Best is trial 21 with value: 0.6925181013676589.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:33:43,040]\u001b[0m Trial 24 finished with value: 0.6896218825422364 and parameters: {'min_child_weight': 0.4851327268761161, 'subsample': 0.7302052452522172, 'max_depth': 6, 'reg_lambda': 4.189791923536424, 'reg_alpha': 3.9456014948034195, 'num_leaves': 392, 'colsample_bytree': 0.9309486125248713, 'learning_rate': 0.07433195666120522}. Best is trial 21 with value: 0.6925181013676589.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:33:51,959]\u001b[0m Trial 25 finished with value: 0.6717618664521319 and parameters: {'min_child_weight': 0.3930271058885927, 'subsample': 0.6043988046791674, 'max_depth': 16, 'reg_lambda': 8.554375203938813, 'reg_alpha': 3.5639856025510923, 'num_leaves': 308, 'colsample_bytree': 0.4742063459711424, 'learning_rate': 0.3942963855182262}. Best is trial 21 with value: 0.6925181013676589.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:34:08,472]\u001b[0m Trial 26 finished with value: 0.6849557522123894 and parameters: {'min_child_weight': 0.23346925629070325, 'subsample': 0.7725606138574671, 'max_depth': 10, 'reg_lambda': 5.312194263858783, 'reg_alpha': 4.167414142129054, 'num_leaves': 470, 'colsample_bytree': 0.7214034853001356, 'learning_rate': 0.012720935612952872}. Best is trial 21 with value: 0.6925181013676589.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:34:24,165]\u001b[0m Trial 27 finished with value: 0.6881737731295253 and parameters: {'min_child_weight': 0.6008179711664493, 'subsample': 0.6455524067841145, 'max_depth': 12, 'reg_lambda': 6.918120356969619, 'reg_alpha': 4.737107562210652, 'num_leaves': 367, 'colsample_bytree': 0.6134594469146335, 'learning_rate': 0.0913840742014534}. Best is trial 21 with value: 0.6925181013676589.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:34:34,120]\u001b[0m Trial 28 finished with value: 0.6870474658085277 and parameters: {'min_child_weight': 0.45255667229857444, 'subsample': 0.8293042768038004, 'max_depth': 8, 'reg_lambda': 6.0901101635172346, 'reg_alpha': 2.836385442938122, 'num_leaves': 283, 'colsample_bytree': 0.31565377669816996, 'learning_rate': 0.03501172789964607}. Best is trial 21 with value: 0.6925181013676589.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:34:45,748]\u001b[0m Trial 29 finished with value: 0.6791633145615447 and parameters: {'min_child_weight': 0.11256946745857804, 'subsample': 0.6991926717295419, 'max_depth': 5, 'reg_lambda': 2.1790430466911994, 'reg_alpha': 2.2779547397173694, 'num_leaves': 414, 'colsample_bytree': 0.8836053736876088, 'learning_rate': 0.24193425434569588}. Best is trial 21 with value: 0.6925181013676589.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:35:12,078]\u001b[0m Trial 30 finished with value: 0.6827031375703942 and parameters: {'min_child_weight': 0.2930922877018477, 'subsample': 0.8698252026057496, 'max_depth': 16, 'reg_lambda': 3.6159981426492127, 'reg_alpha': 0.8263311524010508, 'num_leaves': 480, 'colsample_bytree': 0.8018016085487112, 'learning_rate': 0.015595012152969599}. Best is trial 21 with value: 0.6925181013676589.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:35:21,564]\u001b[0m Trial 31 finished with value: 0.6925181013676589 and parameters: {'min_child_weight': 0.6094525842102911, 'subsample': 0.72619440484972, 'max_depth': 5, 'reg_lambda': 6.231992659904265, 'reg_alpha': 4.511875456024251, 'num_leaves': 454, 'colsample_bytree': 0.6580943433278793, 'learning_rate': 0.05254020740468952}. Best is trial 21 with value: 0.6925181013676589.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:35:30,266]\u001b[0m Trial 32 finished with value: 0.6934835076427996 and parameters: {'min_child_weight': 0.6605570747395244, 'subsample': 0.7274050150171957, 'max_depth': 5, 'reg_lambda': 7.234739441962705, 'reg_alpha': 4.554844396534948, 'num_leaves': 385, 'colsample_bytree': 0.6091052241401881, 'learning_rate': 0.03528066139139683}. Best is trial 32 with value: 0.6934835076427996.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:35:36,618]\u001b[0m Trial 33 finished with value: 0.6769106999195496 and parameters: {'min_child_weight': 0.6839804748138092, 'subsample': 0.722568208547641, 'max_depth': 4, 'reg_lambda': 6.647740729867609, 'reg_alpha': 4.5236187870828095, 'num_leaves': 384, 'colsample_bytree': 0.6292106175517307, 'learning_rate': 0.00702268991425038}. Best is trial 32 with value: 0.6934835076427996.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:35:46,494]\u001b[0m Trial 34 finished with value: 0.6925181013676588 and parameters: {'min_child_weight': 0.661168280721877, 'subsample': 0.672397607266984, 'max_depth': 5, 'reg_lambda': 4.756340487412962, 'reg_alpha': 3.6123232946713317, 'num_leaves': 351, 'colsample_bytree': 0.7147162818927144, 'learning_rate': 0.032713280728870836}. Best is trial 32 with value: 0.6934835076427996.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:35:56,305]\u001b[0m Trial 35 finished with value: 0.6936444086886564 and parameters: {'min_child_weight': 0.8423251255354968, 'subsample': 0.6828017226874928, 'max_depth': 5, 'reg_lambda': 5.007541814930531, 'reg_alpha': 3.7628236005356737, 'num_leaves': 334, 'colsample_bytree': 0.7222463042987832, 'learning_rate': 0.031777727342208226}. Best is trial 35 with value: 0.6936444086886564.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:36:06,552]\u001b[0m Trial 36 finished with value: 0.6061142397425584 and parameters: {'min_child_weight': 0.8017335658688471, 'subsample': 0.744751356543486, 'max_depth': 7, 'reg_lambda': 5.149767978849443, 'reg_alpha': 3.8363330646308875, 'num_leaves': 328, 'colsample_bytree': 0.5765784499025699, 'learning_rate': 0.0026388269744752075}. Best is trial 35 with value: 0.6936444086886564.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:36:12,894]\u001b[0m Trial 37 finished with value: 0.6954143201930812 and parameters: {'min_child_weight': 0.995643604153198, 'subsample': 0.6376167015953358, 'max_depth': 3, 'reg_lambda': 6.076198133226301, 'reg_alpha': 3.15470431816153, 'num_leaves': 268, 'colsample_bytree': 0.8610949729492925, 'learning_rate': 0.019015669993043882}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:36:18,795]\u001b[0m Trial 38 finished with value: 0.6577634754625905 and parameters: {'min_child_weight': 0.9849437826301228, 'subsample': 0.6400187090252477, 'max_depth': 3, 'reg_lambda': 6.4491847671422775, 'reg_alpha': 3.0346260021333906, 'num_leaves': 259, 'colsample_bytree': 0.8620969462392291, 'learning_rate': 0.004074996833464866}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:36:36,081]\u001b[0m Trial 39 finished with value: 0.6875301689460981 and parameters: {'min_child_weight': 0.8766345978953649, 'subsample': 0.6287321439257285, 'max_depth': 9, 'reg_lambda': 7.155577454778162, 'reg_alpha': 3.250365129563025, 'num_leaves': 209, 'colsample_bytree': 0.7528473678502621, 'learning_rate': 0.018351617636582836}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:36:51,634]\u001b[0m Trial 40 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.8843690539755943, 'subsample': 0.6832862508967468, 'max_depth': 25, 'reg_lambda': 8.334919271954693, 'reg_alpha': 3.736940195386476, 'num_leaves': 283, 'colsample_bytree': 0.8802409360893867, 'learning_rate': 0.00173887710064061}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:36:59,648]\u001b[0m Trial 41 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.7745161002556469, 'subsample': 0.7218301123207749, 'max_depth': 5, 'reg_lambda': 5.79980947473745, 'reg_alpha': 4.165439993439815, 'num_leaves': 277, 'colsample_bytree': 0.6733937553065469, 'learning_rate': 0.00010046306091776254}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:37:11,894]\u001b[0m Trial 42 finished with value: 0.6926790024135157 and parameters: {'min_child_weight': 0.8152135576742563, 'subsample': 0.6857991098817309, 'max_depth': 6, 'reg_lambda': 5.967156399374208, 'reg_alpha': 4.99266600675806, 'num_leaves': 430, 'colsample_bytree': 0.7454901819835055, 'learning_rate': 0.03155840016774019}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:37:27,397]\u001b[0m Trial 43 finished with value: 0.6905872888173773 and parameters: {'min_child_weight': 0.838089606342611, 'subsample': 0.7119617388709489, 'max_depth': 7, 'reg_lambda': 4.237772144934708, 'reg_alpha': 4.466400156185459, 'num_leaves': 426, 'colsample_bytree': 0.7762409884899972, 'learning_rate': 0.02848922180365324}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:37:33,478]\u001b[0m Trial 44 finished with value: 0.6839903459372486 and parameters: {'min_child_weight': 0.9341403425125201, 'subsample': 0.682404403114128, 'max_depth': 3, 'reg_lambda': 5.7768145343384605, 'reg_alpha': 4.859714653382724, 'num_leaves': 349, 'colsample_bytree': 0.9138188260392583, 'learning_rate': 0.007530688454599403}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:37:46,859]\u001b[0m Trial 45 finished with value: 0.6839903459372486 and parameters: {'min_child_weight': 0.986885137707082, 'subsample': 0.6194277723371299, 'max_depth': 6, 'reg_lambda': 5.156466719416396, 'reg_alpha': 2.6272957034913516, 'num_leaves': 224, 'colsample_bytree': 0.7342718615672458, 'learning_rate': 0.11164228426765979}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:38:06,991]\u001b[0m Trial 46 finished with value: 0.6891391794046662 and parameters: {'min_child_weight': 0.7340911386943507, 'subsample': 0.6435704327362545, 'max_depth': 8, 'reg_lambda': 7.115313126208409, 'reg_alpha': 3.58446647986784, 'num_leaves': 378, 'colsample_bytree': 0.9784658223572823, 'learning_rate': 0.021238153031205954}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:38:27,230]\u001b[0m Trial 47 finished with value: 0.6893000804505229 and parameters: {'min_child_weight': 0.9248212802382443, 'subsample': 0.7430405511409958, 'max_depth': 22, 'reg_lambda': 6.564841738231723, 'reg_alpha': 4.0491774629003805, 'num_leaves': 151, 'colsample_bytree': 0.8059547514942265, 'learning_rate': 0.04799845245966513}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:38:33,587]\u001b[0m Trial 48 finished with value: 0.6921962992759452 and parameters: {'min_child_weight': 0.8433619752530819, 'subsample': 0.9842879433874279, 'max_depth': 4, 'reg_lambda': 4.5461113160072255, 'reg_alpha': 4.970900134412904, 'num_leaves': 252, 'colsample_bytree': 0.5243895000449077, 'learning_rate': 0.08037319910588889}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:38:42,553]\u001b[0m Trial 49 finished with value: 0.6928399034593725 and parameters: {'min_child_weight': 0.560448959379586, 'subsample': 0.6891998165267401, 'max_depth': 28, 'reg_lambda': 6.121670870894789, 'reg_alpha': 4.584677361417844, 'num_leaves': 10, 'colsample_bytree': 0.8358330587010614, 'learning_rate': 0.015706452832785628}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:38:56,875]\u001b[0m Trial 50 finished with value: 0.6854384553499597 and parameters: {'min_child_weight': 0.7841253562945443, 'subsample': 0.6911178872819438, 'max_depth': 27, 'reg_lambda': 8.144190201089044, 'reg_alpha': 4.2727663436989545, 'num_leaves': 49, 'colsample_bytree': 0.8310039086860181, 'learning_rate': 0.012857419947240819}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:39:13,412]\u001b[0m Trial 51 finished with value: 0.6872083668543845 and parameters: {'min_child_weight': 0.5588936370832681, 'subsample': 0.7117706633047918, 'max_depth': 29, 'reg_lambda': 6.19875454899595, 'reg_alpha': 4.6106081399488374, 'num_leaves': 96, 'colsample_bytree': 0.697966963087248, 'learning_rate': 0.04213402807158757}. Best is trial 37 with value: 0.6954143201930812.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:39:22,604]\u001b[0m Trial 52 finished with value: 0.6957361222847949 and parameters: {'min_child_weight': 0.7252918201473721, 'subsample': 0.7694117027990933, 'max_depth': 21, 'reg_lambda': 6.751360167930013, 'reg_alpha': 4.716146701800353, 'num_leaves': 11, 'colsample_bytree': 0.8437124236983123, 'learning_rate': 0.022935665781881696}. Best is trial 52 with value: 0.6957361222847949.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:39:28,953]\u001b[0m Trial 53 finished with value: 0.6880128720836685 and parameters: {'min_child_weight': 0.7239815867751798, 'subsample': 0.7600104396767934, 'max_depth': 32, 'reg_lambda': 7.219889772546296, 'reg_alpha': 4.750211624429888, 'num_leaves': 5, 'colsample_bytree': 0.9095635443094382, 'learning_rate': 0.009826958950609577}. Best is trial 52 with value: 0.6957361222847949.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:39:44,848]\u001b[0m Trial 54 finished with value: 0.6899436846339502 and parameters: {'min_child_weight': 0.6619564543382174, 'subsample': 0.7773667019603143, 'max_depth': 18, 'reg_lambda': 6.732047282389937, 'reg_alpha': 4.344342765912507, 'num_leaves': 49, 'colsample_bytree': 0.8394413543141727, 'learning_rate': 0.024413679476588162}. Best is trial 52 with value: 0.6957361222847949.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:39:51,069]\u001b[0m Trial 55 finished with value: 0.6635559131134352 and parameters: {'min_child_weight': 0.8180393874250067, 'subsample': 0.6786724546353252, 'max_depth': 21, 'reg_lambda': 5.520730412590751, 'reg_alpha': 3.196883463422709, 'num_leaves': 5, 'colsample_bytree': 0.7937462902986858, 'learning_rate': 0.004429014838167363}. Best is trial 52 with value: 0.6957361222847949.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:40:07,691]\u001b[0m Trial 56 finished with value: 0.6838294448913917 and parameters: {'min_child_weight': 0.7010082433224161, 'subsample': 0.6951692305968086, 'max_depth': 21, 'reg_lambda': 8.020493916840785, 'reg_alpha': 3.4088609736942006, 'num_leaves': 137, 'colsample_bytree': 0.7518835316726687, 'learning_rate': 0.017547196637711305}. Best is trial 52 with value: 0.6957361222847949.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:40:21,411]\u001b[0m Trial 57 finished with value: 0.6846339501206758 and parameters: {'min_child_weight': 0.7590646868550053, 'subsample': 0.6514728125014191, 'max_depth': 28, 'reg_lambda': 8.841460439130266, 'reg_alpha': 4.7863809476534795, 'num_leaves': 31, 'colsample_bytree': 0.9987609291121761, 'learning_rate': 0.009973357144620191}. Best is trial 52 with value: 0.6957361222847949.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:40:45,142]\u001b[0m Trial 58 finished with value: 0.6851166532582461 and parameters: {'min_child_weight': 0.9061098021353509, 'subsample': 0.8163557204475012, 'max_depth': 23, 'reg_lambda': 1.1856145053403049, 'reg_alpha': 2.5332127344049558, 'num_leaves': 205, 'colsample_bytree': 0.8551209815964872, 'learning_rate': 0.023114192128907703}. Best is trial 52 with value: 0.6957361222847949.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:41:06,193]\u001b[0m Trial 59 finished with value: 0.6942880128720836 and parameters: {'min_child_weight': 0.6467304331612448, 'subsample': 0.6182707146300508, 'max_depth': 26, 'reg_lambda': 7.430631441881793, 'reg_alpha': 4.000108052567693, 'num_leaves': 66, 'colsample_bytree': 0.9492121564362965, 'learning_rate': 0.03939151620338212}. Best is trial 52 with value: 0.6957361222847949.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:41:26,112]\u001b[0m Trial 60 finished with value: 0.6880128720836686 and parameters: {'min_child_weight': 0.5819541695721651, 'subsample': 0.6199085739117657, 'max_depth': 26, 'reg_lambda': 7.427722598004744, 'reg_alpha': 3.7579616322829743, 'num_leaves': 77, 'colsample_bytree': 0.9561452840201976, 'learning_rate': 0.13551499506023815}. Best is trial 52 with value: 0.6957361222847949.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:41:45,447]\u001b[0m Trial 61 finished with value: 0.6960579243765084 and parameters: {'min_child_weight': 0.6465809337325895, 'subsample': 0.6299569078876784, 'max_depth': 30, 'reg_lambda': 6.828029860902401, 'reg_alpha': 4.254290007692038, 'num_leaves': 71, 'colsample_bytree': 0.8977313257674813, 'learning_rate': 0.03936948835864795}. Best is trial 61 with value: 0.6960579243765084.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:42:06,534]\u001b[0m Trial 62 finished with value: 0.6867256637168142 and parameters: {'min_child_weight': 0.6546190886287022, 'subsample': 0.6013743176586273, 'max_depth': 29, 'reg_lambda': 6.868609555379915, 'reg_alpha': 4.001873664029507, 'num_leaves': 73, 'colsample_bytree': 0.9396070732105024, 'learning_rate': 0.0643954146439293}. Best is trial 61 with value: 0.6960579243765084.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:42:19,298]\u001b[0m Trial 63 finished with value: 0.6910699919549477 and parameters: {'min_child_weight': 0.6337681890826328, 'subsample': 0.6327215937904139, 'max_depth': 31, 'reg_lambda': 6.379677071710021, 'reg_alpha': 4.2463061950260785, 'num_leaves': 25, 'colsample_bytree': 0.8782396673896324, 'learning_rate': 0.014346486863923053}. Best is trial 61 with value: 0.6960579243765084.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:42:40,228]\u001b[0m Trial 64 finished with value: 0.6928399034593726 and parameters: {'min_child_weight': 0.542089988919534, 'subsample': 0.6579808643023023, 'max_depth': 27, 'reg_lambda': 7.852397194337056, 'reg_alpha': 4.381741860648823, 'num_leaves': 111, 'colsample_bytree': 0.904878553168406, 'learning_rate': 0.043594381869963145}. Best is trial 61 with value: 0.6960579243765084.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:43:01,957]\u001b[0m Trial 65 finished with value: 0.6881737731295253 and parameters: {'min_child_weight': 0.5291765868743479, 'subsample': 0.6157070163594651, 'max_depth': 25, 'reg_lambda': 7.916066296612863, 'reg_alpha': 4.072909991704758, 'num_leaves': 113, 'colsample_bytree': 0.9252686456697067, 'learning_rate': 0.04825599554353635}. Best is trial 61 with value: 0.6960579243765084.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:43:22,698]\u001b[0m Trial 66 finished with value: 0.6965406275140789 and parameters: {'min_child_weight': 0.7136702029320868, 'subsample': 0.6529037344913294, 'max_depth': 30, 'reg_lambda': 8.84703134835669, 'reg_alpha': 4.37901670121631, 'num_leaves': 64, 'colsample_bytree': 0.898450068980573, 'learning_rate': 0.03948819446269652}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:43:46,772]\u001b[0m Trial 67 finished with value: 0.6897827835880934 and parameters: {'min_child_weight': 0.7179585143301357, 'subsample': 0.6376089805922209, 'max_depth': 32, 'reg_lambda': 9.922028634399787, 'reg_alpha': 3.459650013347969, 'num_leaves': 71, 'colsample_bytree': 0.9746269095210873, 'learning_rate': 0.02582483500279298}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:44:11,630]\u001b[0m Trial 68 finished with value: 0.6904263877715205 and parameters: {'min_child_weight': 0.7509994776821561, 'subsample': 0.6109506795206201, 'max_depth': 30, 'reg_lambda': 9.468177418347814, 'reg_alpha': 3.757528506029689, 'num_leaves': 59, 'colsample_bytree': 0.8862533630791481, 'learning_rate': 0.09941813171790775}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:44:35,890]\u001b[0m Trial 69 finished with value: 0.6888173773129525 and parameters: {'min_child_weight': 0.6971458959778868, 'subsample': 0.6698410119404032, 'max_depth': 20, 'reg_lambda': 8.724034388437781, 'reg_alpha': 0.6069093232300533, 'num_leaves': 32, 'colsample_bytree': 0.9512272736701531, 'learning_rate': 0.1760417640245197}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:45:00,249]\u001b[0m Trial 70 finished with value: 0.6931617055510861 and parameters: {'min_child_weight': 0.634972899468114, 'subsample': 0.6570301263167148, 'max_depth': 30, 'reg_lambda': 7.390950756198196, 'reg_alpha': 3.138299794447624, 'num_leaves': 89, 'colsample_bytree': 0.8172950431444636, 'learning_rate': 0.036122633989051044}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:45:26,985]\u001b[0m Trial 71 finished with value: 0.685277554304103 and parameters: {'min_child_weight': 0.6747204344454389, 'subsample': 0.6543120242956906, 'max_depth': 30, 'reg_lambda': 7.424468440088907, 'reg_alpha': 2.001185393207996, 'num_leaves': 127, 'colsample_bytree': 0.8181958563011446, 'learning_rate': 0.07105649905150813}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:45:48,645]\u001b[0m Trial 72 finished with value: 0.6904263877715204 and parameters: {'min_child_weight': 0.6364339283706552, 'subsample': 0.6333769119067024, 'max_depth': 29, 'reg_lambda': 6.990444288702451, 'reg_alpha': 3.0719296370197675, 'num_leaves': 93, 'colsample_bytree': 0.8561771528487856, 'learning_rate': 0.03687123430015648}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:46:11,226]\u001b[0m Trial 73 finished with value: 0.6873692679002413 and parameters: {'min_child_weight': 0.5835777447890869, 'subsample': 0.6674809281015149, 'max_depth': 14, 'reg_lambda': 9.148267143347084, 'reg_alpha': 2.841889698917213, 'num_leaves': 187, 'colsample_bytree': 0.9991457339146931, 'learning_rate': 0.021270408295584634}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:46:31,542]\u001b[0m Trial 74 finished with value: 0.6859211584875302 and parameters: {'min_child_weight': 0.6975790633622353, 'subsample': 0.6251672756536637, 'max_depth': 27, 'reg_lambda': 7.297642414532364, 'reg_alpha': 3.91860897254825, 'num_leaves': 303, 'colsample_bytree': 0.7876688334726161, 'learning_rate': 0.058207258755983454}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:46:49,680]\u001b[0m Trial 75 finished with value: 0.6933226065969429 and parameters: {'min_child_weight': 0.9583371164456903, 'subsample': 0.6466318878372448, 'max_depth': 31, 'reg_lambda': 7.6787655778527935, 'reg_alpha': 4.176945008618731, 'num_leaves': 63, 'colsample_bytree': 0.8827220846620836, 'learning_rate': 0.03225902412032511}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:46:54,752]\u001b[0m Trial 76 finished with value: 0.6743362831858407 and parameters: {'min_child_weight': 0.9689196748178515, 'subsample': 0.6465712586497433, 'max_depth': 31, 'reg_lambda': 8.199861483746226, 'reg_alpha': 4.165816623003348, 'num_leaves': 63, 'colsample_bytree': 0.1267781572114799, 'learning_rate': 0.02773678277795225}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:47:06,378]\u001b[0m Trial 77 finished with value: 0.6857602574416732 and parameters: {'min_child_weight': 0.9567467009794299, 'subsample': 0.6088496640346669, 'max_depth': 24, 'reg_lambda': 6.73362817073963, 'reg_alpha': 4.411314769712203, 'num_leaves': 20, 'colsample_bytree': 0.9000932685058854, 'learning_rate': 0.01187096380364236}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:47:27,181]\u001b[0m Trial 78 finished with value: 0.6875301689460981 and parameters: {'min_child_weight': 0.4394853656257757, 'subsample': 0.8684439601971699, 'max_depth': 28, 'reg_lambda': 5.577469713150792, 'reg_alpha': 0.008149180716960913, 'num_leaves': 38, 'colsample_bytree': 0.8678141202072028, 'learning_rate': 0.018291579127061995}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:47:42,023]\u001b[0m Trial 79 finished with value: 0.6756234915526951 and parameters: {'min_child_weight': 0.8734071366868322, 'subsample': 0.7331470686606681, 'max_depth': 32, 'reg_lambda': 7.622024203495728, 'reg_alpha': 4.628245808753656, 'num_leaves': 55, 'colsample_bytree': 0.9223606337986652, 'learning_rate': 0.009011708821937438}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:47:54,660]\u001b[0m Trial 80 finished with value: 0.6474658085277554 and parameters: {'min_child_weight': 0.9098904301180031, 'subsample': 0.7855044754211973, 'max_depth': 17, 'reg_lambda': 8.368723080226104, 'reg_alpha': 3.6745599625214855, 'num_leaves': 328, 'colsample_bytree': 0.5631981737561523, 'learning_rate': 0.005430690911011278}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:48:14,806]\u001b[0m Trial 81 finished with value: 0.6865647626709575 and parameters: {'min_child_weight': 0.7778693947480286, 'subsample': 0.6605875496023624, 'max_depth': 30, 'reg_lambda': 7.665209870234563, 'reg_alpha': 3.8791047326806147, 'num_leaves': 102, 'colsample_bytree': 0.8069349136212643, 'learning_rate': 0.04247593765266583}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:48:31,936]\u001b[0m Trial 82 finished with value: 0.6934835076427996 and parameters: {'min_child_weight': 0.6452993563809324, 'subsample': 0.6749522568604084, 'max_depth': 30, 'reg_lambda': 7.04029422308757, 'reg_alpha': 4.227180351470831, 'num_leaves': 79, 'colsample_bytree': 0.7711769451899584, 'learning_rate': 0.0301755794077218}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:48:52,497]\u001b[0m Trial 83 finished with value: 0.687691069991955 and parameters: {'min_child_weight': 0.9988239233828099, 'subsample': 0.6757191258185317, 'max_depth': 31, 'reg_lambda': 6.503226310376805, 'reg_alpha': 4.484835737549144, 'num_leaves': 80, 'colsample_bytree': 0.9697482230970339, 'learning_rate': 0.02902762226582037}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:49:11,775]\u001b[0m Trial 84 finished with value: 0.6886564762670957 and parameters: {'min_child_weight': 0.9513604544257499, 'subsample': 0.7032568820497596, 'max_depth': 29, 'reg_lambda': 6.7714395250192965, 'reg_alpha': 4.190819345526161, 'num_leaves': 135, 'colsample_bytree': 0.7661531899777051, 'learning_rate': 0.06152325826256589}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:49:18,621]\u001b[0m Trial 85 finished with value: 0.6931617055510861 and parameters: {'min_child_weight': 0.59124489738972, 'subsample': 0.6265995759049858, 'max_depth': 4, 'reg_lambda': 5.008461538008169, 'reg_alpha': 4.023508520687327, 'num_leaves': 359, 'colsample_bytree': 0.6300828718184052, 'learning_rate': 0.019254917664658828}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:49:31,112]\u001b[0m Trial 86 finished with value: 0.6928399034593725 and parameters: {'min_child_weight': 0.8353186912403678, 'subsample': 0.6418700322101522, 'max_depth': 32, 'reg_lambda': 7.031007240254876, 'reg_alpha': 4.311164311774016, 'num_leaves': 20, 'colsample_bytree': 0.84800133670241, 'learning_rate': 0.03476120842293549}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:49:48,692]\u001b[0m Trial 87 finished with value: 0.6867256637168142 and parameters: {'min_child_weight': 0.7363337583833963, 'subsample': 0.7190688343877493, 'max_depth': 26, 'reg_lambda': 6.370221972551773, 'reg_alpha': 4.7254680894386185, 'num_leaves': 264, 'colsample_bytree': 0.7117027156675215, 'learning_rate': 0.07426123791176278}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:50:10,484]\u001b[0m Trial 88 finished with value: 0.6849557522123894 and parameters: {'min_child_weight': 0.5112503170554114, 'subsample': 0.618017557644738, 'max_depth': 24, 'reg_lambda': 7.034751929495106, 'reg_alpha': 3.8769440999326314, 'num_leaves': 343, 'colsample_bytree': 0.8918407520179111, 'learning_rate': 0.09449056943072777}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:50:29,453]\u001b[0m Trial 89 finished with value: 0.6878519710378118 and parameters: {'min_child_weight': 0.8043798995470336, 'subsample': 0.7490404696351036, 'max_depth': 26, 'reg_lambda': 5.928466998618383, 'reg_alpha': 3.5172079234169704, 'num_leaves': 42, 'colsample_bytree': 0.9395252937427332, 'learning_rate': 0.049892123775733856}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:50:41,669]\u001b[0m Trial 90 finished with value: 0.689139179404666 and parameters: {'min_child_weight': 0.03514345986238421, 'subsample': 0.9256005847446711, 'max_depth': 28, 'reg_lambda': 8.968767687495166, 'reg_alpha': 4.532414481379668, 'num_leaves': 396, 'colsample_bytree': 0.4168316525444681, 'learning_rate': 0.024963037556827192}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:51:01,609]\u001b[0m Trial 91 finished with value: 0.6902654867256637 and parameters: {'min_child_weight': 0.6103960806231653, 'subsample': 0.6535896207937599, 'max_depth': 30, 'reg_lambda': 7.4529537540198385, 'reg_alpha': 3.2701899348489363, 'num_leaves': 88, 'colsample_bytree': 0.820962065877363, 'learning_rate': 0.040611352627942195}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:51:08,291]\u001b[0m Trial 92 finished with value: 0.6957361222847948 and parameters: {'min_child_weight': 0.6695026325196773, 'subsample': 0.6364303173268229, 'max_depth': 4, 'reg_lambda': 5.361765661830101, 'reg_alpha': 4.07738475674834, 'num_leaves': 359, 'colsample_bytree': 0.6472992972224372, 'learning_rate': 0.019517246894926885}. Best is trial 66 with value: 0.6965406275140789.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:51:13,304]\u001b[0m Trial 93 finished with value: 0.697184231697506 and parameters: {'min_child_weight': 0.6506956627608508, 'subsample': 0.6315997826972315, 'max_depth': 3, 'reg_lambda': 4.581240958436662, 'reg_alpha': 4.099332003129419, 'num_leaves': 235, 'colsample_bytree': 0.592681761668892, 'learning_rate': 0.030351658694475724}. Best is trial 93 with value: 0.697184231697506.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:51:18,338]\u001b[0m Trial 94 finished with value: 0.6913917940466613 and parameters: {'min_child_weight': 0.6512842106384834, 'subsample': 0.634822586295314, 'max_depth': 3, 'reg_lambda': 4.389212074196524, 'reg_alpha': 4.847928330278499, 'num_leaves': 296, 'colsample_bytree': 0.6452855650835894, 'learning_rate': 0.013053942677528145}. Best is trial 93 with value: 0.697184231697506.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:51:24,839]\u001b[0m Trial 95 finished with value: 0.6931617055510861 and parameters: {'min_child_weight': 0.7150712551855137, 'subsample': 0.6264702762117366, 'max_depth': 4, 'reg_lambda': 3.7373634105372933, 'reg_alpha': 4.060682938863672, 'num_leaves': 236, 'colsample_bytree': 0.6061649837659757, 'learning_rate': 0.01599962776009317}. Best is trial 93 with value: 0.697184231697506.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:51:29,652]\u001b[0m Trial 96 finished with value: 0.6883346741753822 and parameters: {'min_child_weight': 0.6734487629528322, 'subsample': 0.7610943794416757, 'max_depth': 3, 'reg_lambda': 4.8819540004335, 'reg_alpha': 4.304512808360779, 'num_leaves': 163, 'colsample_bytree': 0.5859571577245741, 'learning_rate': 0.00812199918919963}. Best is trial 93 with value: 0.697184231697506.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:51:39,638]\u001b[0m Trial 97 finished with value: 0.6905872888173773 and parameters: {'min_child_weight': 0.6830034382085185, 'subsample': 0.675058395026829, 'max_depth': 6, 'reg_lambda': 4.621984105719094, 'reg_alpha': 3.807381313995018, 'num_leaves': 374, 'colsample_bytree': 0.5309883347796168, 'learning_rate': 0.022524939651402027}. Best is trial 93 with value: 0.697184231697506.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:51:49,350]\u001b[0m Trial 98 finished with value: 0.6905872888173773 and parameters: {'min_child_weight': 0.7655582412472957, 'subsample': 0.6114714133883727, 'max_depth': 5, 'reg_lambda': 5.24446590025311, 'reg_alpha': 3.6527536798632454, 'num_leaves': 408, 'colsample_bytree': 0.6982875477120933, 'learning_rate': 0.05375603161825307}. Best is trial 93 with value: 0.697184231697506.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:51:59,575]\u001b[0m Trial 99 finished with value: 0.6841512469831054 and parameters: {'min_child_weight': 0.6183620999441946, 'subsample': 0.6388499581023138, 'max_depth': 7, 'reg_lambda': 5.766688376364884, 'reg_alpha': 3.962618612647242, 'num_leaves': 314, 'colsample_bytree': 0.5052012939769683, 'learning_rate': 0.011865417902078934}. Best is trial 93 with value: 0.697184231697506.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:52:05,721]\u001b[0m Trial 100 finished with value: 0.588897827835881 and parameters: {'min_child_weight': 0.6485995289942649, 'subsample': 0.6668493557415431, 'max_depth': 4, 'reg_lambda': 5.4431183358895545, 'reg_alpha': 4.428859520548966, 'num_leaves': 330, 'colsample_bytree': 0.5894549767067635, 'learning_rate': 0.0005581920872406877}. Best is trial 93 with value: 0.697184231697506.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:52:11,198]\u001b[0m Trial 101 finished with value: 0.6976669348350765 and parameters: {'min_child_weight': 0.5691480578169538, 'subsample': 0.6468809778225115, 'max_depth': 3, 'reg_lambda': 5.035339244242977, 'reg_alpha': 4.150406000153659, 'num_leaves': 69, 'colsample_bytree': 0.6713469013896531, 'learning_rate': 0.030244809841634978}. Best is trial 101 with value: 0.6976669348350765.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:52:16,501]\u001b[0m Trial 102 finished with value: 0.6970233306516492 and parameters: {'min_child_weight': 0.5737865601934318, 'subsample': 0.6471730297301552, 'max_depth': 3, 'reg_lambda': 4.94628943650263, 'reg_alpha': 4.582157379251402, 'num_leaves': 384, 'colsample_bytree': 0.6712365901791741, 'learning_rate': 0.02892179020770035}. Best is trial 101 with value: 0.6976669348350765.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:52:21,902]\u001b[0m Trial 103 finished with value: 0.6979887369267901 and parameters: {'min_child_weight': 0.5686414071344056, 'subsample': 0.6039498345578893, 'max_depth': 3, 'reg_lambda': 4.094205669894106, 'reg_alpha': 4.6580569264281735, 'num_leaves': 367, 'colsample_bytree': 0.6759192165680175, 'learning_rate': 0.027344178065208877}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:52:27,424]\u001b[0m Trial 104 finished with value: 0.6958970233306516 and parameters: {'min_child_weight': 0.5562575751523708, 'subsample': 0.6078899753512544, 'max_depth': 3, 'reg_lambda': 3.8987560812336586, 'reg_alpha': 1.2395598466450286, 'num_leaves': 389, 'colsample_bytree': 0.6662660154819138, 'learning_rate': 0.019807663844943316}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:52:32,823]\u001b[0m Trial 105 finished with value: 0.6963797264682221 and parameters: {'min_child_weight': 0.4711884533828756, 'subsample': 0.6035230846267444, 'max_depth': 3, 'reg_lambda': 3.9190398810300335, 'reg_alpha': 4.889344456284663, 'num_leaves': 423, 'colsample_bytree': 0.6646990486539406, 'learning_rate': 0.02016429469733312}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:52:38,442]\u001b[0m Trial 106 finished with value: 0.6949316170555109 and parameters: {'min_child_weight': 0.4391635346769681, 'subsample': 0.6039148602198559, 'max_depth': 3, 'reg_lambda': 3.6310280076059804, 'reg_alpha': 1.719663030278711, 'num_leaves': 423, 'colsample_bytree': 0.681937839850209, 'learning_rate': 0.020130239205277255}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:52:45,039]\u001b[0m Trial 107 finished with value: 0.6934835076427996 and parameters: {'min_child_weight': 0.47694519221009435, 'subsample': 0.6042578787992284, 'max_depth': 4, 'reg_lambda': 3.987729165013853, 'reg_alpha': 4.883757038316849, 'num_leaves': 438, 'colsample_bytree': 0.6424172478273481, 'learning_rate': 0.015144740587148478}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:52:49,846]\u001b[0m Trial 108 finished with value: 0.6936444086886565 and parameters: {'min_child_weight': 0.511528323540704, 'subsample': 0.6235383354148815, 'max_depth': 3, 'reg_lambda': 3.1666183631170637, 'reg_alpha': 4.661571357317198, 'num_leaves': 387, 'colsample_bytree': 0.5489719358667504, 'learning_rate': 0.02558358046180152}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:52:57,170]\u001b[0m Trial 109 finished with value: 0.6946098149637973 and parameters: {'min_child_weight': 0.5663494863895392, 'subsample': 0.6134255911529545, 'max_depth': 4, 'reg_lambda': 4.108533053209881, 'reg_alpha': 1.2087985961604784, 'num_leaves': 364, 'colsample_bytree': 0.6661338242038717, 'learning_rate': 0.016249830350665417}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:53:02,925]\u001b[0m Trial 110 finished with value: 0.6893000804505229 and parameters: {'min_child_weight': 0.538992616757874, 'subsample': 0.6001431463320934, 'max_depth': 3, 'reg_lambda': 3.935015904070781, 'reg_alpha': 2.3332392371698383, 'num_leaves': 401, 'colsample_bytree': 0.7305348942765291, 'learning_rate': 0.010925477444650689}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:53:08,536]\u001b[0m Trial 111 finished with value: 0.6954143201930811 and parameters: {'min_child_weight': 0.438369308703918, 'subsample': 0.6330074067703242, 'max_depth': 3, 'reg_lambda': 3.681276849315699, 'reg_alpha': 1.206123659977548, 'num_leaves': 424, 'colsample_bytree': 0.6882280271310239, 'learning_rate': 0.02018055387672366}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:53:15,639]\u001b[0m Trial 112 finished with value: 0.6934835076427996 and parameters: {'min_child_weight': 0.47216083301093276, 'subsample': 0.6314198686138365, 'max_depth': 4, 'reg_lambda': 2.918980483138429, 'reg_alpha': 1.106389956854458, 'num_leaves': 462, 'colsample_bytree': 0.6232717406857644, 'learning_rate': 0.020794981046136155}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:53:29,379]\u001b[0m Trial 113 finished with value: 0.6926790024135157 and parameters: {'min_child_weight': 0.3471744646598277, 'subsample': 0.6455309115320084, 'max_depth': 6, 'reg_lambda': 4.660470817499533, 'reg_alpha': 0.39910904169979533, 'num_leaves': 412, 'colsample_bytree': 0.681077525710315, 'learning_rate': 0.024673564184996867}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:53:39,413]\u001b[0m Trial 114 finished with value: 0.6921962992759454 and parameters: {'min_child_weight': 0.4099538432168183, 'subsample': 0.6230326090478849, 'max_depth': 5, 'reg_lambda': 4.391866005129081, 'reg_alpha': 0.8526069513009478, 'num_leaves': 493, 'colsample_bytree': 0.6480152811931887, 'learning_rate': 0.014012138131298525}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:53:45,021]\u001b[0m Trial 115 finished with value: 0.6791633145615446 and parameters: {'min_child_weight': 0.5656648853400768, 'subsample': 0.612928373399779, 'max_depth': 3, 'reg_lambda': 3.5143811022825435, 'reg_alpha': 1.2742200033761868, 'num_leaves': 422, 'colsample_bytree': 0.6664875246370193, 'learning_rate': 0.00640452272582864}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:53:55,184]\u001b[0m Trial 116 finished with value: 0.6954143201930811 and parameters: {'min_child_weight': 0.4988136671121361, 'subsample': 0.6341684253808458, 'max_depth': 5, 'reg_lambda': 3.7728542876345488, 'reg_alpha': 1.3918407874072765, 'num_leaves': 375, 'colsample_bytree': 0.7095623620130831, 'learning_rate': 0.01766958216533703}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:54:01,676]\u001b[0m Trial 117 finished with value: 0.6949316170555109 and parameters: {'min_child_weight': 0.5933562014091671, 'subsample': 0.8823469041058614, 'max_depth': 4, 'reg_lambda': 4.432337299990808, 'reg_alpha': 4.805651950988427, 'num_leaves': 393, 'colsample_bytree': 0.59557022980288, 'learning_rate': 0.028375235940828965}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:54:11,980]\u001b[0m Trial 118 finished with value: 0.6950925181013676 and parameters: {'min_child_weight': 0.5195810291477309, 'subsample': 0.6503660150879906, 'max_depth': 5, 'reg_lambda': 3.919971673863412, 'reg_alpha': 1.5378653390830563, 'num_leaves': 346, 'colsample_bytree': 0.7008732198580407, 'learning_rate': 0.04624397663627876}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:54:17,355]\u001b[0m Trial 119 finished with value: 0.6970233306516492 and parameters: {'min_child_weight': 0.3871190242134016, 'subsample': 0.6379608555017096, 'max_depth': 3, 'reg_lambda': 4.923672294106961, 'reg_alpha': 1.7608021887872933, 'num_leaves': 182, 'colsample_bytree': 0.6310589125300777, 'learning_rate': 0.03280440142889397}. Best is trial 103 with value: 0.6979887369267901.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:54:22,591]\u001b[0m Trial 120 finished with value: 0.6991150442477877 and parameters: {'min_child_weight': 0.27347948901122066, 'subsample': 0.6407551065997926, 'max_depth': 3, 'reg_lambda': 5.002995161984543, 'reg_alpha': 4.580722182566561, 'num_leaves': 244, 'colsample_bytree': 0.5650106649806554, 'learning_rate': 0.03664915979858746}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:54:27,492]\u001b[0m Trial 121 finished with value: 0.6952534191472244 and parameters: {'min_child_weight': 0.3763872391105951, 'subsample': 0.6443959838081352, 'max_depth': 3, 'reg_lambda': 4.829367780689688, 'reg_alpha': 1.8592625184254823, 'num_leaves': 217, 'colsample_bytree': 0.5039138480305155, 'learning_rate': 0.03983040260324465}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:54:38,049]\u001b[0m Trial 122 finished with value: 0.6912308930008045 and parameters: {'min_child_weight': 0.26117463326162, 'subsample': 0.8472300684281187, 'max_depth': 6, 'reg_lambda': 4.986158532314108, 'reg_alpha': 4.6078565880364035, 'num_leaves': 262, 'colsample_bytree': 0.5621204792461036, 'learning_rate': 0.03301089732549589}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:54:44,882]\u001b[0m Trial 123 finished with value: 0.6928399034593724 and parameters: {'min_child_weight': 0.17090348034218517, 'subsample': 0.6199082824563854, 'max_depth': 4, 'reg_lambda': 4.2000297027546365, 'reg_alpha': 4.690711261505438, 'num_leaves': 245, 'colsample_bytree': 0.6298283476542729, 'learning_rate': 0.028806217049149693}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:54:49,799]\u001b[0m Trial 124 finished with value: 0.6944489139179405 and parameters: {'min_child_weight': 0.2993508371583958, 'subsample': 0.661205910710721, 'max_depth': 3, 'reg_lambda': 5.562821397103829, 'reg_alpha': 4.467298921214657, 'num_leaves': 198, 'colsample_bytree': 0.5732289183375858, 'learning_rate': 0.05879492707089403}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:54:56,777]\u001b[0m Trial 125 finished with value: 0.694770716009654 and parameters: {'min_child_weight': 0.5732943117027027, 'subsample': 0.6376000897686295, 'max_depth': 4, 'reg_lambda': 5.172000955475282, 'reg_alpha': 4.904986758260412, 'num_leaves': 225, 'colsample_bytree': 0.6070675125750398, 'learning_rate': 0.02299539382489754}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:55:05,234]\u001b[0m Trial 126 finished with value: 0.678841512469831 and parameters: {'min_child_weight': 0.3266697256953484, 'subsample': 0.6087104920718176, 'max_depth': 12, 'reg_lambda': 4.5175287433924, 'reg_alpha': 4.392601362098854, 'num_leaves': 276, 'colsample_bytree': 0.22534783634745703, 'learning_rate': 0.03577929004851}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:55:10,402]\u001b[0m Trial 127 finished with value: 0.697184231697506 and parameters: {'min_child_weight': 0.5477365051202918, 'subsample': 0.6275875848352097, 'max_depth': 3, 'reg_lambda': 5.035176147979843, 'reg_alpha': 4.543286037809208, 'num_leaves': 188, 'colsample_bytree': 0.6548491576026317, 'learning_rate': 0.04395249811776103}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:55:19,715]\u001b[0m Trial 128 finished with value: 0.69396621078037 and parameters: {'min_child_weight': 0.5505442257302439, 'subsample': 0.6248316490203484, 'max_depth': 5, 'reg_lambda': 5.028062565093537, 'reg_alpha': 4.549753691757598, 'num_leaves': 177, 'colsample_bytree': 0.6564295541545836, 'learning_rate': 0.06830596015572439}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:55:26,763]\u001b[0m Trial 129 finished with value: 0.6965406275140789 and parameters: {'min_child_weight': 0.616722993021562, 'subsample': 0.6507313633836564, 'max_depth': 4, 'reg_lambda': 5.352390739531636, 'reg_alpha': 4.995816916338794, 'num_leaves': 192, 'colsample_bytree': 0.6317099222616772, 'learning_rate': 0.04900276232790535}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:55:43,297]\u001b[0m Trial 130 finished with value: 0.6902654867256637 and parameters: {'min_child_weight': 0.6048481088479999, 'subsample': 0.6564788301396671, 'max_depth': 15, 'reg_lambda': 4.692382999126255, 'reg_alpha': 4.958332730127916, 'num_leaves': 156, 'colsample_bytree': 0.6769384896248732, 'learning_rate': 0.046158883575441415}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:55:50,359]\u001b[0m Trial 131 finished with value: 0.6944489139179405 and parameters: {'min_child_weight': 0.6126184717351895, 'subsample': 0.6003644667850515, 'max_depth': 4, 'reg_lambda': 5.435385855874964, 'reg_alpha': 4.72366150952859, 'num_leaves': 187, 'colsample_bytree': 0.6393797146376247, 'learning_rate': 0.053690357325439225}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:55:55,523]\u001b[0m Trial 132 finished with value: 0.6923572003218021 and parameters: {'min_child_weight': 0.6264912462773818, 'subsample': 0.6512032540647291, 'max_depth': 3, 'reg_lambda': 4.283491027773924, 'reg_alpha': 4.853529684386991, 'num_leaves': 172, 'colsample_bytree': 0.6163761841699609, 'learning_rate': 0.08610853192495797}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:56:00,942]\u001b[0m Trial 133 finished with value: 0.6975060337892195 and parameters: {'min_child_weight': 0.5334952845317108, 'subsample': 0.6279915974806696, 'max_depth': 3, 'reg_lambda': 5.35540432744022, 'reg_alpha': 4.769136034821303, 'num_leaves': 197, 'colsample_bytree': 0.664276758858065, 'learning_rate': 0.040009354994115974}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:56:06,577]\u001b[0m Trial 134 finished with value: 0.6962188254223652 and parameters: {'min_child_weight': 0.5491528468465967, 'subsample': 0.6128888348779719, 'max_depth': 3, 'reg_lambda': 5.7195945649938515, 'reg_alpha': 4.986008324643781, 'num_leaves': 191, 'colsample_bytree': 0.7365035448263673, 'learning_rate': 0.03887633160577769}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:56:12,116]\u001b[0m Trial 135 finished with value: 0.6970233306516492 and parameters: {'min_child_weight': 0.5335432426402197, 'subsample': 0.6171432154599341, 'max_depth': 3, 'reg_lambda': 4.864671116167837, 'reg_alpha': 4.964379649566946, 'num_leaves': 207, 'colsample_bytree': 0.7264021592809964, 'learning_rate': 0.040852022271277114}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:56:17,942]\u001b[0m Trial 136 finished with value: 0.6973451327433627 and parameters: {'min_child_weight': 0.5188841796875784, 'subsample': 0.6169799146074846, 'max_depth': 3, 'reg_lambda': 4.887860806015519, 'reg_alpha': 4.949768985877657, 'num_leaves': 227, 'colsample_bytree': 0.749757794280365, 'learning_rate': 0.04080573646647043}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:56:23,655]\u001b[0m Trial 137 finished with value: 0.6962188254223651 and parameters: {'min_child_weight': 0.4642434770134174, 'subsample': 0.6157909989255334, 'max_depth': 3, 'reg_lambda': 4.917952964582342, 'reg_alpha': 4.989852951714519, 'num_leaves': 230, 'colsample_bytree': 0.7418184076655056, 'learning_rate': 0.049471473949726556}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:56:31,452]\u001b[0m Trial 138 finished with value: 0.69396621078037 and parameters: {'min_child_weight': 0.4925440889328551, 'subsample': 0.6191221626350669, 'max_depth': 4, 'reg_lambda': 5.1975492865246125, 'reg_alpha': 4.796561199493986, 'num_leaves': 200, 'colsample_bytree': 0.7257709630525692, 'learning_rate': 0.06437574146358134}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:56:41,133]\u001b[0m Trial 139 finished with value: 0.69396621078037 and parameters: {'min_child_weight': 0.5298315721521848, 'subsample': 0.6430933882571824, 'max_depth': 5, 'reg_lambda': 5.663891048401439, 'reg_alpha': 4.924998859070732, 'num_leaves': 215, 'colsample_bytree': 0.6924875858447616, 'learning_rate': 0.074944434185073}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:56:46,400]\u001b[0m Trial 140 finished with value: 0.6949316170555109 and parameters: {'min_child_weight': 0.5459728941245987, 'subsample': 0.6286954347113336, 'max_depth': 3, 'reg_lambda': 1.8770841018301088, 'reg_alpha': 4.64022308308586, 'num_leaves': 245, 'colsample_bytree': 0.6231505061419919, 'learning_rate': 0.11856495541625932}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:56:52,097]\u001b[0m Trial 141 finished with value: 0.6967015285599357 and parameters: {'min_child_weight': 0.4545557599817447, 'subsample': 0.6155131863312273, 'max_depth': 3, 'reg_lambda': 4.7355139218441895, 'reg_alpha': 4.994270763194614, 'num_leaves': 191, 'colsample_bytree': 0.7401837756987916, 'learning_rate': 0.04844920182544072}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:56:58,076]\u001b[0m Trial 142 finished with value: 0.6962188254223652 and parameters: {'min_child_weight': 0.5090467427342346, 'subsample': 0.6114857370877613, 'max_depth': 3, 'reg_lambda': 4.767366624382999, 'reg_alpha': 4.993772660381146, 'num_leaves': 188, 'colsample_bytree': 0.7567805891010049, 'learning_rate': 0.03956104479483556}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:57:05,650]\u001b[0m Trial 143 finished with value: 0.6957361222847949 and parameters: {'min_child_weight': 0.4571435280771739, 'subsample': 0.6243120549718874, 'max_depth': 4, 'reg_lambda': 4.7701123383658075, 'reg_alpha': 4.775047174428456, 'num_leaves': 178, 'colsample_bytree': 0.7146978827711945, 'learning_rate': 0.031220491845267206}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:57:12,684]\u001b[0m Trial 144 finished with value: 0.6936444086886565 and parameters: {'min_child_weight': 0.49326738730594544, 'subsample': 0.6067924245457506, 'max_depth': 4, 'reg_lambda': 5.100919358477296, 'reg_alpha': 4.860421386748909, 'num_leaves': 209, 'colsample_bytree': 0.6629213629281774, 'learning_rate': 0.044789225381092715}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:57:18,514]\u001b[0m Trial 145 finished with value: 0.6975060337892197 and parameters: {'min_child_weight': 0.5865056295351665, 'subsample': 0.6173260327026049, 'max_depth': 3, 'reg_lambda': 4.6449234848363075, 'reg_alpha': 4.5568378424468605, 'num_leaves': 195, 'colsample_bytree': 0.7437703840981634, 'learning_rate': 0.05276375345079518}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:57:28,434]\u001b[0m Trial 146 finished with value: 0.6933226065969429 and parameters: {'min_child_weight': 0.3928949608808949, 'subsample': 0.6279757453408948, 'max_depth': 5, 'reg_lambda': 5.324408071865548, 'reg_alpha': 4.550399038345181, 'num_leaves': 219, 'colsample_bytree': 0.6864525358676096, 'learning_rate': 0.05365306430060839}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:57:33,565]\u001b[0m Trial 147 finished with value: 0.6968624296057925 and parameters: {'min_child_weight': 0.5840457060099394, 'subsample': 0.6392745659113241, 'max_depth': 3, 'reg_lambda': 4.864394700243007, 'reg_alpha': 4.709267628904027, 'num_leaves': 232, 'colsample_bytree': 0.5960434531026235, 'learning_rate': 0.06328687584414285}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:57:40,351]\u001b[0m Trial 148 finished with value: 0.6918744971842317 and parameters: {'min_child_weight': 0.578386217935889, 'subsample': 0.6426101341402866, 'max_depth': 4, 'reg_lambda': 4.511841395891646, 'reg_alpha': 4.707213585199659, 'num_leaves': 239, 'colsample_bytree': 0.5937537809002648, 'learning_rate': 0.10338958980184786}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:57:52,216]\u001b[0m Trial 149 finished with value: 0.6941271118262268 and parameters: {'min_child_weight': 0.5970598093073518, 'subsample': 0.6633502062909883, 'max_depth': 6, 'reg_lambda': 4.895089237402462, 'reg_alpha': 4.602945907664974, 'num_leaves': 202, 'colsample_bytree': 0.6364559433924877, 'learning_rate': 0.07833687902375229}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:57:58,184]\u001b[0m Trial 150 finished with value: 0.6976669348350765 and parameters: {'min_child_weight': 0.2741271002232913, 'subsample': 0.6493938919349969, 'max_depth': 3, 'reg_lambda': 5.279176340019765, 'reg_alpha': 4.4829815142095155, 'num_leaves': 253, 'colsample_bytree': 0.7794117755778843, 'learning_rate': 0.06390256347659333}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:58:04,218]\u001b[0m Trial 151 finished with value: 0.6933226065969429 and parameters: {'min_child_weight': 0.20124569919741508, 'subsample': 0.6503507273973599, 'max_depth': 3, 'reg_lambda': 5.252609732468479, 'reg_alpha': 4.4829932671690935, 'num_leaves': 250, 'colsample_bytree': 0.7824949737695492, 'learning_rate': 0.06391299287296393}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:58:10,055]\u001b[0m Trial 152 finished with value: 0.6923572003218021 and parameters: {'min_child_weight': 0.5237099989638767, 'subsample': 0.6375705431507349, 'max_depth': 3, 'reg_lambda': 4.633823121555517, 'reg_alpha': 4.371661969284218, 'num_leaves': 228, 'colsample_bytree': 0.7620490382944592, 'learning_rate': 0.14433148865676387}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:58:16,586]\u001b[0m Trial 153 finished with value: 0.6952534191472244 and parameters: {'min_child_weight': 0.5813719902123254, 'subsample': 0.6479102907231645, 'max_depth': 4, 'reg_lambda': 5.074910587219349, 'reg_alpha': 4.502779783530257, 'num_leaves': 147, 'colsample_bytree': 0.5742606753654393, 'learning_rate': 0.0537601075634014}. Best is trial 120 with value: 0.6991150442477877.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:58:26,157]\u001b[0m Trial 154 finished with value: 0.6995977473853581 and parameters: {'min_child_weight': 0.534047514075973, 'subsample': 0.6316705486384242, 'max_depth': 5, 'reg_lambda': 5.4130017942167665, 'reg_alpha': 4.741561203592908, 'num_leaves': 194, 'colsample_bytree': 0.725714617307935, 'learning_rate': 0.03366464571120959}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:58:35,752]\u001b[0m Trial 155 finished with value: 0.6954143201930811 and parameters: {'min_child_weight': 0.2673164135380822, 'subsample': 0.6313704518861941, 'max_depth': 5, 'reg_lambda': 4.872151453836096, 'reg_alpha': 4.769704840444491, 'num_leaves': 236, 'colsample_bytree': 0.725761730601148, 'learning_rate': 0.03391838634448358}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:58:41,185]\u001b[0m Trial 156 finished with value: 0.697184231697506 and parameters: {'min_child_weight': 0.27444176635647255, 'subsample': 0.6198030485155465, 'max_depth': 3, 'reg_lambda': 4.370041624615796, 'reg_alpha': 4.680075620710626, 'num_leaves': 208, 'colsample_bytree': 0.704592641990704, 'learning_rate': 0.029444203322408075}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:58:46,929]\u001b[0m Trial 157 finished with value: 0.6976669348350765 and parameters: {'min_child_weight': 0.2776778364158095, 'subsample': 0.619880009630828, 'max_depth': 3, 'reg_lambda': 4.329602457233782, 'reg_alpha': 4.684278606378147, 'num_leaves': 168, 'colsample_bytree': 0.7527500896816, 'learning_rate': 0.02710115875186855}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:58:52,809]\u001b[0m Trial 158 finished with value: 0.6965406275140789 and parameters: {'min_child_weight': 0.2736912066314296, 'subsample': 0.6211167066740252, 'max_depth': 3, 'reg_lambda': 4.320269163181106, 'reg_alpha': 4.649302494603367, 'num_leaves': 164, 'colsample_bytree': 0.7839494257765663, 'learning_rate': 0.027879215279027026}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:59:02,562]\u001b[0m Trial 159 finished with value: 0.6938053097345133 and parameters: {'min_child_weight': 0.24153480458827223, 'subsample': 0.6386756067644781, 'max_depth': 5, 'reg_lambda': 4.1582947988953665, 'reg_alpha': 4.557780842237988, 'num_leaves': 211, 'colsample_bytree': 0.7496686997898189, 'learning_rate': 0.03312095466037011}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:59:09,714]\u001b[0m Trial 160 finished with value: 0.6965406275140789 and parameters: {'min_child_weight': 0.23316180480506343, 'subsample': 0.6276048026746828, 'max_depth': 4, 'reg_lambda': 4.554616732522199, 'reg_alpha': 4.766279503028869, 'num_leaves': 218, 'colsample_bytree': 0.7040825349968849, 'learning_rate': 0.026323748227823473}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:59:15,328]\u001b[0m Trial 161 finished with value: 0.6975060337892196 and parameters: {'min_child_weight': 0.32365825956577005, 'subsample': 0.617315135704448, 'max_depth': 3, 'reg_lambda': 4.76145395718968, 'reg_alpha': 4.680242563911268, 'num_leaves': 181, 'colsample_bytree': 0.746290283324733, 'learning_rate': 0.04262905793727729}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:59:21,098]\u001b[0m Trial 162 finished with value: 0.6955752212389381 and parameters: {'min_child_weight': 0.2886685382574336, 'subsample': 0.6221567785466311, 'max_depth': 3, 'reg_lambda': 5.061216856425782, 'reg_alpha': 4.6426173047007335, 'num_leaves': 201, 'colsample_bytree': 0.7700333623599658, 'learning_rate': 0.04013612750440708}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:59:26,668]\u001b[0m Trial 163 finished with value: 0.6926790024135157 and parameters: {'min_child_weight': 0.32652603951793313, 'subsample': 0.6327939299140806, 'max_depth': 3, 'reg_lambda': 4.40270290195315, 'reg_alpha': 4.834664087797313, 'num_leaves': 254, 'colsample_bytree': 0.7137802595825746, 'learning_rate': 0.0612706656975941}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:59:34,374]\u001b[0m Trial 164 finished with value: 0.6936444086886564 and parameters: {'min_child_weight': 0.3063173286997801, 'subsample': 0.6219113484018367, 'max_depth': 4, 'reg_lambda': 4.614530152708367, 'reg_alpha': 4.701378798051404, 'num_leaves': 178, 'colsample_bytree': 0.754203307190241, 'learning_rate': 0.08660708105147438}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:59:39,972]\u001b[0m Trial 165 finished with value: 0.6960579243765084 and parameters: {'min_child_weight': 0.36764049567525814, 'subsample': 0.6162703509762123, 'max_depth': 3, 'reg_lambda': 4.8558649756219046, 'reg_alpha': 4.411219235868602, 'num_leaves': 226, 'colsample_bytree': 0.7243914947970885, 'learning_rate': 0.03122421922730789}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:59:49,561]\u001b[0m Trial 166 finished with value: 0.6946098149637973 and parameters: {'min_child_weight': 0.20017597585313274, 'subsample': 0.6399053308195571, 'max_depth': 5, 'reg_lambda': 5.458937181956427, 'reg_alpha': 4.29058809676603, 'num_leaves': 171, 'colsample_bytree': 0.6973433200207071, 'learning_rate': 0.037676063216603176}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 11:59:57,345]\u001b[0m Trial 167 finished with value: 0.69396621078037 and parameters: {'min_child_weight': 0.2483973031856243, 'subsample': 0.6083485147720122, 'max_depth': 4, 'reg_lambda': 5.203151094890005, 'reg_alpha': 4.590347235879619, 'num_leaves': 207, 'colsample_bytree': 0.7954663694662374, 'learning_rate': 0.026677089662219763}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:00:02,260]\u001b[0m Trial 168 finished with value: 0.6958970233306516 and parameters: {'min_child_weight': 0.3155401487256799, 'subsample': 0.6319674750723642, 'max_depth': 3, 'reg_lambda': 4.489226076811507, 'reg_alpha': 4.470955252943842, 'num_leaves': 270, 'colsample_bytree': 0.5463420045313714, 'learning_rate': 0.04504846178331977}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:00:09,470]\u001b[0m Trial 169 finished with value: 0.6942880128720837 and parameters: {'min_child_weight': 0.2791914528362855, 'subsample': 0.6162723815321118, 'max_depth': 4, 'reg_lambda': 4.107910043896501, 'reg_alpha': 4.781084892997848, 'num_leaves': 238, 'colsample_bytree': 0.6550884862588029, 'learning_rate': 0.06713282223106583}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:00:14,813]\u001b[0m Trial 170 finished with value: 0.6970233306516492 and parameters: {'min_child_weight': 0.344520026477915, 'subsample': 0.6430662391289277, 'max_depth': 3, 'reg_lambda': 5.0206482020993874, 'reg_alpha': 4.671240499977897, 'num_leaves': 289, 'colsample_bytree': 0.6808027151004552, 'learning_rate': 0.032444943524968}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:00:20,121]\u001b[0m Trial 171 finished with value: 0.6965406275140789 and parameters: {'min_child_weight': 0.36166793391587365, 'subsample': 0.642138485506069, 'max_depth': 3, 'reg_lambda': 5.022956581434564, 'reg_alpha': 4.69582218086228, 'num_leaves': 295, 'colsample_bytree': 0.6781795721535953, 'learning_rate': 0.03327343833184216}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:00:27,474]\u001b[0m Trial 172 finished with value: 0.6941271118262269 and parameters: {'min_child_weight': 0.34139919384460576, 'subsample': 0.6268781009428405, 'max_depth': 4, 'reg_lambda': 4.763770959212147, 'reg_alpha': 4.566217450717979, 'num_leaves': 186, 'colsample_bytree': 0.7353011475606261, 'learning_rate': 0.024635747324586378}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:00:32,974]\u001b[0m Trial 173 finished with value: 0.697184231697506 and parameters: {'min_child_weight': 0.5403169357141333, 'subsample': 0.658574193199736, 'max_depth': 3, 'reg_lambda': 5.285166361709645, 'reg_alpha': 4.83424450617387, 'num_leaves': 159, 'colsample_bytree': 0.7043665151728578, 'learning_rate': 0.04540559607626545}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:00:38,620]\u001b[0m Trial 174 finished with value: 0.6970233306516492 and parameters: {'min_child_weight': 0.5326422193048352, 'subsample': 0.6566665887037549, 'max_depth': 3, 'reg_lambda': 5.3361905968487635, 'reg_alpha': 4.902342815069574, 'num_leaves': 162, 'colsample_bytree': 0.7099630192625586, 'learning_rate': 0.04229341406926411}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:00:46,021]\u001b[0m Trial 175 finished with value: 0.6946098149637973 and parameters: {'min_child_weight': 0.5238983074100049, 'subsample': 0.6000218324662892, 'max_depth': 4, 'reg_lambda': 5.522777220145089, 'reg_alpha': 4.8982137658183325, 'num_leaves': 163, 'colsample_bytree': 0.7099799799463477, 'learning_rate': 0.044027390076619974}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:00:55,410]\u001b[0m Trial 176 finished with value: 0.6930008045052294 and parameters: {'min_child_weight': 0.22112447768585813, 'subsample': 0.6591931668052443, 'max_depth': 5, 'reg_lambda': 5.301197691114936, 'reg_alpha': 4.830610438766372, 'num_leaves': 152, 'colsample_bytree': 0.6957910277268395, 'learning_rate': 0.03847265476868707}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:01:01,217]\u001b[0m Trial 177 finished with value: 0.6957361222847949 and parameters: {'min_child_weight': 0.5413197835764308, 'subsample': 0.6620619790217152, 'max_depth': 3, 'reg_lambda': 5.612955611239834, 'reg_alpha': 4.863176078930942, 'num_leaves': 141, 'colsample_bytree': 0.7636866808984765, 'learning_rate': 0.054147593172453955}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:01:08,515]\u001b[0m Trial 178 finished with value: 0.6960579243765084 and parameters: {'min_child_weight': 0.28562147024281076, 'subsample': 0.6315027692527472, 'max_depth': 4, 'reg_lambda': 5.092986020870422, 'reg_alpha': 4.4872170759342085, 'num_leaves': 180, 'colsample_bytree': 0.6848874710621956, 'learning_rate': 0.030884871204845697}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:01:14,076]\u001b[0m Trial 179 finished with value: 0.697184231697506 and parameters: {'min_child_weight': 0.5047356079691072, 'subsample': 0.6201992906650426, 'max_depth': 3, 'reg_lambda': 5.966629881010691, 'reg_alpha': 4.797073395493314, 'num_leaves': 196, 'colsample_bytree': 0.7281263960489035, 'learning_rate': 0.043483379461030876}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:01:26,034]\u001b[0m Trial 180 finished with value: 0.6928399034593724 and parameters: {'min_child_weight': 0.5638285604812043, 'subsample': 0.6094254133524372, 'max_depth': 6, 'reg_lambda': 5.9102396209191586, 'reg_alpha': 4.624165800883681, 'num_leaves': 212, 'colsample_bytree': 0.7398187968265969, 'learning_rate': 0.024617626724527792}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:01:31,597]\u001b[0m Trial 181 finished with value: 0.6973451327433627 and parameters: {'min_child_weight': 0.505645737471505, 'subsample': 0.6223055771443984, 'max_depth': 3, 'reg_lambda': 5.312808849930219, 'reg_alpha': 4.784782394591499, 'num_leaves': 167, 'colsample_bytree': 0.7219002711501515, 'learning_rate': 0.04399446845112256}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:01:39,709]\u001b[0m Trial 182 finished with value: 0.6949316170555109 and parameters: {'min_child_weight': 0.498335262379471, 'subsample': 0.6246711243326509, 'max_depth': 4, 'reg_lambda': 5.371246428183543, 'reg_alpha': 2.27597686628431, 'num_leaves': 168, 'colsample_bytree': 0.7497802518180022, 'learning_rate': 0.04772467928703382}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:01:45,730]\u001b[0m Trial 183 finished with value: 0.694770716009654 and parameters: {'min_child_weight': 0.5153976790633737, 'subsample': 0.6161903422626466, 'max_depth': 3, 'reg_lambda': 5.182628144897119, 'reg_alpha': 4.789244717502622, 'num_leaves': 129, 'colsample_bytree': 0.724831575143428, 'learning_rate': 0.043182003566202894}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:01:51,277]\u001b[0m Trial 184 finished with value: 0.6984714400643603 and parameters: {'min_child_weight': 0.5559061403430051, 'subsample': 0.648684196752638, 'max_depth': 3, 'reg_lambda': 5.73111177843321, 'reg_alpha': 4.682717000726463, 'num_leaves': 160, 'colsample_bytree': 0.7072281955442387, 'learning_rate': 0.028790722187981344}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:01:58,300]\u001b[0m Trial 185 finished with value: 0.6933226065969429 and parameters: {'min_child_weight': 0.5632243016022186, 'subsample': 0.6485210607817389, 'max_depth': 4, 'reg_lambda': 5.976186442074503, 'reg_alpha': 4.666726085472518, 'num_leaves': 197, 'colsample_bytree': 0.6819842646725529, 'learning_rate': 0.02777240682596445}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:02:07,808]\u001b[0m Trial 186 finished with value: 0.6978278358809332 and parameters: {'min_child_weight': 0.4811140525038941, 'subsample': 0.6686425179772533, 'max_depth': 5, 'reg_lambda': 5.7262110016868775, 'reg_alpha': 4.781373052824173, 'num_leaves': 157, 'colsample_bytree': 0.7109435487493656, 'learning_rate': 0.03699579039068885}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:02:17,602]\u001b[0m Trial 187 finished with value: 0.6931617055510861 and parameters: {'min_child_weight': 0.5468168341023187, 'subsample': 0.6285371639348036, 'max_depth': 5, 'reg_lambda': 6.0991146682329695, 'reg_alpha': 4.357059265007392, 'num_leaves': 145, 'colsample_bytree': 0.7693542855923298, 'learning_rate': 0.023235865720375996}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:02:24,872]\u001b[0m Trial 188 finished with value: 0.6957361222847949 and parameters: {'min_child_weight': 0.487867258880443, 'subsample': 0.6446141825581999, 'max_depth': 4, 'reg_lambda': 5.773065044277212, 'reg_alpha': 4.74332133422439, 'num_leaves': 156, 'colsample_bytree': 0.7054501865173988, 'learning_rate': 0.03579163464364355}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:02:30,968]\u001b[0m Trial 189 finished with value: 0.6915526950925182 and parameters: {'min_child_weight': 0.4289485493919061, 'subsample': 0.6338779409420806, 'max_depth': 3, 'reg_lambda': 5.642734990396319, 'reg_alpha': 4.532542702829286, 'num_leaves': 118, 'colsample_bytree': 0.805662139122284, 'learning_rate': 0.05421886625468882}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:02:38,801]\u001b[0m Trial 190 finished with value: 0.6952534191472244 and parameters: {'min_child_weight': 0.5035036464485925, 'subsample': 0.9872433554509585, 'max_depth': 4, 'reg_lambda': 5.79668183890042, 'reg_alpha': 4.785122707663636, 'num_leaves': 181, 'colsample_bytree': 0.7372688644545893, 'learning_rate': 0.07546839608105992}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:02:44,164]\u001b[0m Trial 191 finished with value: 0.6986323411102172 and parameters: {'min_child_weight': 0.26366894214347564, 'subsample': 0.6645757802953141, 'max_depth': 3, 'reg_lambda': 5.084191917770978, 'reg_alpha': 4.61169588454552, 'num_leaves': 195, 'colsample_bytree': 0.6784492512660115, 'learning_rate': 0.029795993859642735}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:02:59,999]\u001b[0m Trial 192 finished with value: 0.6883346741753822 and parameters: {'min_child_weight': 0.22130969820849983, 'subsample': 0.6535099051742932, 'max_depth': 11, 'reg_lambda': 5.486018597594553, 'reg_alpha': 4.582084002632619, 'num_leaves': 172, 'colsample_bytree': 0.6662228262846657, 'learning_rate': 0.028229932198821573}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:03:05,606]\u001b[0m Trial 193 finished with value: 0.6941271118262268 and parameters: {'min_child_weight': 0.26700354003710475, 'subsample': 0.6691702134470057, 'max_depth': 3, 'reg_lambda': 5.24594061731544, 'reg_alpha': 4.406384553895334, 'num_leaves': 193, 'colsample_bytree': 0.7201457557157799, 'learning_rate': 0.03483067522451836}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:03:11,172]\u001b[0m Trial 194 finished with value: 0.6954143201930812 and parameters: {'min_child_weight': 0.567131919360928, 'subsample': 0.6824014932992599, 'max_depth': 3, 'reg_lambda': 6.31151696477946, 'reg_alpha': 4.613862435976296, 'num_leaves': 157, 'colsample_bytree': 0.694132045365918, 'learning_rate': 0.05460043531603403}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:03:26,999]\u001b[0m Trial 195 finished with value: 0.6936444086886564 and parameters: {'min_child_weight': 0.5323732860754764, 'subsample': 0.675303696307182, 'max_depth': 8, 'reg_lambda': 5.501526093019721, 'reg_alpha': 4.859974656439476, 'num_leaves': 162, 'colsample_bytree': 0.7135340057117491, 'learning_rate': 0.04248407787103593}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:03:33,885]\u001b[0m Trial 196 finished with value: 0.6949316170555109 and parameters: {'min_child_weight': 0.2961354091991704, 'subsample': 0.6226063620715039, 'max_depth': 4, 'reg_lambda': 4.658190846390037, 'reg_alpha': 4.734163728940954, 'num_leaves': 184, 'colsample_bytree': 0.6512155263783542, 'learning_rate': 0.028535970186816337}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:03:43,880]\u001b[0m Trial 197 finished with value: 0.693161705551086 and parameters: {'min_child_weight': 0.24873294490115383, 'subsample': 0.611569299240744, 'max_depth': 5, 'reg_lambda': 4.233771002319953, 'reg_alpha': 4.89231811160909, 'num_leaves': 202, 'colsample_bytree': 0.7499778817874274, 'learning_rate': 0.0386939832292877}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:03:49,615]\u001b[0m Trial 198 finished with value: 0.6960579243765086 and parameters: {'min_child_weight': 0.5152209811246098, 'subsample': 0.6661126807115156, 'max_depth': 3, 'reg_lambda': 5.37411312277231, 'reg_alpha': 4.777046525135055, 'num_leaves': 171, 'colsample_bytree': 0.7755907037725633, 'learning_rate': 0.04816824464449281}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 12:03:56,982]\u001b[0m Trial 199 finished with value: 0.6938053097345133 and parameters: {'min_child_weight': 0.47607126149638124, 'subsample': 0.6374505000277184, 'max_depth': 4, 'reg_lambda': 5.124058788853547, 'reg_alpha': 4.492048916808763, 'num_leaves': 219, 'colsample_bytree': 0.6936002558729584, 'learning_rate': 0.034869636123144004}. Best is trial 154 with value: 0.6995977473853581.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('linear_regression_RFE_selected_features.csv')\n",
    "selected_cols = features['features'].tolist()\n",
    "\n",
    "def objective(trial):    \n",
    "    min_child_weight = trial.suggest_float('min_child_weight', 1e-4, 1.0)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 32)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 1, 10)\n",
    "    reg_alpha = trial.suggest_float('reg_alpha', 0, 5),\n",
    "    num_leaves = trial.suggest_int('num_leaves', 2, 512)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.1, 1.0)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1.0, log=True)\n",
    "    \n",
    "    classifier_obj = lgb.LGBMClassifier(colsample_bytree=colsample_bytree,\n",
    "               learning_rate=learning_rate, max_depth=max_depth,\n",
    "               min_child_weight=min_child_weight, num_leaves=num_leaves,\n",
    "               random_state=23, reg_alpha=reg_alpha,\n",
    "               reg_lambda=reg_lambda, subsample=subsample)\n",
    "    \n",
    "    score = cross_val_score(classifier_obj, X_train, y_train, n_jobs=-1,\n",
    "                           cv=tscv, scoring='accuracy')\n",
    "    \n",
    "    \n",
    "    score_avg = score.mean()\n",
    "    \n",
    "    return score_avg\n",
    "\n",
    "study_name = '../models/hyperparameter_tuning/study_lgbc'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_lgbc = optuna.create_study(study_name = study_name, direction='maximize', \n",
    "                               storage = storage_name, load_if_exists=True)\n",
    "\n",
    "study_lgbc.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31823839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 0.7842585143470099\n",
      "val_acc: 0.6646045072912063\n",
      "LGBoost or XGBoost\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_name = '../models/hyperparameter_tuning/study_lgbc'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_lgbc = optuna.load_study(study_name = study_name, storage = storage_name)\n",
    "\n",
    "params = study_lgbc.best_params\n",
    "\n",
    "best_lgbc =  lgb.LGBMClassifier(**params)\n",
    "\n",
    "best_lgbc.fit(X_train, y_train)\n",
    "\n",
    "print(\"train_acc:\", best_lgbc.score(X_train, y_train))\n",
    "print(\"val_acc:\", best_lgbc.score(X_val, y_val))\n",
    "\n",
    "lgbc_features = view_model_coefs(best_lgbc, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8565e914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AWAY_AST_2PM_L10',\n",
       " 'AWAY_AST_2PM_L20',\n",
       " 'AWAY_AST_2PM_L5',\n",
       " 'AWAY_AST_2PM_opp_L10',\n",
       " 'AWAY_AST_2PM_opp_L20',\n",
       " 'AWAY_AST_2PM_opp_L5',\n",
       " 'AWAY_AST_3PM_L10',\n",
       " 'AWAY_AST_3PM_L20',\n",
       " 'AWAY_AST_3PM_L5',\n",
       " 'AWAY_AST_3PM_opp_L10',\n",
       " 'AWAY_AST_3PM_opp_L20',\n",
       " 'AWAY_AST_3PM_opp_L5',\n",
       " 'AWAY_AST_L10',\n",
       " 'AWAY_AST_L20',\n",
       " 'AWAY_AST_L5',\n",
       " 'AWAY_AST_RATIO_L10',\n",
       " 'AWAY_AST_RATIO_L20',\n",
       " 'AWAY_AST_RATIO_L5',\n",
       " 'AWAY_AST_RATIO_opp_L10',\n",
       " 'AWAY_AST_RATIO_opp_L20',\n",
       " 'AWAY_AST_RATIO_opp_L5',\n",
       " 'AWAY_AST_opp_L10',\n",
       " 'AWAY_AST_opp_L20',\n",
       " 'AWAY_AST_opp_L5',\n",
       " 'AWAY_AVG_ATS_DIFF_L10',\n",
       " 'AWAY_AVG_ATS_DIFF_L20',\n",
       " 'AWAY_AVG_ATS_DIFF_L5',\n",
       " 'AWAY_BLK_L10',\n",
       " 'AWAY_BLK_L20',\n",
       " 'AWAY_BLK_L5',\n",
       " 'AWAY_BLK_opp_L10',\n",
       " 'AWAY_BLK_opp_L20',\n",
       " 'AWAY_BLK_opp_L5',\n",
       " 'AWAY_CFGA_L10',\n",
       " 'AWAY_CFGA_L20',\n",
       " 'AWAY_CFGA_L5',\n",
       " 'AWAY_CFGA_opp_L10',\n",
       " 'AWAY_CFGA_opp_L20',\n",
       " 'AWAY_CFGA_opp_L5',\n",
       " 'AWAY_CFGM_L10',\n",
       " 'AWAY_CFGM_L20',\n",
       " 'AWAY_CFGM_L5',\n",
       " 'AWAY_CFGM_opp_L10',\n",
       " 'AWAY_CFGM_opp_L20',\n",
       " 'AWAY_CFGM_opp_L5',\n",
       " 'AWAY_COVER_PCT_L10',\n",
       " 'AWAY_COVER_PCT_L20',\n",
       " 'AWAY_COVER_PCT_L5',\n",
       " 'AWAY_DEF_RATING_L10',\n",
       " 'AWAY_DEF_RATING_L20',\n",
       " 'AWAY_DEF_RATING_L5',\n",
       " 'AWAY_DEF_RATING_opp_L10',\n",
       " 'AWAY_DEF_RATING_opp_L20',\n",
       " 'AWAY_DEF_RATING_opp_L5',\n",
       " 'AWAY_DFGA_L10',\n",
       " 'AWAY_DFGA_L20',\n",
       " 'AWAY_DFGA_L5',\n",
       " 'AWAY_DFGA_opp_L10',\n",
       " 'AWAY_DFGA_opp_L20',\n",
       " 'AWAY_DFGA_opp_L5',\n",
       " 'AWAY_DFGM_L10',\n",
       " 'AWAY_DFGM_L20',\n",
       " 'AWAY_DFGM_L5',\n",
       " 'AWAY_DFGM_opp_L10',\n",
       " 'AWAY_DFGM_opp_L20',\n",
       " 'AWAY_DFGM_opp_L5',\n",
       " 'AWAY_DIST_L10',\n",
       " 'AWAY_DIST_L20',\n",
       " 'AWAY_DIST_L5',\n",
       " 'AWAY_DIST_opp_L10',\n",
       " 'AWAY_DIST_opp_L20',\n",
       " 'AWAY_DIST_opp_L5',\n",
       " 'AWAY_DRBC_L10',\n",
       " 'AWAY_DRBC_L20',\n",
       " 'AWAY_DRBC_L5',\n",
       " 'AWAY_DRBC_opp_L10',\n",
       " 'AWAY_DRBC_opp_L20',\n",
       " 'AWAY_DRBC_opp_L5',\n",
       " 'AWAY_DREB_L10',\n",
       " 'AWAY_DREB_L20',\n",
       " 'AWAY_DREB_L5',\n",
       " 'AWAY_DREB_PCT_L10',\n",
       " 'AWAY_DREB_PCT_L20',\n",
       " 'AWAY_DREB_PCT_L5',\n",
       " 'AWAY_DREB_PCT_opp_L10',\n",
       " 'AWAY_DREB_PCT_opp_L20',\n",
       " 'AWAY_DREB_PCT_opp_L5',\n",
       " 'AWAY_DREB_opp_L10',\n",
       " 'AWAY_DREB_opp_L20',\n",
       " 'AWAY_DREB_opp_L5',\n",
       " 'AWAY_EFG_PCT_L10',\n",
       " 'AWAY_EFG_PCT_L20',\n",
       " 'AWAY_EFG_PCT_L5',\n",
       " 'AWAY_EFG_PCT_opp_L10',\n",
       " 'AWAY_EFG_PCT_opp_L20',\n",
       " 'AWAY_EFG_PCT_opp_L5',\n",
       " 'AWAY_FG2A_L10',\n",
       " 'AWAY_FG2A_L20',\n",
       " 'AWAY_FG2A_L5',\n",
       " 'AWAY_FG2A_opp_L10',\n",
       " 'AWAY_FG2A_opp_L20',\n",
       " 'AWAY_FG2A_opp_L5',\n",
       " 'AWAY_FG2M_L10',\n",
       " 'AWAY_FG2M_L20',\n",
       " 'AWAY_FG2M_L5',\n",
       " 'AWAY_FG2M_opp_L10',\n",
       " 'AWAY_FG2M_opp_L20',\n",
       " 'AWAY_FG2M_opp_L5',\n",
       " 'AWAY_FG3A_L10',\n",
       " 'AWAY_FG3A_L20',\n",
       " 'AWAY_FG3A_L5',\n",
       " 'AWAY_FG3A_opp_L10',\n",
       " 'AWAY_FG3A_opp_L20',\n",
       " 'AWAY_FG3A_opp_L5',\n",
       " 'AWAY_FG3M_L10',\n",
       " 'AWAY_FG3M_L20',\n",
       " 'AWAY_FG3M_L5',\n",
       " 'AWAY_FG3M_opp_L10',\n",
       " 'AWAY_FG3M_opp_L20',\n",
       " 'AWAY_FG3M_opp_L5',\n",
       " 'AWAY_FTAST_L10',\n",
       " 'AWAY_FTAST_L20',\n",
       " 'AWAY_FTAST_L5',\n",
       " 'AWAY_FTAST_opp_L10',\n",
       " 'AWAY_FTAST_opp_L20',\n",
       " 'AWAY_FTAST_opp_L5',\n",
       " 'AWAY_FTA_L10',\n",
       " 'AWAY_FTA_L20',\n",
       " 'AWAY_FTA_L5',\n",
       " 'AWAY_FTA_opp_L10',\n",
       " 'AWAY_FTA_opp_L20',\n",
       " 'AWAY_FTA_opp_L5',\n",
       " 'AWAY_FTM_L10',\n",
       " 'AWAY_FTM_L20',\n",
       " 'AWAY_FTM_L5',\n",
       " 'AWAY_FTM_opp_L10',\n",
       " 'AWAY_FTM_opp_L20',\n",
       " 'AWAY_FTM_opp_L5',\n",
       " 'AWAY_ML',\n",
       " 'AWAY_NET_RATING_L10',\n",
       " 'AWAY_NET_RATING_L20',\n",
       " 'AWAY_NET_RATING_L5',\n",
       " 'AWAY_NET_RATING_opp_L10',\n",
       " 'AWAY_NET_RATING_opp_L20',\n",
       " 'AWAY_NET_RATING_opp_L5',\n",
       " 'AWAY_OFF_RATING_L10',\n",
       " 'AWAY_OFF_RATING_L20',\n",
       " 'AWAY_OFF_RATING_L5',\n",
       " 'AWAY_OFF_RATING_opp_L10',\n",
       " 'AWAY_OFF_RATING_opp_L20',\n",
       " 'AWAY_OFF_RATING_opp_L5',\n",
       " 'AWAY_ORBC_L10',\n",
       " 'AWAY_ORBC_L20',\n",
       " 'AWAY_ORBC_L5',\n",
       " 'AWAY_ORBC_opp_L10',\n",
       " 'AWAY_ORBC_opp_L20',\n",
       " 'AWAY_ORBC_opp_L5',\n",
       " 'AWAY_OREB_L10',\n",
       " 'AWAY_OREB_L20',\n",
       " 'AWAY_OREB_L5',\n",
       " 'AWAY_OREB_PCT_L10',\n",
       " 'AWAY_OREB_PCT_L20',\n",
       " 'AWAY_OREB_PCT_L5',\n",
       " 'AWAY_OREB_PCT_opp_L10',\n",
       " 'AWAY_OREB_PCT_opp_L20',\n",
       " 'AWAY_OREB_PCT_opp_L5',\n",
       " 'AWAY_OREB_opp_L10',\n",
       " 'AWAY_OREB_opp_L20',\n",
       " 'AWAY_OREB_opp_L5',\n",
       " 'AWAY_PACE_L10',\n",
       " 'AWAY_PACE_L20',\n",
       " 'AWAY_PACE_L5',\n",
       " 'AWAY_PACE_opp_L10',\n",
       " 'AWAY_PACE_opp_L20',\n",
       " 'AWAY_PACE_opp_L5',\n",
       " 'AWAY_PASS_L10',\n",
       " 'AWAY_PASS_L20',\n",
       " 'AWAY_PASS_L5',\n",
       " 'AWAY_PASS_opp_L10',\n",
       " 'AWAY_PASS_opp_L20',\n",
       " 'AWAY_PASS_opp_L5',\n",
       " 'AWAY_PF_L10',\n",
       " 'AWAY_PF_L20',\n",
       " 'AWAY_PF_L5',\n",
       " 'AWAY_PF_opp_L10',\n",
       " 'AWAY_PF_opp_L20',\n",
       " 'AWAY_PF_opp_L5',\n",
       " 'AWAY_PIE_L10',\n",
       " 'AWAY_PIE_L20',\n",
       " 'AWAY_PIE_L5',\n",
       " 'AWAY_PLUS_MINUS_L10',\n",
       " 'AWAY_PLUS_MINUS_L20',\n",
       " 'AWAY_PLUS_MINUS_L5',\n",
       " 'AWAY_PLUS_MINUS_opp_L10',\n",
       " 'AWAY_PLUS_MINUS_opp_L20',\n",
       " 'AWAY_PLUS_MINUS_opp_L5',\n",
       " 'AWAY_POSS_L10',\n",
       " 'AWAY_POSS_L20',\n",
       " 'AWAY_POSS_L5',\n",
       " 'AWAY_POSS_opp_L10',\n",
       " 'AWAY_POSS_opp_L20',\n",
       " 'AWAY_POSS_opp_L5',\n",
       " 'AWAY_PTS_2PT_MR_L10',\n",
       " 'AWAY_PTS_2PT_MR_L20',\n",
       " 'AWAY_PTS_2PT_MR_L5',\n",
       " 'AWAY_PTS_2PT_MR_opp_L10',\n",
       " 'AWAY_PTS_2PT_MR_opp_L20',\n",
       " 'AWAY_PTS_2PT_MR_opp_L5',\n",
       " 'AWAY_PTS_FB_L10',\n",
       " 'AWAY_PTS_FB_L20',\n",
       " 'AWAY_PTS_FB_L5',\n",
       " 'AWAY_PTS_FB_opp_L10',\n",
       " 'AWAY_PTS_FB_opp_L20',\n",
       " 'AWAY_PTS_FB_opp_L5',\n",
       " 'AWAY_PTS_L10',\n",
       " 'AWAY_PTS_L20',\n",
       " 'AWAY_PTS_L5',\n",
       " 'AWAY_PTS_OFF_TOV_L10',\n",
       " 'AWAY_PTS_OFF_TOV_L20',\n",
       " 'AWAY_PTS_OFF_TOV_L5',\n",
       " 'AWAY_PTS_OFF_TOV_opp_L10',\n",
       " 'AWAY_PTS_OFF_TOV_opp_L20',\n",
       " 'AWAY_PTS_OFF_TOV_opp_L5',\n",
       " 'AWAY_PTS_PAINT_L10',\n",
       " 'AWAY_PTS_PAINT_L20',\n",
       " 'AWAY_PTS_PAINT_L5',\n",
       " 'AWAY_PTS_PAINT_opp_L10',\n",
       " 'AWAY_PTS_PAINT_opp_L20',\n",
       " 'AWAY_PTS_PAINT_opp_L5',\n",
       " 'AWAY_PTS_opp_L10',\n",
       " 'AWAY_PTS_opp_L20',\n",
       " 'AWAY_PTS_opp_L5',\n",
       " 'AWAY_RBC_L10',\n",
       " 'AWAY_RBC_L20',\n",
       " 'AWAY_RBC_L5',\n",
       " 'AWAY_RBC_opp_L10',\n",
       " 'AWAY_RBC_opp_L20',\n",
       " 'AWAY_RBC_opp_L5',\n",
       " 'AWAY_REB_L10',\n",
       " 'AWAY_REB_L20',\n",
       " 'AWAY_REB_L5',\n",
       " 'AWAY_REB_PCT_L10',\n",
       " 'AWAY_REB_PCT_L20',\n",
       " 'AWAY_REB_PCT_L5',\n",
       " 'AWAY_REB_PCT_opp_L10',\n",
       " 'AWAY_REB_PCT_opp_L20',\n",
       " 'AWAY_REB_PCT_opp_L5',\n",
       " 'AWAY_REB_opp_L10',\n",
       " 'AWAY_REB_opp_L20',\n",
       " 'AWAY_REB_opp_L5',\n",
       " 'AWAY_REST',\n",
       " 'AWAY_SAST_L10',\n",
       " 'AWAY_SAST_L20',\n",
       " 'AWAY_SAST_L5',\n",
       " 'AWAY_SAST_opp_L10',\n",
       " 'AWAY_SAST_opp_L20',\n",
       " 'AWAY_SAST_opp_L5',\n",
       " 'AWAY_STL_L10',\n",
       " 'AWAY_STL_L20',\n",
       " 'AWAY_STL_L5',\n",
       " 'AWAY_STL_opp_L10',\n",
       " 'AWAY_STL_opp_L20',\n",
       " 'AWAY_STL_opp_L5',\n",
       " 'AWAY_TCHS_L10',\n",
       " 'AWAY_TCHS_L20',\n",
       " 'AWAY_TCHS_L5',\n",
       " 'AWAY_TCHS_opp_L10',\n",
       " 'AWAY_TCHS_opp_L20',\n",
       " 'AWAY_TCHS_opp_L5',\n",
       " 'AWAY_TOV_L10',\n",
       " 'AWAY_TOV_L20',\n",
       " 'AWAY_TOV_L5',\n",
       " 'AWAY_TOV_PCT_L10',\n",
       " 'AWAY_TOV_PCT_L20',\n",
       " 'AWAY_TOV_PCT_L5',\n",
       " 'AWAY_TOV_PCT_opp_L10',\n",
       " 'AWAY_TOV_PCT_opp_L20',\n",
       " 'AWAY_TOV_PCT_opp_L5',\n",
       " 'AWAY_TOV_opp_L10',\n",
       " 'AWAY_TOV_opp_L20',\n",
       " 'AWAY_TOV_opp_L5',\n",
       " 'AWAY_TS_PCT_L10',\n",
       " 'AWAY_TS_PCT_L20',\n",
       " 'AWAY_TS_PCT_L5',\n",
       " 'AWAY_TS_PCT_opp_L10',\n",
       " 'AWAY_TS_PCT_opp_L20',\n",
       " 'AWAY_TS_PCT_opp_L5',\n",
       " 'AWAY_UAST_2PM_L10',\n",
       " 'AWAY_UAST_2PM_L20',\n",
       " 'AWAY_UAST_2PM_L5',\n",
       " 'AWAY_UAST_2PM_opp_L10',\n",
       " 'AWAY_UAST_2PM_opp_L20',\n",
       " 'AWAY_UAST_2PM_opp_L5',\n",
       " 'AWAY_UAST_3PM_L10',\n",
       " 'AWAY_UAST_3PM_L20',\n",
       " 'AWAY_UAST_3PM_L5',\n",
       " 'AWAY_UAST_3PM_opp_L10',\n",
       " 'AWAY_UAST_3PM_opp_L20',\n",
       " 'AWAY_UAST_3PM_opp_L5',\n",
       " 'AWAY_UFGA_L10',\n",
       " 'AWAY_UFGA_L20',\n",
       " 'AWAY_UFGA_L5',\n",
       " 'AWAY_UFGA_opp_L10',\n",
       " 'AWAY_UFGA_opp_L20',\n",
       " 'AWAY_UFGA_opp_L5',\n",
       " 'AWAY_UFGM_L10',\n",
       " 'AWAY_UFGM_L20',\n",
       " 'AWAY_UFGM_L5',\n",
       " 'AWAY_UFGM_opp_L10',\n",
       " 'AWAY_UFGM_opp_L20',\n",
       " 'AWAY_UFGM_opp_L5',\n",
       " 'AWAY_WIN_PCT_L10',\n",
       " 'AWAY_WIN_PCT_L20',\n",
       " 'AWAY_WIN_PCT_L5',\n",
       " 'HOME_AST_2PM_L10',\n",
       " 'HOME_AST_2PM_L20',\n",
       " 'HOME_AST_2PM_L5',\n",
       " 'HOME_AST_2PM_opp_L10',\n",
       " 'HOME_AST_2PM_opp_L20',\n",
       " 'HOME_AST_2PM_opp_L5',\n",
       " 'HOME_AST_3PM_L10',\n",
       " 'HOME_AST_3PM_L20',\n",
       " 'HOME_AST_3PM_L5',\n",
       " 'HOME_AST_3PM_opp_L10',\n",
       " 'HOME_AST_3PM_opp_L20',\n",
       " 'HOME_AST_3PM_opp_L5',\n",
       " 'HOME_AST_L10',\n",
       " 'HOME_AST_L20',\n",
       " 'HOME_AST_L5',\n",
       " 'HOME_AST_RATIO_L10',\n",
       " 'HOME_AST_RATIO_L20',\n",
       " 'HOME_AST_RATIO_L5',\n",
       " 'HOME_AST_RATIO_opp_L10',\n",
       " 'HOME_AST_RATIO_opp_L20',\n",
       " 'HOME_AST_RATIO_opp_L5',\n",
       " 'HOME_AST_opp_L10',\n",
       " 'HOME_AST_opp_L20',\n",
       " 'HOME_AST_opp_L5',\n",
       " 'HOME_AVG_ATS_DIFF_L10',\n",
       " 'HOME_AVG_ATS_DIFF_L20',\n",
       " 'HOME_AVG_ATS_DIFF_L5',\n",
       " 'HOME_BLK_L10',\n",
       " 'HOME_BLK_L20',\n",
       " 'HOME_BLK_L5',\n",
       " 'HOME_BLK_opp_L10',\n",
       " 'HOME_BLK_opp_L20',\n",
       " 'HOME_BLK_opp_L5',\n",
       " 'HOME_CFGA_L10',\n",
       " 'HOME_CFGA_L20',\n",
       " 'HOME_CFGA_L5',\n",
       " 'HOME_CFGA_opp_L10',\n",
       " 'HOME_CFGA_opp_L20',\n",
       " 'HOME_CFGA_opp_L5',\n",
       " 'HOME_CFGM_L10',\n",
       " 'HOME_CFGM_L20',\n",
       " 'HOME_CFGM_L5',\n",
       " 'HOME_CFGM_opp_L10',\n",
       " 'HOME_CFGM_opp_L20',\n",
       " 'HOME_CFGM_opp_L5',\n",
       " 'HOME_COVER_PCT_L10',\n",
       " 'HOME_COVER_PCT_L20',\n",
       " 'HOME_COVER_PCT_L5',\n",
       " 'HOME_DEF_RATING_L10',\n",
       " 'HOME_DEF_RATING_L20',\n",
       " 'HOME_DEF_RATING_L5',\n",
       " 'HOME_DEF_RATING_opp_L10',\n",
       " 'HOME_DEF_RATING_opp_L20',\n",
       " 'HOME_DEF_RATING_opp_L5',\n",
       " 'HOME_DFGA_L10',\n",
       " 'HOME_DFGA_L20',\n",
       " 'HOME_DFGA_L5',\n",
       " 'HOME_DFGA_opp_L10',\n",
       " 'HOME_DFGA_opp_L20',\n",
       " 'HOME_DFGA_opp_L5',\n",
       " 'HOME_DFGM_L10',\n",
       " 'HOME_DFGM_L20',\n",
       " 'HOME_DFGM_L5',\n",
       " 'HOME_DFGM_opp_L10',\n",
       " 'HOME_DFGM_opp_L20',\n",
       " 'HOME_DFGM_opp_L5',\n",
       " 'HOME_DIST_L10',\n",
       " 'HOME_DIST_L20',\n",
       " 'HOME_DIST_L5',\n",
       " 'HOME_DIST_opp_L10',\n",
       " 'HOME_DIST_opp_L20',\n",
       " 'HOME_DIST_opp_L5',\n",
       " 'HOME_DRBC_L10',\n",
       " 'HOME_DRBC_L20',\n",
       " 'HOME_DRBC_L5',\n",
       " 'HOME_DRBC_opp_L10',\n",
       " 'HOME_DRBC_opp_L20',\n",
       " 'HOME_DRBC_opp_L5',\n",
       " 'HOME_DREB_L10',\n",
       " 'HOME_DREB_L20',\n",
       " 'HOME_DREB_L5',\n",
       " 'HOME_DREB_PCT_L10',\n",
       " 'HOME_DREB_PCT_L20',\n",
       " 'HOME_DREB_PCT_L5',\n",
       " 'HOME_DREB_PCT_opp_L10',\n",
       " 'HOME_DREB_PCT_opp_L20',\n",
       " 'HOME_DREB_PCT_opp_L5',\n",
       " 'HOME_DREB_opp_L10',\n",
       " 'HOME_DREB_opp_L20',\n",
       " 'HOME_DREB_opp_L5',\n",
       " 'HOME_EFG_PCT_L10',\n",
       " 'HOME_EFG_PCT_L20',\n",
       " 'HOME_EFG_PCT_L5',\n",
       " 'HOME_EFG_PCT_opp_L10',\n",
       " 'HOME_EFG_PCT_opp_L20',\n",
       " 'HOME_EFG_PCT_opp_L5',\n",
       " 'HOME_FG2A_L10',\n",
       " 'HOME_FG2A_L20',\n",
       " 'HOME_FG2A_L5',\n",
       " 'HOME_FG2A_opp_L10',\n",
       " 'HOME_FG2A_opp_L20',\n",
       " 'HOME_FG2A_opp_L5',\n",
       " 'HOME_FG2M_L10',\n",
       " 'HOME_FG2M_L20',\n",
       " 'HOME_FG2M_L5',\n",
       " 'HOME_FG2M_opp_L10',\n",
       " 'HOME_FG2M_opp_L20',\n",
       " 'HOME_FG2M_opp_L5',\n",
       " 'HOME_FG3A_L10',\n",
       " 'HOME_FG3A_L20',\n",
       " 'HOME_FG3A_L5',\n",
       " 'HOME_FG3A_opp_L10',\n",
       " 'HOME_FG3A_opp_L20',\n",
       " 'HOME_FG3A_opp_L5',\n",
       " 'HOME_FG3M_L10',\n",
       " 'HOME_FG3M_L20',\n",
       " 'HOME_FG3M_L5',\n",
       " 'HOME_FG3M_opp_L10',\n",
       " 'HOME_FG3M_opp_L20',\n",
       " 'HOME_FG3M_opp_L5',\n",
       " 'HOME_FTAST_L10',\n",
       " 'HOME_FTAST_L20',\n",
       " 'HOME_FTAST_L5',\n",
       " 'HOME_FTAST_opp_L10',\n",
       " 'HOME_FTAST_opp_L20',\n",
       " 'HOME_FTAST_opp_L5',\n",
       " 'HOME_FTA_L10',\n",
       " 'HOME_FTA_L20',\n",
       " 'HOME_FTA_L5',\n",
       " 'HOME_FTA_opp_L10',\n",
       " 'HOME_FTA_opp_L20',\n",
       " 'HOME_FTA_opp_L5',\n",
       " 'HOME_FTM_L10',\n",
       " 'HOME_FTM_L20',\n",
       " 'HOME_FTM_L5',\n",
       " 'HOME_FTM_opp_L10',\n",
       " 'HOME_FTM_opp_L20',\n",
       " 'HOME_FTM_opp_L5',\n",
       " 'HOME_NET_RATING_L10',\n",
       " 'HOME_NET_RATING_L20',\n",
       " 'HOME_NET_RATING_L5',\n",
       " 'HOME_NET_RATING_opp_L10',\n",
       " 'HOME_NET_RATING_opp_L20',\n",
       " 'HOME_NET_RATING_opp_L5',\n",
       " 'HOME_OFF_RATING_L10',\n",
       " 'HOME_OFF_RATING_L20',\n",
       " 'HOME_OFF_RATING_L5',\n",
       " 'HOME_OFF_RATING_opp_L10',\n",
       " 'HOME_OFF_RATING_opp_L20',\n",
       " 'HOME_OFF_RATING_opp_L5',\n",
       " 'HOME_ORBC_L10',\n",
       " 'HOME_ORBC_L20',\n",
       " 'HOME_ORBC_L5',\n",
       " 'HOME_ORBC_opp_L10',\n",
       " 'HOME_ORBC_opp_L20',\n",
       " 'HOME_ORBC_opp_L5',\n",
       " 'HOME_OREB_L10',\n",
       " 'HOME_OREB_L20',\n",
       " 'HOME_OREB_L5',\n",
       " 'HOME_OREB_PCT_L10',\n",
       " 'HOME_OREB_PCT_L20',\n",
       " 'HOME_OREB_PCT_L5',\n",
       " 'HOME_OREB_PCT_opp_L10',\n",
       " 'HOME_OREB_PCT_opp_L20',\n",
       " 'HOME_OREB_PCT_opp_L5',\n",
       " 'HOME_OREB_opp_L10',\n",
       " 'HOME_OREB_opp_L20',\n",
       " 'HOME_OREB_opp_L5',\n",
       " 'HOME_PACE_L10',\n",
       " 'HOME_PACE_L20',\n",
       " 'HOME_PACE_L5',\n",
       " 'HOME_PACE_opp_L10',\n",
       " 'HOME_PACE_opp_L20',\n",
       " 'HOME_PACE_opp_L5',\n",
       " 'HOME_PASS_L10',\n",
       " 'HOME_PASS_L20',\n",
       " 'HOME_PASS_L5',\n",
       " 'HOME_PASS_opp_L10',\n",
       " 'HOME_PASS_opp_L20',\n",
       " 'HOME_PASS_opp_L5',\n",
       " 'HOME_PF_L10',\n",
       " 'HOME_PF_L20',\n",
       " 'HOME_PF_L5',\n",
       " 'HOME_PF_opp_L10',\n",
       " 'HOME_PF_opp_L20',\n",
       " 'HOME_PF_opp_L5',\n",
       " 'HOME_PIE_L10',\n",
       " 'HOME_PIE_L20',\n",
       " 'HOME_PIE_L5',\n",
       " 'HOME_PLUS_MINUS_L10',\n",
       " 'HOME_PLUS_MINUS_L20',\n",
       " 'HOME_PLUS_MINUS_L5',\n",
       " 'HOME_PLUS_MINUS_opp_L10',\n",
       " 'HOME_PLUS_MINUS_opp_L20',\n",
       " 'HOME_PLUS_MINUS_opp_L5',\n",
       " 'HOME_POSS_L10',\n",
       " 'HOME_POSS_L20',\n",
       " 'HOME_POSS_L5',\n",
       " 'HOME_POSS_opp_L10',\n",
       " 'HOME_POSS_opp_L20',\n",
       " 'HOME_POSS_opp_L5',\n",
       " 'HOME_PTS_2PT_MR_L10',\n",
       " 'HOME_PTS_2PT_MR_L20',\n",
       " 'HOME_PTS_2PT_MR_L5',\n",
       " 'HOME_PTS_2PT_MR_opp_L10',\n",
       " 'HOME_PTS_2PT_MR_opp_L20',\n",
       " 'HOME_PTS_2PT_MR_opp_L5',\n",
       " 'HOME_PTS_FB_L10',\n",
       " 'HOME_PTS_FB_L20',\n",
       " 'HOME_PTS_FB_L5',\n",
       " 'HOME_PTS_FB_opp_L10',\n",
       " 'HOME_PTS_FB_opp_L20',\n",
       " 'HOME_PTS_FB_opp_L5',\n",
       " 'HOME_PTS_L10',\n",
       " 'HOME_PTS_L20',\n",
       " 'HOME_PTS_L5',\n",
       " 'HOME_PTS_OFF_TOV_L10',\n",
       " 'HOME_PTS_OFF_TOV_L20',\n",
       " 'HOME_PTS_OFF_TOV_L5',\n",
       " 'HOME_PTS_OFF_TOV_opp_L10',\n",
       " 'HOME_PTS_OFF_TOV_opp_L20',\n",
       " 'HOME_PTS_OFF_TOV_opp_L5',\n",
       " 'HOME_PTS_PAINT_L10',\n",
       " 'HOME_PTS_PAINT_L20',\n",
       " 'HOME_PTS_PAINT_L5',\n",
       " 'HOME_PTS_PAINT_opp_L10',\n",
       " 'HOME_PTS_PAINT_opp_L20',\n",
       " 'HOME_PTS_PAINT_opp_L5',\n",
       " 'HOME_PTS_opp_L10',\n",
       " 'HOME_PTS_opp_L20',\n",
       " 'HOME_PTS_opp_L5',\n",
       " 'HOME_RBC_L10',\n",
       " 'HOME_RBC_L20',\n",
       " 'HOME_RBC_L5',\n",
       " 'HOME_RBC_opp_L10',\n",
       " 'HOME_RBC_opp_L20',\n",
       " 'HOME_RBC_opp_L5',\n",
       " 'HOME_REB_L10',\n",
       " 'HOME_REB_L20',\n",
       " 'HOME_REB_L5',\n",
       " 'HOME_REB_PCT_L10',\n",
       " 'HOME_REB_PCT_L20',\n",
       " 'HOME_REB_PCT_L5',\n",
       " 'HOME_REB_PCT_opp_L10',\n",
       " 'HOME_REB_PCT_opp_L20',\n",
       " 'HOME_REB_PCT_opp_L5',\n",
       " 'HOME_REB_opp_L10',\n",
       " 'HOME_REB_opp_L20',\n",
       " 'HOME_REB_opp_L5',\n",
       " 'HOME_REST',\n",
       " 'HOME_SAST_L10',\n",
       " 'HOME_SAST_L20',\n",
       " 'HOME_SAST_L5',\n",
       " 'HOME_SAST_opp_L10',\n",
       " 'HOME_SAST_opp_L20',\n",
       " 'HOME_SAST_opp_L5',\n",
       " 'HOME_STL_L10',\n",
       " 'HOME_STL_L20',\n",
       " 'HOME_STL_L5',\n",
       " 'HOME_STL_opp_L10',\n",
       " 'HOME_STL_opp_L20',\n",
       " 'HOME_STL_opp_L5',\n",
       " 'HOME_TCHS_L10',\n",
       " 'HOME_TCHS_L20',\n",
       " 'HOME_TCHS_L5',\n",
       " 'HOME_TCHS_opp_L10',\n",
       " 'HOME_TCHS_opp_L20',\n",
       " 'HOME_TCHS_opp_L5',\n",
       " 'HOME_TOV_L10',\n",
       " 'HOME_TOV_L20',\n",
       " 'HOME_TOV_L5',\n",
       " 'HOME_TOV_PCT_L10',\n",
       " 'HOME_TOV_PCT_L20',\n",
       " 'HOME_TOV_PCT_L5',\n",
       " 'HOME_TOV_PCT_opp_L10',\n",
       " 'HOME_TOV_PCT_opp_L20',\n",
       " 'HOME_TOV_PCT_opp_L5',\n",
       " 'HOME_TOV_opp_L10',\n",
       " 'HOME_TOV_opp_L20',\n",
       " 'HOME_TOV_opp_L5',\n",
       " 'HOME_TS_PCT_L10',\n",
       " 'HOME_TS_PCT_L20',\n",
       " 'HOME_TS_PCT_L5',\n",
       " 'HOME_TS_PCT_opp_L10',\n",
       " 'HOME_TS_PCT_opp_L20',\n",
       " 'HOME_TS_PCT_opp_L5',\n",
       " 'HOME_UAST_2PM_L10',\n",
       " 'HOME_UAST_2PM_L20',\n",
       " 'HOME_UAST_2PM_L5',\n",
       " 'HOME_UAST_2PM_opp_L10',\n",
       " 'HOME_UAST_2PM_opp_L20',\n",
       " 'HOME_UAST_2PM_opp_L5',\n",
       " 'HOME_UAST_3PM_L10',\n",
       " 'HOME_UAST_3PM_L20',\n",
       " 'HOME_UAST_3PM_L5',\n",
       " 'HOME_UAST_3PM_opp_L10',\n",
       " 'HOME_UAST_3PM_opp_L20',\n",
       " 'HOME_UAST_3PM_opp_L5',\n",
       " 'HOME_UFGA_L10',\n",
       " 'HOME_UFGA_L20',\n",
       " 'HOME_UFGA_L5',\n",
       " 'HOME_UFGA_opp_L10',\n",
       " 'HOME_UFGA_opp_L20',\n",
       " 'HOME_UFGA_opp_L5',\n",
       " 'HOME_UFGM_L10',\n",
       " 'HOME_UFGM_L20',\n",
       " 'HOME_UFGM_L5',\n",
       " 'HOME_UFGM_opp_L10',\n",
       " 'HOME_UFGM_opp_L20',\n",
       " 'HOME_UFGM_opp_L5',\n",
       " 'HOME_WIN_PCT_L10',\n",
       " 'HOME_WIN_PCT_L20',\n",
       " 'HOME_WIN_PCT_L5']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_dict(sfs_pipe.named_steps['sffs'].get_metric_dict()).T\n",
    "res.sort_values('avg_score', ascending=False)\n",
    "\n",
    "best_trial = res.sort_values('avg_score', ascending=False).index[0]\n",
    "\n",
    "feature_idx = [int(x) for x in res.loc[best_trial, 'feature_names']]\n",
    "sfs_selected_cols_sgd_log = X_train.iloc[:, feature_idx].columns\n",
    "sfs_selected_cols_sgd_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_dict(sfs_pipe.named_steps['sfs'].get_metric_dict()).T\n",
    "res.sort_values('avg_score', ascending=False)\n",
    "\n",
    "best_trial = res.sort_values('avg_score', ascending=False).index[0]\n",
    "\n",
    "feature_idx = [int(x) for x in res.loc[best_trial, 'feature_names']]\n",
    "sfs_selected_cols_sgd_log = X_train.iloc[:, feature_idx].columns\n",
    "sfs_selected_cols_sgd_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_pipe_lr = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('sfs', SFS(LogisticRegression(solver='saga',tol = 0.001, max_iter=1000, n_jobs=-1, random_state=23),\n",
    "                        k_features='best', cv=tscv, scoring='accuracy', verbose=2))])\n",
    "\n",
    "\n",
    "sfs_pipe_lr.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_dict(sfs_pipe_lr.named_steps['sfs'].get_metric_dict()).T\n",
    "res.sort_values('avg_score', ascending=False)\n",
    "\n",
    "best_trial = res.sort_values('avg_score', ascending=False).index[0]\n",
    "\n",
    "feature_idx = [int(x) for x in res.loc[best_trial, 'feature_names']]\n",
    "sfs_selected_cols_log = X_train.iloc[:, feature_idx].columns\n",
    "sfs_selected_cols_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = SequentialFeatureSelector(lr, scoring = 'accuracy', cv=tscv, n_jobs=-1)\n",
    "\n",
    "sfs.fit(rfe_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = rfe_features.iloc[:, sfs.support_].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train[selected_cols], y_train)\n",
    "\n",
    "print(lr.score(X_test[selected_cols], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "view_model_coefs(lr.named_steps['lr'], X_train[selected_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-taiwan",
   "metadata": {},
   "source": [
    "## Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-house",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-prince",
   "metadata": {},
   "source": [
    "Train Set: 2006-2015\n",
    "<br>Test Set: 2016-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-steering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_selected_cols_log = ['RECORD_team_diff', 'OREB_team_diff', 'DREB_team_diff', 'REB_team_diff',\n",
    "       'STL_team_diff', 'TOV_team_diff', 'PLUS_MINUS_team_diff',\n",
    "       'E_DEF_RATING_team_diff', 'PTS_OFF_TOV_team_diff', 'AST_3PM_team_diff',\n",
    "       'UAST_2PM_team_diff', 'ATS_DIFF_team_diff', 'FG2A_opp_diff',\n",
    "       'FG3A_opp_diff', 'FTM_opp_diff', 'FTA_opp_diff', 'AST_opp_diff',\n",
    "       'TOV_opp_diff', 'E_OFF_RATING_opp_diff', 'PTS_FB_opp_diff',\n",
    "       'AST_2PM_opp_diff', 'UAST_2PM_opp_diff', 'UAST_3PM_opp_diff',\n",
    "       'ATS_PCT_diff', 'AVG_SPREAD_diff', 'AVG_ML_diff', 'AVG_ATS_DIFF_diff',\n",
    "       'REST_diff', 'OREB_PCT_team_diff', 'OREB_PCT_opp_diff',\n",
    "       'DREB_PCT_team_diff', 'DREB_PCT_opp_diff', 'TS_PCT_team_diff',\n",
    "       'EFG_PCT_team_diff', 'EFG_PCT_opp_diff', 'AST_RATIO_team_diff',\n",
    "       'TOV_PCT_team_diff', 'TOV_PCT_opp_diff', 'team_elo_pred',\n",
    "       'elo_MOV_pred', 'SPREAD_team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-highway",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    lr_C = trial.suggest_float('C', 1e-5, 1e2, log=True)\n",
    "    \n",
    "    classifier_obj = Pipeline([('selector', ColumnTransformer([\n",
    "                        (\"selector\", \"passthrough\", sfs_selected_cols_log)\n",
    "                    ], remainder=\"drop\")),\n",
    "                                        ('scaler', StandardScaler()),\n",
    "                                        ('logreg', LogisticRegression(solver='saga', C=lr_C,\n",
    "                                                                      penalty='l2', max_iter=10000,\n",
    "                                                                     verbose=1, random_state=23))])\n",
    "    \n",
    "    score = cross_val_score(classifier_obj, X_train, y_train, n_jobs=-1,\n",
    "                           cv=tscv, scoring='accuracy')\n",
    "    \n",
    "    \n",
    "    score_avg = score.mean()\n",
    "    \n",
    "    return score_avg\n",
    "\n",
    "study_name = '../models/hyperparameter_tuning/study_lr2_select_sffs'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_lr = optuna.create_study(study_name = study_name, direction='maximize', \n",
    "                               storage = storage_name, load_if_exists=True)\n",
    "\n",
    "study_lr.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_lr.trials_dataframe().sort_values(['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-motor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_C = study_lr.best_params['C']\n",
    "print(lr_C)\n",
    "best_lr = Pipeline([('selector', ColumnTransformer([\n",
    "    (\"selector\", \"passthrough\", sfs_selected_cols_log)\n",
    "], remainder=\"drop\")),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('logreg', LogisticRegression(solver='saga', C=lr_C,\n",
    "                                                  penalty='l2', max_iter=100000,\n",
    "                                                 verbose=1, random_state=23))])\n",
    "best_lr.fit(X_train, y_train)\n",
    "\n",
    "print(best_lr)\n",
    "\n",
    "print(\"train_acc:\", best_lr.score(X_train, y_train))\n",
    "print(\"test_acc:\", best_lr.score(X_test, y_test))\n",
    "\n",
    "view_model_coefs(best_lr.named_steps['logreg'], X_train[sfs_selected_cols_log])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/best_lr_diffs_sfs'\n",
    "joblib.dump(best_lr, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-inventory",
   "metadata": {},
   "source": [
    "### SGD Hinge (SVC Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_pipe_sgd = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('sffs', SFS(SGDClassifier(loss='hinge', random_state=23, alpha=0.03320641664870966),\n",
    "                        k_features='best', cv=tscv, scoring='accuracy', floating=True, verbose=1))])\n",
    "\n",
    "\n",
    "sfs_pipe_sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_dict(sfs_pipe_sgd.named_steps['sffs'].get_metric_dict()).T\n",
    "res.sort_values('avg_score', ascending=False)\n",
    "\n",
    "best_trial = res.sort_values('avg_score', ascending=False).index[0]\n",
    "\n",
    "feature_idx = [int(x) for x in res.loc[best_trial, 'feature_names']]\n",
    "sfs_selected_cols_hinge = X_train.iloc[:, feature_idx].columns\n",
    "sfs_selected_cols_hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_dict(sfs_pipe_sgd.named_steps['sfs'].get_metric_dict()).T\n",
    "res.sort_values('avg_score', ascending=False)\n",
    "\n",
    "best_trial = res.sort_values('avg_score', ascending=False).index[0]\n",
    "\n",
    "feature_idx = [int(x) for x in res.loc[best_trial, 'feature_names']]\n",
    "sfs_selected_cols_hinge = X_train.iloc[:, feature_idx].columns\n",
    "sfs_selected_cols_hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_selected_cols_hinge = ['RECORD_team_diff', 'FG2M_team_diff', 'FG3M_team_diff',\n",
    "       'FG3A_team_diff', 'FTM_team_diff', 'FTA_team_diff', 'OREB_team_diff',\n",
    "       'DREB_team_diff', 'REB_team_diff', 'AST_team_diff', 'STL_team_diff',\n",
    "       'PTS_team_diff', 'PLUS_MINUS_team_diff', 'E_OFF_RATING_team_diff',\n",
    "       'E_NET_RATING_team_diff', 'POSS_team_diff', 'PIE_team_diff',\n",
    "       'PTS_OFF_TOV_team_diff', 'AST_2PM_team_diff', 'AST_3PM_team_diff',\n",
    "       'UAST_2PM_team_diff', 'UAST_3PM_team_diff', 'RECORD_opp_diff',\n",
    "       'FG2M_opp_diff', 'FG2A_opp_diff', 'FG3A_opp_diff', 'FTM_opp_diff',\n",
    "       'FTA_opp_diff', 'OREB_opp_diff', 'TOV_opp_diff', 'PF_opp_diff',\n",
    "       'PTS_opp_diff', 'PLUS_MINUS_opp_diff', 'E_DEF_RATING_opp_diff',\n",
    "       'E_NET_RATING_opp_diff', 'PIE_opp_diff', 'PTS_FB_opp_diff',\n",
    "       'AST_2PM_opp_diff', 'UAST_2PM_opp_diff', 'UAST_3PM_opp_diff',\n",
    "       'WL_PCT_diff', 'REST_diff', 'OREB_PCT_team_diff', 'OREB_PCT_opp_diff',\n",
    "       'DREB_PCT_team_diff', 'TS_PCT_team_diff', 'EFG_PCT_team_diff',\n",
    "       'EFG_PCT_opp_diff', 'AST_RATIO_team_diff', 'AST_RATIO_opp_diff',\n",
    "       'TOV_PCT_opp_diff', 'elo_MOV_pred', 'SPREAD_team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    sgd_alpha = trial.suggest_float('alpha', 1e-5, 1e2, log=True)\n",
    "    \n",
    "    classifier_obj = Pipeline(steps=[(\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", sfs_selected_cols_hinge)], remainder=\"drop\")),\n",
    "        ('scaler', StandardScaler()),\n",
    "                ('sgd', SGDClassifier(alpha = sgd_alpha,\n",
    "                                      loss='hinge',\n",
    "                                       max_iter=5000,\n",
    "                                     random_state=23))])\n",
    "    \n",
    "    score = cross_val_score(classifier_obj, X_train, y_train, n_jobs=-1,\n",
    "                           cv=tscv, scoring='accuracy')\n",
    "    \n",
    "    \n",
    "    score_avg = score.mean()\n",
    "    \n",
    "    return score_avg\n",
    "\n",
    "study_name = '../models/hyperparameter_tuning/study_sgd_hinge_sffs'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_sgd = optuna.create_study(study_name = study_name, direction='maximize', \n",
    "                               storage = storage_name, load_if_exists=True)\n",
    "\n",
    "study_sgd.optimize(objective, n_trials=10, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_alpha = study_sgd.best_params['alpha']\n",
    "print('C:', sgd_alpha)\n",
    "\n",
    "best_sgd_hinge = Pipeline(steps=[(\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", sfs_selected_cols_hinge)], remainder=\"drop\")),\n",
    "        ('scaler', StandardScaler()),\n",
    "                ('sgd', SGDClassifier(alpha = sgd_alpha,\n",
    "                                      loss='hinge',\n",
    "                                       max_iter=1000,\n",
    "                                     random_state=23))])\n",
    "\n",
    "\n",
    "best_sgd_hinge.fit(X_train, y_train)\n",
    "\n",
    "print(\"best_svc:\", best_sgd_hinge)\n",
    "\n",
    "\n",
    "print(\"train_score:\", best_sgd_hinge.score(X_train, y_train))\n",
    "print(\"test_score:\", best_sgd_hinge.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/best_sgd_hinge_diffs_sfs'\n",
    "joblib.dump(best_lr, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-postcard",
   "metadata": {},
   "source": [
    "### SGD modified_huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_pipe_sgd_huber = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('sffs', SFS(SGDClassifier(loss='modified_huber', random_state=23, alpha=0.56299),\n",
    "                        k_features='best', cv=tscv, scoring='accuracy', floating=True, verbose=1))])\n",
    "\n",
    "\n",
    "sfs_pipe_sgd_huber.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_dict(sfs_pipe_sgd_huber.named_steps['sffs'].get_metric_dict()).T\n",
    "res.sort_values('avg_score', ascending=False)\n",
    "\n",
    "best_trial = res.sort_values('avg_score', ascending=False).index[0]\n",
    "\n",
    "feature_idx = [int(x) for x in res.loc[best_trial, 'feature_names']]\n",
    "sfs_selected_cols_huber = X_train.iloc[:, feature_idx].columns\n",
    "sfs_selected_cols_huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-regard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_dict(sfs_pipe_sgd_huber.named_steps['sfs'].get_metric_dict()).T\n",
    "res.sort_values('avg_score', ascending=False)\n",
    "\n",
    "best_trial = res.sort_values('avg_score', ascending=False).index[0]\n",
    "\n",
    "feature_idx = [int(x) for x in res.loc[best_trial, 'feature_names']]\n",
    "sfs_selected_cols_huber = X_train.iloc[:, feature_idx].columns\n",
    "sfs_selected_cols_huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_selected_cols_huber = ['RECORD_team_diff', 'FG2M_team_diff', 'FG2A_team_diff',\n",
    "       'FG3A_team_diff', 'FTM_team_diff', 'FTA_team_diff', 'OREB_team_diff',\n",
    "       'DREB_team_diff', 'STL_team_diff', 'E_OFF_RATING_team_diff',\n",
    "       'E_DEF_RATING_team_diff', 'PIE_team_diff', 'PTS_OFF_TOV_team_diff',\n",
    "       'AST_2PM_team_diff', 'AST_3PM_team_diff', 'UAST_2PM_team_diff',\n",
    "       'UAST_3PM_team_diff', 'RECORD_opp_diff', 'FG2M_opp_diff',\n",
    "       'FG3A_opp_diff', 'FTA_opp_diff', 'AST_opp_diff',\n",
    "       'E_OFF_RATING_opp_diff', 'E_DEF_RATING_opp_diff', 'PTS_FB_opp_diff',\n",
    "       'AST_3PM_opp_diff', 'UAST_2PM_opp_diff', 'TEAM_COVERED_opp_diff',\n",
    "       'WL_PCT_diff', 'REST_diff', 'TS_PCT_team_diff', 'AST_RATIO_team_diff',\n",
    "       'AST_RATIO_opp_diff', 'TOV_PCT_opp_diff', 'ML_team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-collins",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    sgd_alpha = trial.suggest_float('alpha', 1e-5, 1e2, log=True)\n",
    "    \n",
    "    classifier_obj = Pipeline(steps=[(\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", sfs_selected_cols_huber)], remainder=\"drop\")),\n",
    "        ('scaler', StandardScaler()),\n",
    "                ('sgd', SGDClassifier(alpha = sgd_alpha,\n",
    "                                      loss='modified_huber',\n",
    "                                       max_iter=1000,\n",
    "                                     random_state=23))])\n",
    "    \n",
    "    score = cross_val_score(classifier_obj, X_train, y_train, n_jobs=-1,\n",
    "                           cv=tscv, scoring='accuracy')\n",
    "    \n",
    "    \n",
    "    score_avg = score.mean()\n",
    "    \n",
    "    return score_avg\n",
    "\n",
    "study_name = '../models/hyperparameter_tuning/study_sgd_huber_sffs'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_sgd = optuna.create_study(study_name = study_name, direction='maximize', \n",
    "                               storage = storage_name, load_if_exists=True)\n",
    "\n",
    "study_sgd.optimize(objective, n_trials=10, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_alpha = study_sgd.best_params['alpha']\n",
    "print(sgd_alpha)\n",
    "best_sgd_huber = Pipeline(steps=[(\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", sfs_selected_cols_huber)], remainder=\"drop\")),\n",
    "        ('scaler', StandardScaler()),\n",
    "                ('sgd', SGDClassifier(alpha = sgd_alpha,\n",
    "                                      loss='modified_huber',\n",
    "                                       max_iter=1000,\n",
    "                                     random_state=23))])\n",
    "\n",
    "print(\"best_sgd:\", best_sgd_huber)\n",
    "\n",
    "best_sgd_huber.fit(X_train, y_train)\n",
    "\n",
    "print(\"train_score:\", best_sgd_huber.score(X_train, y_train))\n",
    "print(\"test_score:\", best_sgd_huber.score(X_test, y_test))\n",
    "\n",
    "view_model_coefs(best_sgd_huber.named_steps['sgd'], X_train[sfs_selected_cols_huber])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/best_sgd_huber_diffs_sfs'\n",
    "\n",
    "joblib.dump(best_sgd_huber, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-concept",
   "metadata": {},
   "source": [
    "### LGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_pipe_lgb = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('sfs', SFS(lgb.LGBMClassifier(colsample_bytree=0.30306249172980904,\n",
    "               learning_rate=0.03464725063611881, max_depth=3,\n",
    "               min_child_weight=0.6782064406615411, num_leaves=120,\n",
    "               random_state=23, reg_alpha=2.5908850696822157,\n",
    "               reg_lambda=6.57863348422055, subsample=0.7226323380307508),\n",
    "                        k_features='best', cv=tscv, scoring='accuracy', verbose=1))])\n",
    "\n",
    "\n",
    "sfs_pipe_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_dict(sfs_pipe_lgb.named_steps['sfs'].get_metric_dict()).T\n",
    "res.sort_values('avg_score', ascending=False)\n",
    "\n",
    "best_trial = res.sort_values('avg_score', ascending=False).index[0]\n",
    "\n",
    "feature_idx = [int(x) for x in res.loc[best_trial, 'feature_names']]\n",
    "sfs_selected_cols_lgb = X_train.iloc[:, feature_idx].columns\n",
    "sfs_selected_cols_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-poster",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    min_child_weight = trial.suggest_float('min_child_weight', 1e-4, 1.0)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 32)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 1, 10)\n",
    "    reg_alpha = trial.suggest_float('reg_alpha', 0, 5),\n",
    "    num_leaves = trial.suggest_int('num_leaves', 2, 512)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.1, 1.0)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1.0, log=True)\n",
    "    \n",
    "    classifier_obj = Pipeline(steps=[(\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", sfs_selected_cols_lgb)], remainder=\"drop\")),\n",
    "        ('lgbc', lgb.LGBMClassifier(colsample_bytree=colsample_bytree,\n",
    "               learning_rate=learning_rate, max_depth=max_depth,\n",
    "               min_child_weight=min_child_weight, num_leaves=num_leaves,\n",
    "               random_state=23, reg_alpha=reg_alpha,\n",
    "               reg_lambda=reg_lambda, subsample=subsample))])\n",
    "    \n",
    "    score = cross_val_score(classifier_obj, X_train, y_train, n_jobs=-1,\n",
    "                           cv=tscv, scoring='accuracy')\n",
    "    \n",
    "    \n",
    "    score_avg = score.mean()\n",
    "    \n",
    "    return score_avg\n",
    "\n",
    "study_name = '../models/hyperparameter_tuning/study_lgbc_sfs'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_lgbc = optuna.create_study(study_name = study_name, direction='maximize', \n",
    "                               storage = storage_name, load_if_exists=True)\n",
    "\n",
    "study_lgbc.optimize(objective, n_trials=200, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-healthcare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    min_child_weight = trial.suggest_float('min_child_weight', 1e-4, 1.0)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 32)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 1, 10)\n",
    "    reg_alpha = trial.suggest_float('reg_alpha', 0, 5),\n",
    "    num_leaves = trial.suggest_int('num_leaves', 2, 512)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.1, 1.0)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1.0, log=True)\n",
    "    \n",
    "    classifier_obj = lgb.LGBMClassifier(colsample_bytree=colsample_bytree,\n",
    "               learning_rate=learning_rate, max_depth=max_depth,\n",
    "               min_child_weight=min_child_weight, num_leaves=num_leaves,\n",
    "               random_state=23, reg_alpha=reg_alpha,\n",
    "               reg_lambda=reg_lambda, subsample=subsample)\n",
    "    \n",
    "    score = cross_val_score(classifier_obj, X_train, y_train, n_jobs=-1,\n",
    "                           cv=tscv, scoring='accuracy')\n",
    "    \n",
    "    \n",
    "    score_avg = score.mean()\n",
    "    \n",
    "    return score_avg\n",
    "\n",
    "study_name = '../models/hyperparameter_tuning/study_lgbc'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_lgbc = optuna.create_study(study_name = study_name, direction='maximize', \n",
    "                               storage = storage_name, load_if_exists=True)\n",
    "\n",
    "study_lgbc.optimize(objective, n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name = '../models/hyperparameter_tuning/study_lgbc'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_lgbc = optuna.load_study(study_name = study_name, storage = storage_name)\n",
    "\n",
    "lgbc_params = study_lgbc.best_trial.params\n",
    "lgbc_params['random_state'] = 23\n",
    "best_lgbc = lgb.LGBMClassifier()\n",
    "best_lgbc.set_params(**lgbc_params)\n",
    "print(\"best_lgbc:\", best_lgbc)\n",
    "\n",
    "best_lgbc.fit(X_train, y_train)\n",
    "\n",
    "print(\"train_acc:\", best_lgbc.score(X_train, y_train))\n",
    "print(\"test_acc:\", best_lgbc.score(X_test, y_test))\n",
    "\n",
    "\n",
    "view_model_coefs(best_lgbc, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/best_lgbc_diffs'\n",
    "joblib.dump(best_lgbc, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-richardson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-ratio",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgbc_params = study_lgbc.best_trial.params\n",
    "lgbc_params['random_state'] = 23\n",
    "best_lgbc = lgb.LGBMClassifier()\n",
    "best_lgbc.set_params(**lgbc_params)\n",
    "print(\"best_lgbc:\", best_lgbc)\n",
    "\n",
    "best_lgbc.fit(X_train, y_train)\n",
    "\n",
    "print(\"train_acc:\", best_lgbc.score(X_train, y_train))\n",
    "print(\"test_acc:\", best_lgbc.score(X_test, y_test))\n",
    "\n",
    "\n",
    "view_model_coefs(best_lgbc, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lgbc = lgb.LGBMClassifier(colsample_bytree=0.30306249172980904,\n",
    "               learning_rate=0.03464725063611881, max_depth=3,\n",
    "               min_child_weight=0.6782064406615411, num_leaves=120,\n",
    "               random_state=23, reg_alpha=2.5908850696822157,\n",
    "               reg_lambda=6.57863348422055, subsample=0.7226323380307508)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-medium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-wedding",
   "metadata": {},
   "source": [
    "### KNNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_pipe_knn = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                                     ('pca', PCA(n_components=0.99)),\n",
    "                                    ('knn',\n",
    "                                     SFS(KNeighborsClassifier(n_neighbors=47),\n",
    "                                    k_features='best', cv=tscv, scoring='accuracy', verbose=1))])\n",
    "\n",
    "\n",
    "sfs_pipe_knn.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_dict(sfs_pipe_knn.named_steps['knn'].get_metric_dict()).T\n",
    "res.sort_values('avg_score', ascending=False)\n",
    "\n",
    "best_trial = res.sort_values('avg_score', ascending=False).index[0]\n",
    "\n",
    "feature_idx = [int(x) for x in res.loc[best_trial, 'feature_names']]\n",
    "sfs_selected_cols_knn = X_train.iloc[:, feature_idx].columns\n",
    "sfs_selected_cols_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_selected_cols_knn = ['FG2M_team_diff', 'FG2A_team_diff', 'FTM_team_diff', 'AST_team_diff',\n",
    "       'BLK_team_diff', 'TOV_team_diff', 'PF_team_diff',\n",
    "       'PLUS_MINUS_team_diff', 'E_OFF_RATING_team_diff', 'POSS_team_diff',\n",
    "       'PIE_team_diff', 'PTS_2PT_MR_team_diff', 'PTS_OFF_TOV_team_diff',\n",
    "       'AST_3PM_team_diff', 'UAST_2PM_team_diff', 'UAST_3PM_team_diff',\n",
    "       'ATS_DIFF_team_diff', 'RECORD_opp_diff', 'FG2M_opp_diff',\n",
    "       'FG3M_opp_diff', 'FG3A_opp_diff', 'FTM_opp_diff', 'FTA_opp_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-separation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 52)\n",
    "    n_components = trial.suggest_float('n_components', 0.9, 0.99)\n",
    "    \n",
    "    classifier_obj = Pipeline(steps=[(\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", sfs_selected_cols_knn)], remainder=\"drop\")),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=n_components)),\n",
    "                ('knn',\n",
    "                 KNeighborsClassifier(n_neighbors=n_neighbors))])\n",
    "    \n",
    "    score = cross_val_score(classifier_obj, X_train, y_train, n_jobs=-1,\n",
    "                           cv=tscv, scoring='accuracy')\n",
    "    \n",
    "    \n",
    "    score_avg = score.mean()\n",
    "    \n",
    "    return score_avg\n",
    "\n",
    "study_name = '../models/hyperparameter_tuning/study_knn_sfs'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "search_space = {'n_neighbors':np.arange(3, 50, 4).tolist(),\n",
    "               'n_components':np.linspace(0.9, 0.99, 10).tolist()}\n",
    "\n",
    "study_knn = optuna.create_study(study_name = study_name, direction='maximize', \n",
    "                               storage = storage_name, load_if_exists=True,\n",
    "                               sampler = optuna.samplers.GridSampler(search_space))\n",
    "\n",
    "study_knn.optimize(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name = '../models/hyperparameter_tuning/study_knn_sfs'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_knn = optuna.load_study(study_name = study_name, \n",
    "                               storage = storage_name)\n",
    "\n",
    "\n",
    "best_n = study_knn.best_trial.params['n_neighbors']\n",
    "best_n_components = study_knn.best_trial.params['n_components']\n",
    "\n",
    "\n",
    "best_knn = Pipeline(steps=[(\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", sfs_selected_cols_knn)], remainder=\"drop\")),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=best_n_components)),\n",
    "                ('knn',\n",
    "                 KNeighborsClassifier(n_neighbors=best_n))])\n",
    "\n",
    "print(\"best_knn:\", best_knn)\n",
    "\n",
    "best_knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"train_score:\", best_knn.score(X_train, y_train))\n",
    "print(\"test_score:\", best_knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-cambridge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'best_knn_diffs_sfs'\n",
    "\n",
    "joblib.dump(best_knn, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-component",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_pipe_rf = SFS(RandomForestClassifier(max_depth=9,\n",
    "                                        min_samples_leaf=0.010338564023847334,\n",
    "                                        min_samples_split=0.017844890716741457,\n",
    "                                        random_state=23), k_features=25, cv=tscv, scoring='accuracy', floating=True, verbose=1)\n",
    "\n",
    "\n",
    "sfs_pipe_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_dict(sfs_pipe_rf.get_metric_dict()).T\n",
    "res.sort_values('avg_score', ascending=False)\n",
    "\n",
    "best_trial = res.sort_values('avg_score', ascending=False).index[0]\n",
    "\n",
    "sfs_selected_cols_rf = [str(x) for x in res.loc[best_trial, 'feature_names']]\n",
    "# sfs_selected_cols_rf = X_train.iloc[:, feature_idx].columns\n",
    "sfs_selected_cols_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_dict(sfs_pipe_rf.get_metric_dict()).T\n",
    "res.sort_values('avg_score', ascending=False)\n",
    "\n",
    "best_trial = res.sort_values('avg_score', ascending=False).index[0]\n",
    "\n",
    "sfs_selected_cols_rf = [str(x) for x in res.loc[best_trial, 'feature_names']]\n",
    "# sfs_selected_cols_rf = X_train.iloc[:, feature_idx].columns\n",
    "sfs_selected_cols_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-sussex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-emission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    min_samples_split = trial.suggest_float('min_samples_split', 0.01, 0.5)\n",
    "#     subsample = trial.suggest_float('subsample', 0.6, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 32)\n",
    "    min_samples_leaf = trial.suggest_float('min_samples_leaf', 0.01, 0.5)\n",
    "\n",
    "    classifier_obj = Pipeline(steps=[(\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", sfs_selected_cols_rf)], remainder=\"drop\")),\n",
    "        ('rf', RandomForestClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf,\n",
    "                       min_samples_split=min_samples_split, random_state=23))])\n",
    "    \n",
    "    \n",
    "    score = cross_val_score(classifier_obj, X_train, y_train, n_jobs=-1,\n",
    "                           cv=tscv, scoring='accuracy')\n",
    "    \n",
    "    \n",
    "    score_avg = score.mean()\n",
    "    \n",
    "    return score_avg\n",
    "\n",
    "study_name = '../models/hyperparameter_tuning/study_rf2_sffs'\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study_rf = optuna.create_study(study_name = study_name, direction='maximize', \n",
    "                               storage = storage_name, load_if_exists=True)\n",
    "\n",
    "study_rf.optimize(objective, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study_rf.best_params)\n",
    "\n",
    "max_depth = study_rf.best_params['max_depth']\n",
    "min_samples_leaf = study_rf.best_params['min_samples_leaf']\n",
    "min_samples_split = study_rf.best_params['min_samples_split']\n",
    "\n",
    "\n",
    "best_rf = Pipeline(steps=[(\"selector\", ColumnTransformer([\n",
    "        (\"selector\", \"passthrough\", sfs_selected_cols_rf)], remainder=\"drop\")),\n",
    "        ('rf', RandomForestClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf,\n",
    "                       min_samples_split=min_samples_split, random_state=23))])\n",
    "\n",
    "print(best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = Pipeline(steps=[('selector',\n",
    "                 ColumnTransformer(transformers=[('selector', 'passthrough',\n",
    "                                                  ['STL_team_diff',\n",
    "                                                   'PTS_2PT_MR_team_diff',\n",
    "                                                   'AST_2PM_team_diff',\n",
    "                                                   'UAST_2PM_team_diff',\n",
    "                                                   'STL_opp_diff',\n",
    "                                                   'BLK_opp_diff',\n",
    "                                                   'PTS_2PT_MR_opp_diff',\n",
    "                                                   'PTS_FB_opp_diff',\n",
    "                                                   'OREB_PCT_team_diff',\n",
    "                                                   'TS_PCT_opp_diff',\n",
    "                                                   'EFG_PCT_opp_diff',\n",
    "                                                   'AST_RATIO_opp_diff',\n",
    "                                                   'team_elo_pred'])])),\n",
    "                ('rf',\n",
    "                 RandomForestClassifier(max_depth=5,\n",
    "                                        min_samples_leaf=0.041549315118501726,\n",
    "                                        min_samples_split=0.10343617670917564,\n",
    "                                        random_state=23))])\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"rf train_acc:\", best_rf.score(X_train, y_train))\n",
    "print(\"rf test_acc:\", best_rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = Pipeline(steps=[('selector',\n",
    "                 ColumnTransformer(transformers=[('selector', 'passthrough',\n",
    "                                                  ['REB_team_diff',\n",
    "                                                   'AST_3PM_team_diff',\n",
    "                                                   'UAST_2PM_team_diff',\n",
    "                                                   'FG3A_opp_diff',\n",
    "                                                   'FTM_opp_diff',\n",
    "                                                   'DREB_opp_diff',\n",
    "                                                   'REB_opp_diff',\n",
    "                                                   'PTS_2PT_MR_opp_diff',\n",
    "                                                   'PTS_FB_opp_diff',\n",
    "                                                   'AST_2PM_opp_diff',\n",
    "                                                   'ATS_DIFF_opp_diff',\n",
    "                                                   'TEAM_COVERED_opp_diff',\n",
    "                                                   'TS_PCT_opp_diff',\n",
    "                                                   'EFG_PCT_opp_diff',\n",
    "                                                   'AST_RATIO_opp_diff'])])),\n",
    "                ('rf',\n",
    "                 RandomForestClassifier(max_depth=9,\n",
    "                                        min_samples_leaf=0.010338564023847334,\n",
    "                                        min_samples_split=0.017844890716741457,\n",
    "                                        random_state=23))])\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"rf train_acc:\", best_rf.score(X_train, y_train))\n",
    "print(\"rf test_acc:\", best_rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-campus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view_model_coefs(best_rf.named_steps['rf'], X_train[sfs_selected_cols_rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-disney",
   "metadata": {},
   "source": [
    "## Stacked Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('log', best_lr), ('sgd_huber', best_sgd_huber),\n",
    "              ('svc', best_sgd_hinge), ('lgbc', best_lgbc), \n",
    "              ('rf', best_rf), ('knn', best_knn)]\n",
    "\n",
    "\n",
    "stacked_clf = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression(),\n",
    "                                 n_jobs=-1, verbose=1)\n",
    "\n",
    "\n",
    "stacked_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"stacked clf train_acc:\", stacked_clf.score(X_train, y_train))\n",
    "print(\"stacked clf test_acc:\", stacked_clf.score(X_test, y_test))\n",
    "\n",
    "cutoffs = [cutoff_16, cutoff_17, cutoff_18, cutoff_19, cutoff_20, cutoff_21, cutoff_22]\n",
    "\n",
    "threshold = 0.53\n",
    "\n",
    "for estimator in [best_lr, stacked_clf]:\n",
    "    season = []\n",
    "    win_pcts = []\n",
    "    rois = []\n",
    "    profits = []\n",
    "    num_games_bet = []\n",
    "    best_thresholds = []\n",
    "    for i in range(len(cutoffs)-1):\n",
    "        X_train1, X_test1, y_train1, y_test1, train_idx1, test_idx1 = split_prep_data(df_ewm_19_diffs, cutoffs[i])\n",
    "\n",
    "        X_test1, y_test1, test_idx1 = (X_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       y_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       X_test1.loc[cutoffs[i]+1:cutoffs[i+1]].index)\n",
    "\n",
    "        print(i)\n",
    "        print(\"test set 1:\", df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[0], \"-\",\n",
    "             df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[-1])\n",
    "\n",
    "        year = df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].astype(str).str[:4].values[-1]\n",
    "        \n",
    "        estimator.fit(X_train1, y_train1)\n",
    "        try:\n",
    "            y_probs = estimator.predict_proba(X_test1)\n",
    "        except:\n",
    "            decisions = estimator.decision_function(X_test1)\n",
    "            y_probs = 1 / (1 + np.exp(-decisions))\n",
    "            y_probs = np.concatenate([np.zeros_like(y_probs).reshape(-1,1), y_probs.reshape(-1,1)], axis=1)\n",
    "        \n",
    "        betting_df = create_betting_df(df_ewm_19_diffs, y_probs, test_idx1)\n",
    "\n",
    "        \n",
    "        select_bets = betting_df.loc[~betting_df['prob_avg'].between(1-threshold, threshold)]\n",
    "        \n",
    "        selected_bets, roi, profit, win_pct = simulate_bets_3(select_bets)\n",
    "\n",
    "        season.append(year)\n",
    "        best_thresholds.append(threshold)\n",
    "        win_pcts.append(win_pct)\n",
    "        profits.append(profit)\n",
    "        rois.append(roi)\n",
    "        num_games_bet.append(selected_bets.shape[0])\n",
    "\n",
    "    results_by_season = pd.DataFrame({\n",
    "                                    'season':season,\n",
    "                                    'best_threshold':best_thresholds,\n",
    "                                     'win_pcts':win_pcts,\n",
    "                                     'num_games_bet':num_games_bet,\n",
    "                                     'rois':rois,\n",
    "                                      'profits':profits\n",
    "                                     })\n",
    "    \n",
    "    print('\\n', estimator)\n",
    "    print(results_by_season)\n",
    "\n",
    "results_by_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('log', best_lr), ('sgd_huber', best_sgd_huber),\n",
    "              ('svc', best_sgd_hinge), ('lgbc', best_lgbc), \n",
    "              ('rf', best_rf), ('knn', best_knn)]\n",
    "\n",
    "\n",
    "stacked_clf = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression(),\n",
    "                                 n_jobs=-1, verbose=1)\n",
    "\n",
    "\n",
    "stacked_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"stacked clf train_acc:\", stacked_clf.score(X_train, y_train))\n",
    "print(\"stacked clf test_acc:\", stacked_clf.score(X_test, y_test))\n",
    "\n",
    "cutoffs = [cutoff_16, cutoff_17, cutoff_18, cutoff_19, cutoff_20, cutoff_21, cutoff_22]\n",
    "\n",
    "threshold = 0.53\n",
    "\n",
    "for estimator in [stacked_clf]:\n",
    "    season = []\n",
    "    win_pcts = []\n",
    "    rois = []\n",
    "    profits = []\n",
    "    num_games_bet = []\n",
    "    best_thresholds = []\n",
    "    for i in range(len(cutoffs)-1):\n",
    "        X_train1, X_test1, y_train1, y_test1, train_idx1, test_idx1 = split_prep_data(df_ewm_19_diffs, cutoffs[i])\n",
    "\n",
    "        X_test1, y_test1, test_idx1 = (X_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       y_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       X_test1.loc[cutoffs[i]+1:cutoffs[i+1]].index)\n",
    "\n",
    "        print(i)\n",
    "        print(\"test set 1:\", df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[0], \"-\",\n",
    "             df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[-1])\n",
    "\n",
    "        year = df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].astype(str).str[:4].values[-1]\n",
    "        \n",
    "        estimator.fit(X_train1, y_train1)\n",
    "        try:\n",
    "            y_probs = estimator.predict_proba(X_test1)\n",
    "        except:\n",
    "            decisions = estimator.decision_function(X_test1)\n",
    "            y_probs = 1 / (1 + np.exp(-decisions))\n",
    "            y_probs = np.concatenate([np.zeros_like(y_probs).reshape(-1,1), y_probs.reshape(-1,1)], axis=1)\n",
    "        \n",
    "        betting_df = create_betting_df(df_ewm_19_diffs, y_probs, test_idx1)\n",
    "\n",
    "        \n",
    "        select_bets = betting_df.loc[~betting_df['prob_avg'].between(1-threshold, threshold)]\n",
    "        \n",
    "        selected_bets, roi, profit, win_pct = simulate_bets_3(select_bets)\n",
    "\n",
    "        season.append(year)\n",
    "        best_thresholds.append(threshold)\n",
    "        win_pcts.append(win_pct)\n",
    "        profits.append(profit)\n",
    "        rois.append(roi)\n",
    "        num_games_bet.append(selected_bets.shape[0])\n",
    "\n",
    "    results_by_season = pd.DataFrame({\n",
    "                                    'season':season,\n",
    "                                    'best_threshold':best_thresholds,\n",
    "                                     'win_pcts':win_pcts,\n",
    "                                     'num_games_bet':num_games_bet,\n",
    "                                     'rois':rois,\n",
    "                                      'profits':profits\n",
    "                                     })\n",
    "    \n",
    "    print('\\n', estimator)\n",
    "    print(results_by_season)\n",
    "\n",
    "results_by_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('log', best_lr), ('sgd_huber', best_sgd_huber),\n",
    "              ('svc', best_sgd_hinge), ('lgbc', best_lgbc), \n",
    "              ('rf', best_rf), ('knn', best_knn)]\n",
    "\n",
    "\n",
    "stacked_clf = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression(),\n",
    "                                 n_jobs=-1, verbose=1)\n",
    "\n",
    "\n",
    "stacked_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"stacked clf train_acc:\", stacked_clf.score(X_train, y_train))\n",
    "print(\"stacked clf test_acc:\", stacked_clf.score(X_test, y_test))\n",
    "\n",
    "cutoffs = [cutoff_16, cutoff_17, cutoff_18, cutoff_19, cutoff_20, cutoff_21, cutoff_22]\n",
    "\n",
    "threshold = 0.53\n",
    "\n",
    "for estimator in [stacked_clf]:\n",
    "    season = []\n",
    "    win_pcts = []\n",
    "    rois = []\n",
    "    profits = []\n",
    "    num_games_bet = []\n",
    "    best_thresholds = []\n",
    "    for i in range(len(cutoffs)-1):\n",
    "        X_train1, X_test1, y_train1, y_test1, train_idx1, test_idx1 = split_prep_data(df_ewm_19_diffs, cutoffs[i])\n",
    "\n",
    "        X_test1, y_test1, test_idx1 = (X_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       y_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       X_test1.loc[cutoffs[i]+1:cutoffs[i+1]].index)\n",
    "\n",
    "        print(i)\n",
    "        print(\"test set 1:\", df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[0], \"-\",\n",
    "             df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[-1])\n",
    "\n",
    "        year = df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].str[:4].values[-1]\n",
    "        \n",
    "        estimator.fit(X_train1, y_train1)\n",
    "        try:\n",
    "            y_probs = estimator.predict_proba(X_test1)\n",
    "        except:\n",
    "            decisions = estimator.decision_function(X_test1)\n",
    "            y_probs = 1 / (1 + np.exp(-decisions))\n",
    "            y_probs = np.concatenate([np.zeros_like(y_probs).reshape(-1,1), y_probs.reshape(-1,1)], axis=1)\n",
    "        \n",
    "        betting_df = create_betting_df(df_ewm_19_diffs, y_probs, test_idx1)\n",
    "\n",
    "        \n",
    "        select_bets = betting_df.loc[~betting_df['prob_avg'].between(1-threshold, threshold)]\n",
    "        \n",
    "        selected_bets, roi, profit, win_pct = simulate_bets_3(select_bets)\n",
    "\n",
    "        season.append(year)\n",
    "        best_thresholds.append(threshold)\n",
    "        win_pcts.append(win_pct)\n",
    "        profits.append(profit)\n",
    "        rois.append(roi)\n",
    "        num_games_bet.append(selected_bets.shape[0])\n",
    "\n",
    "    results_by_season = pd.DataFrame({\n",
    "                                    'season':season,\n",
    "                                    'best_threshold':best_thresholds,\n",
    "                                     'win_pcts':win_pcts,\n",
    "                                     'num_games_bet':num_games_bet,\n",
    "                                     'rois':rois,\n",
    "                                      'profits':profits\n",
    "                                     })\n",
    "    \n",
    "    print('\\n', estimator)\n",
    "    print(results_by_season)\n",
    "\n",
    "results_by_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-finding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-samba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "known-healthcare",
   "metadata": {},
   "source": [
    "### with select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-saying",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('log', best_lr), ('sgd_huber', best_sgd_huber),\n",
    "              ('svc', best_sgd_hinge), ('lgbc', best_lgbc),\n",
    "             ('rf', best_rf), ('knn', best_knn)]\n",
    "\n",
    "\n",
    "stacked_clf = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression(),\n",
    "                                 n_jobs=-1, verbose=1)\n",
    "\n",
    "\n",
    "# stacked_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# print(\"stacked clf train_acc:\", stacked_clf.score(X_train, y_train))\n",
    "# print(\"stacked clf test_acc:\", stacked_clf.score(X_test, y_test))\n",
    "\n",
    "cutoffs = [cutoff_16, cutoff_mid_16, cutoff_17, cutoff_mid_17, cutoff_18, cutoff_mid_18,\n",
    "           cutoff_19, cutoff_mid_19, cutoff_20, cutoff_mid_20, cutoff_21, cutoff_mid_21, cutoff_22]\n",
    "\n",
    "threshold = 0.53\n",
    "\n",
    "for estimator in [best_lr, best_sgd_hinge, best_sgd, best_lgbc, best_rf, stacked_clf]:\n",
    "    season = []\n",
    "    win_pcts = []\n",
    "    rois = []\n",
    "    profits = []\n",
    "    num_games_bet = []\n",
    "    best_thresholds = []\n",
    "    for i in range(len(cutoffs)-1):\n",
    "        X_train1, X_test1, y_train1, y_test1, train_idx1, test_idx1 = split_prep_data(df_ewm_19_diffs, cutoffs[i])\n",
    "\n",
    "        X_test1, y_test1, test_idx1 = (X_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       y_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       X_test1.loc[cutoffs[i]+1:cutoffs[i+1]].index)\n",
    "\n",
    "        print(i)\n",
    "        print(\"test set 1:\", df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[0], \"-\",\n",
    "             df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[-1])\n",
    "\n",
    "        year = df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].str[:4].values[-1]\n",
    "        \n",
    "        estimator.fit(X_train1, y_train1)\n",
    "        try:\n",
    "            y_probs = estimator.predict_proba(X_test1)\n",
    "        except:\n",
    "            decisions = estimator.decision_function(X_test1)\n",
    "            y_probs = 1 / (1 + np.exp(-decisions))\n",
    "            y_probs = np.concatenate([np.zeros_like(y_probs).reshape(-1,1), y_probs.reshape(-1,1)], axis=1)\n",
    "        \n",
    "        betting_df = create_betting_df(df_ewm_19_diffs, y_probs, test_idx1)\n",
    "\n",
    "        \n",
    "        select_bets = betting_df.loc[~betting_df['prob_avg'].between(1-threshold, threshold)]\n",
    "        \n",
    "        selected_bets, roi, profit, win_pct = simulate_bets_3(select_bets)\n",
    "\n",
    "        season.append(year)\n",
    "        best_thresholds.append(threshold)\n",
    "        win_pcts.append(win_pct)\n",
    "        profits.append(profit)\n",
    "        rois.append(roi)\n",
    "        num_games_bet.append(selected_bets.shape[0])\n",
    "\n",
    "    results_by_season = pd.DataFrame({\n",
    "                                    'season':season,\n",
    "                                    'best_threshold':best_thresholds,\n",
    "                                     'win_pcts':win_pcts,\n",
    "                                     'num_games_bet':num_games_bet,\n",
    "                                     'rois':rois,\n",
    "                                      'profits':profits\n",
    "                                     })\n",
    "    \n",
    "    print('\\n', estimator)\n",
    "    print(results_by_season)\n",
    "\n",
    "results_by_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf.fit(X_train, y_train)\n",
    "y_preds = stacked_clf.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('log', best_lr), ('sgd', best_sgd),\n",
    "              ('svc', best_svc), ('lgbc', best_lgbc),\n",
    "             ('rf', best_rf), ('knn', best_knn)]\n",
    "\n",
    "\n",
    "stacked_clf = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression(),\n",
    "                                 n_jobs=-1, verbose=1)\n",
    "\n",
    "\n",
    "stacked_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"stacked clf train_acc:\", stacked_clf.score(X_train, y_train))\n",
    "print(\"stacked clf test_acc:\", stacked_clf.score(X_test, y_test))\n",
    "\n",
    "cutoffs = [cutoff_16, cutoff_17, cutoff_18, cutoff_19, cutoff_20, cutoff_21, cutoff_22]\n",
    "\n",
    "threshold = 0.53\n",
    "\n",
    "for estimator in [best_lr, best_svc, best_sgd, best_rf, stacked_clf]:\n",
    "    season = []\n",
    "    win_pcts = []\n",
    "    rois = []\n",
    "    profits = []\n",
    "    num_games_bet = []\n",
    "    best_thresholds = []\n",
    "    for i in range(len(cutoffs)-1):\n",
    "        X_train1, X_test1, y_train1, y_test1, train_idx1, test_idx1 = split_prep_data(df_ewm_19_diffs, cutoffs[i])\n",
    "\n",
    "        X_test1, y_test1, test_idx1 = (X_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       y_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       X_test1.loc[cutoffs[i]+1:cutoffs[i+1]].index)\n",
    "\n",
    "        print(i)\n",
    "        print(\"test set 1:\", np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[0], unit='D'), \"-\",\n",
    "             np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[-1], unit='D'))\n",
    "\n",
    "        year = (np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[0], unit='Y'), \"-\",\n",
    "             np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[-1], unit='Y'))\n",
    "\n",
    "\n",
    "        estimator.fit(X_train1, y_train1)\n",
    "        try:\n",
    "            y_probs = estimator.predict_proba(X_test1)\n",
    "        except:\n",
    "            decisions = estimator.decision_function(X_test1)\n",
    "            y_probs = 1 / (1 + np.exp(-decisions))\n",
    "            y_probs = np.concatenate([np.zeros_like(y_probs).reshape(-1,1), y_probs.reshape(-1,1)], axis=1)\n",
    "        \n",
    "        betting_df = create_betting_df(df_ewm_19_diffs, y_probs, test_idx1)\n",
    "\n",
    "        \n",
    "        select_bets = betting_df.loc[~betting_df['prob_avg'].between(1-threshold, threshold)]\n",
    "        \n",
    "        selected_bets, roi, profit, win_pct = simulate_bets_3(select_bets)\n",
    "\n",
    "        season.append(year)\n",
    "        best_thresholds.append(threshold)\n",
    "        win_pcts.append(win_pct)\n",
    "        profits.append(profit)\n",
    "        rois.append(roi)\n",
    "        num_games_bet.append(selected_bets.shape[0])\n",
    "\n",
    "    results_by_season = pd.DataFrame({\n",
    "                                    'season':season,\n",
    "                                    'best_threshold':best_thresholds,\n",
    "                                     'win_pcts':win_pcts,\n",
    "                                     'num_games_bet':num_games_bet,\n",
    "                                     'rois':rois,\n",
    "                                      'profits':profits\n",
    "                                     })\n",
    "    \n",
    "    print('\\n', estimator)\n",
    "    print(results_by_season)\n",
    "\n",
    "results_by_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-nothing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('log', best_lr),\n",
    "              ('svc', best_svc), ('lgbc', best_lgbc),\n",
    "              ('knn', best_knn)]\n",
    "\n",
    "\n",
    "stacked_clf = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression(),\n",
    "                                 n_jobs=-1, verbose=1)\n",
    "\n",
    "\n",
    "stacked_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"stacked clf train_acc:\", stacked_clf.score(X_train, y_train))\n",
    "print(\"stacked clf test_acc:\", stacked_clf.score(X_test, y_test))\n",
    "\n",
    "cutoffs = [cutoff_16, cutoff_17, cutoff_18, cutoff_19, cutoff_20, cutoff_21, cutoff_22]\n",
    "\n",
    "threshold = 0.53\n",
    "\n",
    "for estimator in [stacked_clf]:\n",
    "    season = []\n",
    "    win_pcts = []\n",
    "    rois = []\n",
    "    profits = []\n",
    "    num_games_bet = []\n",
    "    best_thresholds = []\n",
    "    for i in range(len(cutoffs)-1):\n",
    "        X_train1, X_test1, y_train1, y_test1, train_idx1, test_idx1 = split_prep_data(df_ewm_19_diffs, cutoffs[i])\n",
    "\n",
    "        X_test1, y_test1, test_idx1 = (X_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       y_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       X_test1.loc[cutoffs[i]+1:cutoffs[i+1]].index)\n",
    "\n",
    "        print(i)\n",
    "        print(\"test set 1:\", np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[0], unit='D'), \"-\",\n",
    "             np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[-1], unit='D'))\n",
    "\n",
    "        year = (np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[0], unit='Y'), \"-\",\n",
    "             np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[-1], unit='Y'))\n",
    "\n",
    "\n",
    "        estimator.fit(X_train1, y_train1)\n",
    "        try:\n",
    "            y_probs = estimator.predict_proba(X_test1)\n",
    "        except:\n",
    "            decisions = estimator.decision_function(X_test1)\n",
    "            y_probs = 1 / (1 + np.exp(-decisions))\n",
    "            y_probs = np.concatenate([np.zeros_like(y_probs).reshape(-1,1), y_probs.reshape(-1,1)], axis=1)\n",
    "        \n",
    "        betting_df = create_betting_df(df_ewm_19_diffs, y_probs, test_idx1)\n",
    "\n",
    "        \n",
    "        select_bets = betting_df.loc[~betting_df['prob_avg'].between(1-threshold, threshold)]\n",
    "        \n",
    "        selected_bets, roi, profit, win_pct = simulate_bets_3(select_bets)\n",
    "\n",
    "        season.append(year)\n",
    "        best_thresholds.append(threshold)\n",
    "        win_pcts.append(win_pct)\n",
    "        profits.append(profit)\n",
    "        rois.append(roi)\n",
    "        num_games_bet.append(selected_bets.shape[0])\n",
    "\n",
    "    results_by_season = pd.DataFrame({\n",
    "                                    'season':season,\n",
    "                                    'best_threshold':best_thresholds,\n",
    "                                     'win_pcts':win_pcts,\n",
    "                                     'num_games_bet':num_games_bet,\n",
    "                                     'rois':rois,\n",
    "                                      'profits':profits\n",
    "                                     })\n",
    "    \n",
    "    print('\\n', estimator)\n",
    "    print(results_by_season)\n",
    "\n",
    "results_by_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-sewing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('log', best_lr), ('sgd', best_sgd),\n",
    "              ('svc', best_svc), ('lgbc', best_lgbc), \n",
    "              ('rf', best_rf), ('knn', best_knn)]\n",
    "\n",
    "\n",
    "stacked_clf = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression(),\n",
    "                                 n_jobs=-1, verbose=1)\n",
    "\n",
    "\n",
    "# stacked_clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# print(\"stacked clf train_acc:\", stacked_clf2.score(X_train, y_train))\n",
    "# print(\"stacked clf test_acc:\", stacked_clf2.score(X_test, y_test))\n",
    "\n",
    "cutoffs = [cutoff_16, cutoff_17, cutoff_18, cutoff_19, cutoff_20, cutoff_21]\n",
    "\n",
    "threshold = 0.53\n",
    "\n",
    "for estimator in [stacked_clf]:\n",
    "    season = []\n",
    "    win_pcts = []\n",
    "    rois = []\n",
    "    profits = []\n",
    "    num_games_bet = []\n",
    "    best_thresholds = []\n",
    "    for i in range(len(cutoffs)-1):\n",
    "        X_train1, X_test1, y_train1, y_test1, train_idx1, test_idx1 = split_prep_data(df_ewm_19_diffs, cutoffs[i])\n",
    "\n",
    "        X_test1, y_test1, test_idx1 = (X_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       y_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       X_test1.loc[cutoffs[i]+1:cutoffs[i+1]].index)\n",
    "\n",
    "        print(i)\n",
    "        print(\"test set 1:\", np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[0], unit='D'), \"-\",\n",
    "             np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[-1], unit='D'))\n",
    "\n",
    "        year = (np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[0], unit='Y'), \"-\",\n",
    "             np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[-1], unit='Y'))\n",
    "\n",
    "\n",
    "        estimator.fit(X_train1, y_train1)\n",
    "        try:\n",
    "            y_probs = estimator.predict_proba(X_test1)\n",
    "        except:\n",
    "            decisions = estimator.decision_function(X_test1)\n",
    "            y_probs = 1 / (1 + np.exp(-decisions))\n",
    "            y_probs = np.concatenate([np.zeros_like(y_probs).reshape(-1,1), y_probs.reshape(-1,1)], axis=1)\n",
    "        \n",
    "        betting_df = create_betting_df(df_ewm_19_diffs, y_probs, test_idx1)\n",
    "\n",
    "        \n",
    "        select_bets = betting_df.loc[~betting_df['prob_avg'].between(1-threshold, threshold)]\n",
    "        \n",
    "        selected_bets, roi, profit, win_pct = simulate_bets_3(select_bets)\n",
    "\n",
    "        season.append(year)\n",
    "        best_thresholds.append(threshold)\n",
    "        win_pcts.append(win_pct)\n",
    "        profits.append(profit)\n",
    "        rois.append(roi)\n",
    "        num_games_bet.append(selected_bets.shape[0])\n",
    "\n",
    "    results_by_season = pd.DataFrame({\n",
    "                                    'season':season,\n",
    "                                    'best_threshold':best_thresholds,\n",
    "                                     'win_pcts':win_pcts,\n",
    "                                     'num_games_bet':num_games_bet,\n",
    "                                     'rois':rois,\n",
    "                                      'profits':profits\n",
    "                                     })\n",
    "    \n",
    "    print('\\n', estimator)\n",
    "    print(results_by_season)\n",
    "\n",
    "results_by_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-healthcare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-haiti",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-doctor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_lr_acc = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                ('logreg',\n",
    "                 LogisticRegression(C=0.001258237256125393, max_iter=10000,\n",
    "                                    random_state=22, solver='saga',\n",
    "                                    verbose=1))])\n",
    "\n",
    "best_svc_acc = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                ('svc',\n",
    "                 LinearSVC(C=0.003958061983606178, loss='hinge',\n",
    "                           max_iter=100000, random_state=23))])\n",
    "\n",
    "best_sgd_acc = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                ('sgd',\n",
    "                 SGDClassifier(alpha=0.1572381278512917, loss='modified_huber',\n",
    "                               max_iter=10000, random_state=23))])\n",
    "\n",
    "best_lgbc_acc = lgb.LGBMClassifier(feature_fraction=0.7796269937403173, max_depth=5,\n",
    "               min_child_weight=7, num_leaves=16860, random_state=22,\n",
    "               reg_alpha=3.571940784753475, reg_lambda=17.76958546447963)\n",
    "\n",
    "best_knn_acc = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                ('knn', KNeighborsClassifier(n_neighbors=24))])\n",
    "\n",
    "best_rf_acc = RandomForestClassifier(max_depth=25,\n",
    "                                min_samples_leaf=0.019764150817908317,\n",
    "                                min_samples_split=0.10607525263857515,\n",
    "                                random_state=22)\n",
    "\n",
    "estimators2 = [('log', best_lr_acc), ('sgd', best_sgd_acc),\n",
    "              ('svc', best_svc_acc), ('lgbc', best_lgbc_acc), \n",
    "              ('rf', best_rf_acc), ('knn', best_knn_acc)]\n",
    "\n",
    "\n",
    "stacked_clf2 = StackingClassifier(estimators = estimators2, final_estimator = LogisticRegression(),\n",
    "                                 n_jobs=-1, verbose=1)\n",
    "\n",
    "\n",
    "# stacked_clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# print(\"stacked clf train_acc:\", stacked_clf2.score(X_train, y_train))\n",
    "# print(\"stacked clf test_acc:\", stacked_clf2.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-campbell",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cutoffs = [cutoff_16, cutoff_17, cutoff_18, cutoff_19, cutoff_20, cutoff_21, cutoff_22]\n",
    "\n",
    "threshold = 0.53\n",
    "\n",
    "for estimator in [stacked_clf2]:\n",
    "    season = []\n",
    "    win_pcts = []\n",
    "    rois = []\n",
    "    profits = []\n",
    "    num_games_bet = []\n",
    "    best_thresholds = []\n",
    "    for i in range(len(cutoffs)-1):\n",
    "        X_train1, X_test1, y_train1, y_test1, train_idx1, test_idx1 = split_prep_data(df_ewm_19_diffs, cutoffs[i])\n",
    "\n",
    "        X_test1, y_test1, test_idx1 = (X_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       y_test1.loc[cutoffs[i]+1:cutoffs[i+1]], \n",
    "                                       X_test1.loc[cutoffs[i]+1:cutoffs[i+1]].index)\n",
    "\n",
    "        print(i)\n",
    "        print(\"test set 1:\", np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[0], unit='D'), \"-\",\n",
    "             np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[-1], unit='D'))\n",
    "\n",
    "        year = (np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[0], unit='Y'), \"-\",\n",
    "             np.datetime_as_string(df_ewm_19_diffs.loc[test_idx1, 'GAME_DATE'].values[-1], unit='Y'))\n",
    "\n",
    "\n",
    "        estimator.fit(X_train1, y_train1)\n",
    "        try:\n",
    "            y_probs = estimator.predict_proba(X_test1)\n",
    "        except:\n",
    "            decisions = estimator.decision_function(X_test1)\n",
    "            y_probs = 1 / (1 + np.exp(-decisions))\n",
    "            y_probs = np.concatenate([np.zeros_like(y_probs).reshape(-1,1), y_probs.reshape(-1,1)], axis=1)\n",
    "        \n",
    "        betting_df = create_betting_df(df_ewm_19_diffs, y_probs, test_idx1)\n",
    "\n",
    "        \n",
    "        select_bets = betting_df.loc[~betting_df['prob_avg'].between(1-threshold, threshold)]\n",
    "        \n",
    "        selected_bets, roi, profit, win_pct = simulate_bets_3(select_bets)\n",
    "\n",
    "        season.append(year)\n",
    "        best_thresholds.append(threshold)\n",
    "        win_pcts.append(win_pct)\n",
    "        profits.append(profit)\n",
    "        rois.append(roi)\n",
    "        num_games_bet.append(selected_bets.shape[0])\n",
    "\n",
    "    results_by_season = pd.DataFrame({\n",
    "                                    'season':season,\n",
    "                                    'best_threshold':best_thresholds,\n",
    "                                     'win_pcts':win_pcts,\n",
    "                                     'num_games_bet':num_games_bet,\n",
    "                                     'rois':rois,\n",
    "                                      'profits':profits\n",
    "                                     })\n",
    "    \n",
    "    print('\\n', estimator)\n",
    "    print(results_by_season)\n",
    "\n",
    "results_by_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elo_ratings(df, prev_season_final_elo):\n",
    "    \"\"\"This function will generate elo_ratings in the elo_df\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.loc[df['HOME_GAME'] == 1]\n",
    "    # Initialize the following columns\n",
    "\n",
    "    df['home_elo_pred'] = np.nan\n",
    "\n",
    "    df['home_rating_i'] = np.nan\n",
    "    df['home_rating_n'] = np.nan\n",
    "\n",
    "    df['away_rating_i'] = np.nan\n",
    "    df['away_rating_n'] = np.nan\n",
    "\n",
    "    elo_dic = prev_season_final_elo\n",
    "    for team in elo_dic:\n",
    "        elo_dic[team] = season_reset(elo_dic[team])\n",
    "        \n",
    "    for idx, row in tqdm(df.iterrows(), desc=\"progress:\"):\n",
    "        home_team_abbr = row['MATCHUP'][:3]\n",
    "        away_team_abbr = row['MATCHUP'][-3:]\n",
    "        \n",
    "        df.loc[idx, 'home_rating_i'] = elo_dic[home_team_abbr]\n",
    "        df.loc[idx, 'away_rating_i'] = elo_dic[away_team_abbr]\n",
    "\n",
    "        home_score = row['SCORE_team']\n",
    "        away_score = home_score - row['point_diff_team']\n",
    "        home_rating = elo_dic[home_team_abbr]\n",
    "        away_rating = elo_dic[away_team_abbr]\n",
    "\n",
    "        home_update, away_update = elo_update(home_score, away_score, home_rating, away_rating)\n",
    "\n",
    "        df.loc[idx, 'home_rating_n'] = home_rating + home_update\n",
    "        df.loc[idx, 'away_rating_n'] = away_rating + away_update\n",
    "        df.loc[idx, 'home_elo_pred'] = elo_prediction(home_rating+100, away_rating)\n",
    "\n",
    "    df['elo_MOV_pred'] = round((df['home_rating_i']+100 - df['away_rating_i'])/28, 2)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_2020 = add_elo_ratings(df_2020, final_elo_2020)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-bundle",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "ETL Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-gather",
   "metadata": {},
   "source": [
    "### Update Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.update_data import update_all_data\n",
    "\n",
    "\n",
    "# connection = sqlite3.connect('../data/nba.db')\n",
    "# update_all_data(connection, season=2021)\n",
    "# connection.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.model_preparation import get_days_spreads\n",
    "from src.models.model_preparation import get_days_moneylines\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_str(x):\n",
    "    return str(x) + '-' + str(x+1)[-2:]\n",
    "\n",
    "def load_current_season_team_data(conn, season):\n",
    "    \"\"\"Loads basic, advanced, and scoring boxscores \n",
    "    from sqlite db and merges them into one dataframe\"\"\"\n",
    "\n",
    "    basic = pd.read_sql(\"SELECT * FROM team_basic_boxscores\", conn)\n",
    "    adv = pd.read_sql(\"SELECT * FROM team_advanced_boxscores\", conn)\n",
    "    scoring = pd.read_sql(\"SELECT * FROM team_scoring_boxscores\", conn)\n",
    "\n",
    "    temp = pd.merge(basic, adv, how='left', on=[\n",
    "                    'GAME_ID', 'TEAM_ID'], suffixes=['', '_y'])\n",
    "    df = pd.merge(temp, scoring, how='left', on=[\n",
    "                  'GAME_ID', 'TEAM_ID'], suffixes=['', '_y'])\n",
    "\n",
    "    df = df.drop(columns=['TEAM_NAME_y', 'TEAM_CITY',\n",
    "                          'TEAM_ABBREVIATION_y',\n",
    "                          'TEAM_CITY_y', 'MIN_y'])\n",
    "    \n",
    "    df = df.loc[df['SEASON'] == season_str(2021)]\n",
    "            \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-preserve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection = sqlite3.connect('../data/nba.db')\n",
    "def load_current_season_betting_data(conn, season):\n",
    "    season_string = season_str(season)\n",
    "    spreads = pd.read_sql(f\"SELECT * FROM spreads WHERE SEASON = '{season_string}'\", conn)\n",
    "    moneylines = pd.read_sql(f\"SELECT * FROM moneylines WHERE SEASON = '{season_string}'\", conn)\n",
    "    conn.close()\n",
    "    return spreads, moneylines\n",
    "\n",
    "\n",
    "\n",
    "# create_matchups(df)\n",
    "# get_team_and_opp_ewm(df, min_periods=5, alpha=0.1, adjust=True)\n",
    "\n",
    "\n",
    "# connection.close()\n",
    "# betting_data_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-pitch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_and_opp_ewm(df, min_periods=1, alpha=0.1, adjust=True):\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df[['SEASON_team', 'TEAM_ID_team', 'TEAM_ABBREVIATION_team',\n",
    "             'TEAM_NAME_team', 'GAME_ID', 'GAME_DATE_team', 'MATCHUP_team',\n",
    "             'HOME_GAME_team', 'TEAM_SCORE_team', 'POINT_DIFF_team', 'WL_team',\n",
    "             'ML_team', 'SPREAD_team', 'TEAM_COVERED_team', 'RECORD_team',\n",
    "             'FG2M_team', 'FG2A_team',\n",
    "             'FG3M_team', 'FG3A_team', 'FTM_team', 'FTA_team', 'OREB_team',\n",
    "             'DREB_team', 'REB_team',\n",
    "             'AST_team', 'STL_team', 'BLK_team', 'TOV_team', 'PF_team', 'PTS_team',\n",
    "             'PLUS_MINUS_team', 'E_OFF_RATING_team', 'E_DEF_RATING_team',\n",
    "             'E_NET_RATING_team', 'POSS_team', 'PIE_team', 'PTS_2PT_MR_team',\n",
    "             'PTS_FB_team', 'PTS_OFF_TOV_team', 'PTS_PAINT_team', 'AST_2PM_team',\n",
    "             'AST_3PM_team', 'UAST_2PM_team', 'UAST_3PM_team', 'ATS_DIFF_team',\n",
    "             'RECORD_opp', 'FG2M_opp', 'FG2A_opp', 'FG3M_opp',\n",
    "             'FG3A_opp', 'FTM_opp', 'FTA_opp', 'OREB_opp', 'DREB_opp', 'REB_opp',\n",
    "             'AST_opp', 'STL_opp', 'BLK_opp',\n",
    "             'TOV_opp', 'PF_opp', 'PTS_opp', 'PLUS_MINUS_opp', 'E_OFF_RATING_opp',\n",
    "             'E_DEF_RATING_opp', 'E_NET_RATING_opp', 'POSS_opp', 'PIE_opp',\n",
    "             'PTS_2PT_MR_opp', 'PTS_FB_opp', 'PTS_OFF_TOV_opp', 'PTS_PAINT_opp',\n",
    "             'AST_2PM_opp', 'AST_3PM_opp', 'UAST_2PM_opp', 'UAST_3PM_opp',\n",
    "             'ATS_DIFF_opp', 'TEAM_COVERED_opp']]\n",
    "\n",
    "    team_dfs = []\n",
    "\n",
    "    for team in df['TEAM_ABBREVIATION_team'].unique():\n",
    "        team_df = df.loc[df['TEAM_ABBREVIATION_team'] == team].sort_values(\n",
    "            'GAME_DATE_team')\n",
    "\n",
    "        avg_spread = team_df['SPREAD_team'].shift(1).expanding().mean()\n",
    "\n",
    "        avg_ml = team_df['ML_team'].shift(1).expanding().mean()\n",
    "\n",
    "        record = team_df['RECORD_team'].shift(1).expanding().mean()\n",
    "\n",
    "        ATS_rec = team_df['TEAM_COVERED_team'].shift(\n",
    "            1).expanding().mean()\n",
    "\n",
    "        ATS_avg_diff = team_df['ATS_DIFF_team'].shift(\n",
    "            1).expanding().mean()\n",
    "\n",
    "        records = pd.DataFrame({'WL_PCT': record,\n",
    "                               'ATS_PCT': ATS_rec,\n",
    "                                'AVG_SPREAD': avg_spread,\n",
    "                                'AVG_ML': avg_ml,\n",
    "                                'AVG_ATS_DIFF': ATS_avg_diff\n",
    "                                })\n",
    "\n",
    "        team_df.iloc[:, 14:] = team_df.iloc[:, 14:].shift(\n",
    "            1).ewm(alpha=alpha, min_periods=min_periods).mean()\n",
    "\n",
    "        team_df = pd.concat([team_df, records], axis=1)\n",
    "\n",
    "        team_dfs.append(team_df)\n",
    "\n",
    "    new_df = pd.concat(team_dfs)\n",
    "    new_df = new_df.reset_index(drop=True)\n",
    "\n",
    "    return new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-telescope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-arctic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_rest_days_for_model(df):\n",
    "    df['REST'] = np.nan\n",
    "    for team in df['TEAM_ABBREVIATION_team'].unique():\n",
    "        team_df = df.loc[df['TEAM_ABBREVIATION_team'] == team].sort_values('GAME_DATE_team')\n",
    "        idx = team_df.index\n",
    "        team_df['rest'] = (team_df['GAME_DATE_team'].shift(-1) - team_df['GAME_DATE_team']) / np.timedelta64(1, 'D')\n",
    "        team_df.at[max(idx), 'REST'] = (pd.to_datetime(date.today()) - team_df.at[max(idx), 'GAME_DATE_team']) / np.timedelta64(1, 'D')\n",
    "\n",
    "        df.loc[idx, 'REST'] = team_df['REST']\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-vermont",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_season_elo_ratings(df, prev_season_final_elo):\n",
    "    \"\"\"This function will generate elo_ratings in the elo_df\n",
    "    \"\"\"\n",
    "    df = df.sort_values(['GAME_ID', 'HOME_GAME_team'])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    df['team_elo_pred'] = np.nan\n",
    "\n",
    "    df['team_rating_i'] = np.nan\n",
    "    df['team_rating_n'] = np.nan\n",
    "\n",
    "    df['opp_rating_i'] = np.nan\n",
    "    df['opp_rating_n'] = np.nan\n",
    "\n",
    "    elo_dic = pd.Series(prev_season_final_elo.ELO.values, index=prev_season_final_elo.TEAM).to_dict()\n",
    "\n",
    "    for team in elo_dic:\n",
    "        elo_dic[team] = season_reset(elo_dic[team])\n",
    "        \n",
    "    for idx, row in tqdm(df.iterrows(), desc=\"progress:\"):\n",
    "                \n",
    "        if (idx >= 1) and (row['GAME_ID'] == df.loc[idx-1, 'GAME_ID']):\n",
    "            df.at[idx, 'team_rating_i'] = df.at[idx-1, 'opp_rating_i']\n",
    "            df.at[idx, 'team_rating_n'] = df.at[idx-1, 'opp_rating_n']\n",
    "            df.at[idx, 'opp_rating_i'] = df.at[idx-1, 'team_rating_i']\n",
    "            df.at[idx, 'opp_rating_n'] = df.at[idx-1, 'team_rating_n']\n",
    "            df.at[idx, 'team_elo_pred'] = 1 - df.at[idx-1, 'team_elo_pred']            \n",
    "            continue\n",
    "            \n",
    "        team_abbr = row['MATCHUP_team'][:3]\n",
    "        opp_abbr = row['MATCHUP_team'][-3:]   \n",
    "        \n",
    "        df.at[idx, 'team_rating_i'] = elo_dic[team_abbr]            \n",
    "        df.at[idx, 'opp_rating_i'] = elo_dic[opp_abbr]\n",
    "            \n",
    "\n",
    "        team_score = row['TEAM_SCORE_team']\n",
    "        opp_score = row['TEAM_SCORE_team'] - row['POINT_DIFF_team']\n",
    "            \n",
    "        team_rating = elo_dic[team_abbr]\n",
    "        opp_rating = elo_dic[opp_abbr]\n",
    "\n",
    "        if row['HOME_GAME_team'] == 1:\n",
    "            team_rating_temp = team_rating + 69\n",
    "            opp_rating_temp = opp_rating\n",
    "        else:\n",
    "            opp_rating_temp = opp_rating + 69\n",
    "            team_rating_temp = team_rating\n",
    "            \n",
    "        team_update, opp_update = elo_update(team_score, opp_score, team_rating_temp, opp_rating_temp)\n",
    "\n",
    "        df.at[idx, 'team_rating_n'] = team_rating + team_update\n",
    "        df.at[idx, 'opp_rating_n'] = opp_rating + opp_update\n",
    "        \n",
    "\n",
    "        df.at[idx, 'team_elo_pred'] = elo_prediction(team_rating_temp, opp_rating_temp)\n",
    "\n",
    "        elo_dic[team_abbr] = df.at[idx, 'team_rating_n']\n",
    "        elo_dic[opp_abbr] = df.at[idx, 'opp_rating_n']\n",
    "\n",
    "    df['elo_MOV_pred'] = round((df['team_rating_i'] - df['opp_rating_i'])/28, 2)\n",
    "    \n",
    "\n",
    "    return elo_dic, df\n",
    "\n",
    "\n",
    "# final_elo_2020 = pd.read_csv(\"../data/final_elo_ratings_2020\")\n",
    "# current_elo, team_avgs_21 = get_current_season_elo_ratings(team_avgs_21, final_elo_2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchup_rows_for_model(df, home_team, away_team, home_spread, away_spread,\n",
    "                                  home_ml, away_ml):\n",
    "    df = df.copy(deep=True)\n",
    "    df.rename(columns={'SEASON_team':'SEASON',\n",
    "                      'TEAM_ID_team':'TEAM_ID',\n",
    "                      'TEAM_ABBREVIATION_team':'TEAM_ABBREVIATION',\n",
    "                      'GAME_DATE_team':'GAME_DATE',\n",
    "                      'MATCHUP_team':'MATCHUP',\n",
    "                      'HOME_GAME_team':'HOME_GAME',\n",
    "                       'TEAM_SCORE_team':'SCORE_team'}, inplace=True)\n",
    "    \n",
    "    df = df.sort_values(['GAME_ID', 'HOME_GAME'])\n",
    "    \n",
    "    home_stats = df.loc[df['TEAM_ABBREVIATION'] == home_team].reset_index(drop=True)\n",
    "    away_stats = df.loc[df['TEAM_ABBREVIATION'] == away_team].reset_index(drop=True)\n",
    "\n",
    "    home_diffs = home_stats.iloc[-1, 14:-6] - away_stats.iloc[-1, 14:-6]\n",
    "    home_diffs = home_diffs.values.reshape(1, -1)    \n",
    "#     home_diffs = np.concatenate([home_diffs, home_stats.iloc[-1, -6:].values.reshape(1, -1)], axis=1)\n",
    "\n",
    "    away_diffs = away_stats.iloc[-1, 14:-6] - home_stats.iloc[-1, 14:-6]\n",
    "    away_diffs = away_diffs.values.reshape(1, -1)\n",
    "#     away_diffs = np.concatenate([away_diffs, away_stats.iloc[-1, -6:].values.reshape(1, -1)], axis=1)\n",
    "    \n",
    "    diffs = np.concatenate([home_diffs, away_diffs], axis=0)\n",
    "    \n",
    "    new_cols = [col+\"_diff\" for col in home_stats.columns[14:-6]]\n",
    "#     new_cols.extend(home_stats.columns[-6:])\n",
    "    \n",
    "    diffs = pd.DataFrame(diffs, columns=new_cols)\n",
    "    \n",
    "    home_rating_i = home_stats.iloc[-1, -5]\n",
    "    away_rating_i = away_stats.iloc[-1, -5]\n",
    "    \n",
    "    diffs['team_rating_i'] = np.nan\n",
    "    diffs['opp_rating_i'] = np.nan\n",
    "    \n",
    "    diffs.at[0, 'team_rating_i'] = home_rating_i\n",
    "    diffs.at[0, 'opp_rating_i'] = away_rating_i\n",
    "    \n",
    "    diffs.at[1, 'team_rating_i'] = away_rating_i\n",
    "    diffs.at[1, 'opp_rating_i'] = home_rating_i\n",
    "    \n",
    "    diffs.at[0, 'team_elo_pred'] = elo_prediction(home_rating_i+69, away_rating_i)\n",
    "    diffs.at[1, 'team_elo_pred'] = elo_prediction(away_rating_i, home_rating_i+69)\n",
    "\n",
    "    diffs['elo_MOV_pred'] = np.nan\n",
    "    diffs.at[0, 'elo_MOV_pred'] = round((home_rating_i + 69 - away_rating_i)/28, 2)\n",
    "    diffs.at[1, 'elo_MOV_pred'] = round((away_rating_i - (home_rating_i + 69))/28, 2)\n",
    "\n",
    "    diffs['SPREAD_team'] = np.nan\n",
    "    diffs['ML_team'] = np.nan\n",
    "    \n",
    "    diffs.at[0, 'SPREAD_team'] = home_spread\n",
    "    diffs.at[1, 'SPREAD_team'] = away_spread \n",
    "    \n",
    "    diffs.at[0, 'ML_team'] = home_ml\n",
    "    diffs.at[1, 'ML_team'] = away_ml\n",
    "    \n",
    "    diffs = diffs[X_train.columns].astype(float)\n",
    "    \n",
    "    return diffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "todays_spreads = get_days_spreads(todays_date)\n",
    "todays_spreads = clean_spreads_df(todays_spreads)\n",
    "\n",
    "todays_mls = get_days_moneylines(todays_date)\n",
    "todays_mls = clean_moneyline_df(todays_mls)\n",
    "\n",
    "todays_lines = pd.concat([todays_spreads, todays_mls.iloc[:, -2:]], axis=1)\n",
    "todays_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "web = 'https://sportsbook.draftkings.com/leagues/basketball/88670846?category=game-lines&subcategory=game'\n",
    "path = '../chromedriver.exe'\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.get(web)\n",
    "sleep(2)\n",
    "\n",
    "teams = driver.find_elements_by_xpath('//*[@id=\"root\"]/section/section[2]/section/div[3]/div/div[3]/div/div/div[2]/div/div[2]/div[1]/table/tbody/tr/th/a/div/div[2]/span/div/div')\n",
    "# spreads = driver.find_elements_by_xpath('//*[@id=\"root\"]/section/section[2]/section/div[4]/div/div[3]/div/div/div[2]/div/div[2]/div[1]/table/tbody/tr/td[1]/div/div/div/div[1]/span')\n",
    "# moneylines = driver.find_elements_by_xpath('//*[@id=\"root\"]/section/section[2]/section/div[4]/div/div[3]/div/div/div[2]/div/div[2]/div[1]/table/tbody/tr/td[3]/div/div/div/div/div[2]/span')\n",
    "'//*[@id=\"root\"]/section/section[2]/section/div[3]/div/div[3]/div/div/div[2]/div/div[2]/div[1]/table/tbody/tr[2]/th/a/div/div[2]/span/div/div'\n",
    "'//*[@id=\"root\"]/section/section[2]/section/div[3]/div/div[3]/div/div/div[2]/div/div[2]/div[2]/table/tbody/tr[1]/th/a/div/div[2]/span/div/div'\n",
    "print(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "\n",
    "def get_draftking_lines(date):\n",
    "    \"\"\"\n",
    "    INPUTS\n",
    "    date: \"yyyy-mm-dd\"\n",
    "    OUPUTS \n",
    "    dataframe with game spreads\n",
    "    \"\"\"\n",
    "    gm_dates = []\n",
    "    away_teams = []\n",
    "    home_teams = []\n",
    "    away_spreads = []\n",
    "    home_spreads = []\n",
    "    away_moneylines = []\n",
    "    home_moneylines = []\n",
    "\n",
    "    web = 'https://sportsbook.draftkings.com/leagues/basketball/88670846?category=game-lines&subcategory=game'\n",
    "    path = '../chromedriver.exe'\n",
    "    driver = webdriver.Chrome(path)\n",
    "    driver.get(web)\n",
    "    sleep(2)\n",
    "    \n",
    "    teams = driver.find_elements_by_xpath('//*[@id=\"root\"]/section/section[2]/section/div[3]/div/div[3]/div/div/div[2]/div/div[2]/div[1]/table/tbody/tr/th/a/div/div[2]/span/div/div')\n",
    "    spreads = driver.find_elements_by_xpath('//*[@id=\"root\"]/section/section[2]/section/div[3]/div/div[3]/div/div/div[2]/div/div[2]/div[1]/table/tbody/tr/td[1]/div/div/div/div[1]/span')\n",
    "    moneylines = driver.find_elements_by_xpath('//*[@id=\"root\"]/section/section[2]/section/div[3]/div/div[3]/div/div/div[2]/div/div[2]/div[1]/table/tbody/tr/td[3]/div/div/div/div/div[2]/span')\n",
    "\n",
    "    print(len(teams), len(spreads), len(moneylines))\n",
    "    \n",
    "    for i in range(len(teams)):\n",
    "        if i%2==0:\n",
    "            away_teams.append(teams[i].text)\n",
    "            away_spreads.append(spreads[i].text)\n",
    "            away_moneylines.append(moneylines[i].text)\n",
    "            gm_dates.append(date)\n",
    "        else:\n",
    "            home_teams.append(teams[i].text)\n",
    "            home_spreads.append(spreads[i].text)\n",
    "            home_moneylines.append(moneylines[i].text)    \n",
    "\n",
    "#     driver.quit()\n",
    "\n",
    "    todays_lines = pd.DataFrame({\"game_date\":gm_dates,\n",
    "                'away_team':away_teams,\n",
    "                'home_team':home_teams,\n",
    "                'away_spread':away_spreads,\n",
    "                'home_spread':home_spreads,\n",
    "                'away_moneyline':away_moneylines,\n",
    "                'home_moneyline':home_moneylines})\n",
    "    \n",
    "    return todays_lines\n",
    "\n",
    "\n",
    "get_draftking_lines('2021-11-09')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.model_preparation import get_draftking_lines, clean_draftking_lines\n",
    "\n",
    "todays_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "todays_lines = get_draftking_lines(todays_date)\n",
    "\n",
    "# todays_lines = clean_draftking_lines(todays_lines)\n",
    "\n",
    "todays_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-brake",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv(\"../data/clean/processed_data.csv\")\n",
    "\n",
    "clean_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, df):\n",
    "    todays_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    todays_lines = get_draftking_lines(todays_date)\n",
    "    todays_lines = clean_draftking_lines(todays_lines)\n",
    "\n",
    "    game_dates = []\n",
    "    home_teams = []\n",
    "    away_teams = []\n",
    "    home_spreads = []\n",
    "    home_cover_probs = []\n",
    "    away_cover_probs = []\n",
    "\n",
    "    for idx, row in todays_lines.iterrows():\n",
    "        home_team = row['home_team']\n",
    "        away_team = row['away_team']\n",
    "        home_spread = row['home_spread'] \n",
    "        away_spread = row['away_spread']\n",
    "        home_ml = row['home_moneyline']\n",
    "        away_ml = row['away_moneyline']\n",
    "        game_date = row['game_date']\n",
    "        matchup = create_matchup_rows_for_model(df, home_team, away_team,\n",
    "                                                home_spread, away_spread, home_ml, away_ml)\n",
    "\n",
    "        probs = model.predict_proba(matchup)\n",
    "\n",
    "        game_dates.append(game_date)\n",
    "        home_teams.append(home_team)\n",
    "        away_teams.append(away_team)\n",
    "        home_cover_probs.append(probs[0, 1])\n",
    "        away_cover_probs.append(probs[1, 1])\n",
    "        home_spreads.append(home_spread)\n",
    "\n",
    "    todays_predictions = pd.DataFrame({'game_date':game_dates,\n",
    "                                      'home_team':home_teams,\n",
    "                                      'away_team':away_teams,\n",
    "                                       'home_spread':home_spreads,\n",
    "                                      'home_cover_probs':home_cover_probs,\n",
    "                                      'away_cover_probs':away_cover_probs})\n",
    "\n",
    "    todays_predictions['home_cover_avg'] = (todays_predictions['home_cover_probs'] \n",
    "                                            + (1-todays_predictions['away_cover_probs']))/2\n",
    "    return todays_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stacked_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stacked_clf = joblib.load('../models/finalized_stacked_model_sfs')\n",
    "\n",
    "X_full = pd.concat([X_train, X_test])\n",
    "y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "X_full.shape, y_full.shape\n",
    "\n",
    "final_stacked_clf.fit(X_full, y_full)\n",
    "\n",
    "\n",
    "filename = '../models/finalized_stacked_model_retrain-21-12-20'\n",
    "\n",
    "joblib.dump(final_stacked_clf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stacked_model = joblib.load('../models/finalized_stacked_model_sfs')\n",
    "\n",
    "prev_season_elo = pd.read_csv(\"../data/clean/final_elo_ratings_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.concat([X_train, X_test])\n",
    "y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "X_full.shape, y_full.shape\n",
    "\n",
    "stacked_clf2.fit(X_full, y_full)\n",
    "\n",
    "filename = '../models/final_stacked_clf_v2-21-12-20'\n",
    "\n",
    "joblib.dump(stacked_clf2, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-windsor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2840d83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(conn, season, model, prev_season_elo, append = True):\n",
    "    update_all_data(conn, season=season)\n",
    "\n",
    "    df = load_current_season_team_data(conn, season)\n",
    "\n",
    "    df = clean_team_data(df)\n",
    "\n",
    "    df = prep_for_aggregation(df)\n",
    "\n",
    "    spreads, moneylines = load_current_season_betting_data(conn, 2021)\n",
    "    clean_moneylines = clean_moneyline_df(df=moneylines)\n",
    "    clean_spreads = clean_spreads_df(df=spreads)\n",
    "\n",
    "\n",
    "    full_df = merge_betting_and_boxscore_data(clean_spreads, clean_moneylines, df)\n",
    "    full_df = create_matchups(full_df)\n",
    "    full_df = get_team_and_opp_ewm(full_df)\n",
    "\n",
    "    full_df = add_percentage_features(full_df)\n",
    "    full_df = add_rest_days_for_model(full_df)\n",
    "\n",
    "    current_elo, full_df = get_current_season_elo_ratings(full_df, prev_season_elo)\n",
    "    \n",
    "    todays_predictions = make_predictions(model, full_df)\n",
    "    \n",
    "    if append == True:\n",
    "        todays_predictions.to_csv(\"../results/predictions_2021.csv\", mode='a', header=False, index=False)  \n",
    "    \n",
    "    return todays_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sqlite3.connect('../data/nba.db')\n",
    "\n",
    "prev_season_elo = pd.read_csv(\"../data/clean/final_elo_ratings_2020.csv\")\n",
    "todays_predictions = main(connection, 2021, final_stacked_model, prev_season_elo, append=True)\n",
    "\n",
    "connection.close()\n",
    "\n",
    "todays_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "season = 2021\n",
    "home_team = 'PHI'\n",
    "away_team = 'NYK'\n",
    "home_spread = -3.5\n",
    "away_spread = -home_spread\n",
    "home_ml = 1.63\n",
    "away_ml = 2.4\n",
    "\n",
    "conn = sqlite3.connect('../data/nba.db')\n",
    "\n",
    "# update_all_data(conn, season=season)\n",
    "\n",
    "df = load_current_season_team_data(conn, season)\n",
    "\n",
    "df = clean_team_data(df)\n",
    "\n",
    "df = prep_for_aggregation(df)\n",
    "\n",
    "spreads, moneylines = load_current_season_betting_data(conn, 2021)\n",
    "clean_moneylines = clean_moneyline_df(df=moneylines)\n",
    "clean_spreads = clean_spreads_df(df=spreads)\n",
    "\n",
    "\n",
    "full_df = merge_betting_and_boxscore_data(clean_spreads, clean_moneylines, df)\n",
    "full_df = create_matchups(full_df)\n",
    "full_df = get_team_and_opp_ewm(full_df)\n",
    "\n",
    "full_df = add_percentage_features(full_df)\n",
    "full_df = add_rest_days_for_model(full_df)\n",
    "\n",
    "current_elo, full_df = get_current_season_elo_ratings(full_df, prev_season_elo)\n",
    "\n",
    "matchup = create_matchup_rows_for_model(full_df, home_team, away_team,\n",
    "                                        home_spread, away_spread, home_ml, away_ml)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# print(matchup)\n",
    "\n",
    "# full_df\n",
    "matchup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stacked_model.predict_proba(matchup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afed4e3e0de72dfe896065169312871c2edc1b77c10ac917e4bc0d2d23ff8bb0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nba-model-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "436px",
    "width": "426px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "350.278px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
